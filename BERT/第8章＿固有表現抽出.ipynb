{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/seiji0203/BERT/blob/master/%E7%AC%AC8%E7%AB%A0%EF%BC%BF%E5%9B%BA%E6%9C%89%E8%A1%A8%E7%8F%BE%E6%8A%BD%E5%87%BA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gVnvArYlINT_"
      },
      "source": [
        "# 目標\n",
        "固有表現抽出を行うためのアルゴリズムを理解する。\n",
        "BERTを用いて固有表現抽出を実装し、ファインチューニングと性能評価を行う。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WMvO49oDHwtV",
        "outputId": "230c22da-4753-4e53-90d0-503c72e3c5bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/chap8\n"
          ]
        }
      ],
      "source": [
        "!mkdir chap8\n",
        "%cd ./chap8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_yCaTRPXIqnb",
        "outputId": "9ffaec34-febe-4c7d-e4b4-fb5180a08e68"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers==4.5.0 in /usr/local/lib/python3.7/dist-packages (4.5.0)\n",
            "Requirement already satisfied: fugashi==1.1.0 in /usr/local/lib/python3.7/dist-packages (1.1.0)\n",
            "Requirement already satisfied: ipadic==1.0.0 in /usr/local/lib/python3.7/dist-packages (1.0.0)\n",
            "Requirement already satisfied: pytorch-lightning==1.2.10 in /usr/local/lib/python3.7/dist-packages (1.2.10)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.0) (1.19.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.0) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.0) (3.3.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.0) (0.0.46)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.0) (0.10.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.0) (4.62.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.0) (4.8.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.0) (2.23.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.0) (21.0)\n",
            "Requirement already satisfied: torchmetrics==0.2.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.2.10) (0.2.0)\n",
            "Requirement already satisfied: torch>=1.4 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.2.10) (1.9.0+cu111)\n",
            "Requirement already satisfied: PyYAML!=5.4.*,>=5.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.2.10) (6.0)\n",
            "Requirement already satisfied: fsspec[http]>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.2.10) (2021.10.1)\n",
            "Requirement already satisfied: future>=0.17.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.2.10) (0.18.2)\n",
            "Requirement already satisfied: tensorboard!=2.5.0,>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.2.10) (2.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from fsspec[http]>=0.8.1->pytorch-lightning==1.2.10) (3.7.4.post0)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.2.10) (1.41.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.2.10) (3.3.4)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.2.10) (0.4.6)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.2.10) (57.4.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.2.10) (1.0.1)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.2.10) (3.17.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.2.10) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.2.10) (1.8.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.2.10) (0.37.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.2.10) (0.12.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.2.10) (1.35.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py>=0.4->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.2.10) (1.15.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.2.10) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.2.10) (4.7.2)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.2.10) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.2.10) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.2.10) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.5.0) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.5.0) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.5.0) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.5.0) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.2.10) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4->pytorch-lightning==1.2.10) (3.7.4.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]>=0.8.1->pytorch-lightning==1.2.10) (21.2.0)\n",
            "Requirement already satisfied: async-timeout<4.0,>=3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]>=0.8.1->pytorch-lightning==1.2.10) (3.0.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]>=0.8.1->pytorch-lightning==1.2.10) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]>=0.8.1->pytorch-lightning==1.2.10) (5.2.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.5.0) (3.6.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==4.5.0) (2.4.7)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.5.0) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.5.0) (1.0.1)\n"
          ]
        }
      ],
      "source": [
        "# 8-2\n",
        "!pip install transformers==4.5.0 fugashi==1.1.0 ipadic==1.0.0 pytorch-lightning==1.2.10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ef3sRemI2b6"
      },
      "outputs": [],
      "source": [
        "# 8-3\n",
        "import itertools\n",
        "import random\n",
        "import json\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import unicodedata\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import BertJapaneseTokenizer, BertForTokenClassification\n",
        "import pytorch_lightning as pl\n",
        "\n",
        "# 日本語学習済みモデル\n",
        "MODEL_NAME = 'cl-tohoku/bert-base-japanese-whole-word-masking'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l9lf0mSrKLAJ"
      },
      "source": [
        "### 固有表現抽出とは(与えられた文章をトークンかいて、各トークンのラベルを予測する分類問題として扱える)\n",
        "文章が与えられたときに、その中から固有表現に対応する文字列を抜き出して、抽出したそれぞれの固有表現のカテゴリーを判断する。\n",
        "\n",
        "## IREX\n",
        "組織名（政府組織名）、固有物名、人名、地名、日付表現、時間表現、金額表現、割合表現\n",
        "## 拡張固有表現階層\n",
        "\n",
        "#### どのようなものに応用されるか？\n",
        "タグ付け、人名へのマスク付け"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tjdOTDtyJ3s6",
        "outputId": "cf2353f3-d8b7-46d0-f1a9-dedf92fe551f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ＡＢＣ -> ABC\n",
            "ABC -> ABC\n",
            "１２３ -> 123\n",
            "123 -> 123\n",
            "アイウ -> アイウ\n",
            "ｱｲｳ -> アイウ\n"
          ]
        }
      ],
      "source": [
        "# 8-4\n",
        "normalize = lambda s: unicodedata.normalize(\"NFKC\",s)\n",
        "print(f'ＡＢＣ -> {normalize(\"ＡＢＣ\")}' )  # 全角アルファベット\n",
        "print(f'ABC -> {normalize(\"ABC\")}' )        # 半角アルファベット\n",
        "print(f'１２３ -> {normalize(\"１２３\")}' )  # 全角数字\n",
        "print(f'123 -> {normalize(\"123\")}' )        # 半角数字\n",
        "print(f'アイウ -> {normalize(\"アイウ\")}' )  # 全角カタカナ\n",
        "print(f'ｱｲｳ -> {normalize(\"ｱｲｳ\")}' )        # 半角カタカナ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H07odCkATEXv"
      },
      "source": [
        "##BERTが出力したタグ列から文章中の固有表現を得る関数を実装する\n",
        "####・文章と固有表現が与えられた時に、文章の符号化とタグ列の作成を行い、モデルに入力できる形式にする関数（学習）\n",
        "####・文章の符号化をするとともに、各トークンの文章中の位置を特定する関数（推論）\n",
        "####・文章とタグ列と各トークンの文章中の位置が与えられた時に、文章中に含まれる固有表現に対応する文字列や位置を特定する関数（推論）"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IuZsdhFAM_Wv"
      },
      "outputs": [],
      "source": [
        "# 8-5\n",
        "class NER_tokenizer(BertJapaneseTokenizer):\n",
        "       \n",
        "    def encode_plus_tagged(self, text, entities, max_length):\n",
        "        \"\"\"\n",
        "        文章とそれに含まれる固有表現が与えられた時に、\n",
        "        符号化とラベル列の作成を行う。\n",
        "        \"\"\"\n",
        "        # 固有表現の前後でtextを分割し、それぞれのラベルをつけておく。\n",
        "        entities = sorted(entities, key=lambda x: x['span'][0])\n",
        "        splitted = [] # 分割後の文字列を追加していく\n",
        "        position = 0\n",
        "        for entity in entities:\n",
        "            start = entity['span'][0]\n",
        "            end = entity['span'][1]\n",
        "            label = entity['type_id']\n",
        "            # 固有表現ではないものには0のラベルを付与\n",
        "            splitted.append({'text':text[position:start], 'label':0}) \n",
        "            # 固有表現には、固有表現のタイプに対応するIDをラベルとして付与\n",
        "            splitted.append({'text':text[start:end], 'label':label}) \n",
        "            position = end\n",
        "        splitted.append({'text': text[position:], 'label':0})\n",
        "        splitted = [ s for s in splitted if s['text'] ] # 長さ0の文字列は除く\n",
        "\n",
        "        # 分割されたそれぞれの文字列をトークン化し、ラベルをつける。\n",
        "        tokens = [] # トークンを追加していく\n",
        "        labels = [] # トークンのラベルを追加していく\n",
        "        for text_splitted in splitted:\n",
        "            text = text_splitted['text']\n",
        "            label = text_splitted['label']\n",
        "            tokens_splitted = self.tokenize(text)\n",
        "            labels_splitted = [label] * len(tokens_splitted)\n",
        "            tokens.extend(tokens_splitted)\n",
        "            labels.extend(labels_splitted)\n",
        "\n",
        "        # 符号化を行いBERTに入力できる形式にする。\n",
        "        input_ids = self.convert_tokens_to_ids(tokens)\n",
        "        encoding = self.prepare_for_model(\n",
        "            input_ids, \n",
        "            max_length=max_length, \n",
        "            padding='max_length', \n",
        "            truncation=True\n",
        "        ) # input_idsをencodingに変換\n",
        "        # 特殊トークン[CLS]、[SEP]のラベルを0にする。\n",
        "        labels = [0] + labels[:max_length-2] + [0] \n",
        "        # 特殊トークン[PAD]のラベルを0にする。\n",
        "        labels = labels + [0]*( max_length - len(labels) ) \n",
        "        encoding['labels'] = labels\n",
        "\n",
        "        return encoding\n",
        "\n",
        "    def encode_plus_untagged(\n",
        "        self, text, max_length=None, return_tensors=None\n",
        "    ):\n",
        "        \"\"\"\n",
        "        文章をトークン化し、それぞれのトークンの文章中の位置も特定しておく。\n",
        "        \"\"\"\n",
        "        # 文章のトークン化を行い、\n",
        "        # それぞれのトークンと文章中の文字列を対応づける。\n",
        "        tokens = [] # トークンを追加していく。\n",
        "        tokens_original = [] # トークンに対応する文章中の文字列を追加していく。\n",
        "        words = self.word_tokenizer.tokenize(text) # MeCabで単語に分割\n",
        "        for word in words:\n",
        "            # 単語をサブワードに分割\n",
        "            tokens_word = self.subword_tokenizer.tokenize(word) \n",
        "            tokens.extend(tokens_word)\n",
        "            if tokens_word[0] == '[UNK]': # 未知語への対応\n",
        "                tokens_original.append(word)\n",
        "            else:\n",
        "                tokens_original.extend([\n",
        "                    token.replace('##','') for token in tokens_word\n",
        "                ])\n",
        "\n",
        "        # 各トークンの文章中での位置を調べる。（空白の位置を考慮する）\n",
        "        position = 0\n",
        "        spans = [] # トークンの位置を追加していく。\n",
        "        for token in tokens_original:\n",
        "            l = len(token)\n",
        "            while 1:\n",
        "                if token != text[position:position+l]:\n",
        "                    position += 1\n",
        "                else:\n",
        "                    spans.append([position, position+l])\n",
        "                    position += l\n",
        "                    break\n",
        "\n",
        "        # 符号化を行いBERTに入力できる形式にする。\n",
        "        input_ids = self.convert_tokens_to_ids(tokens) \n",
        "        encoding = self.prepare_for_model(\n",
        "            input_ids, \n",
        "            max_length=max_length, \n",
        "            padding='max_length' if max_length else False, \n",
        "            truncation=True if max_length else False\n",
        "        )\n",
        "        sequence_length = len(encoding['input_ids'])\n",
        "        # 特殊トークン[CLS]に対するダミーのspanを追加。\n",
        "        spans = [[-1, -1]] + spans[:sequence_length-2] \n",
        "        # 特殊トークン[SEP]、[PAD]に対するダミーのspanを追加。\n",
        "        spans = spans + [[-1, -1]] * ( sequence_length - len(spans) ) \n",
        "\n",
        "        # 必要に応じてtorch.Tensorにする。\n",
        "        if return_tensors == 'pt':\n",
        "            encoding = { k: torch.tensor([v]) for k, v in encoding.items() }\n",
        "\n",
        "        return encoding, spans\n",
        "\n",
        "    def convert_bert_output_to_entities(self, text, labels, spans):\n",
        "        \"\"\"\n",
        "        文章、ラベル列の予測値、各トークンの位置から固有表現を得る。\n",
        "        \"\"\"\n",
        "        # labels, spansから特殊トークンに対応する部分を取り除く\n",
        "        labels = [label for label, span in zip(labels, spans) if span[0] != -1]\n",
        "        spans = [span for span in spans if span[0] != -1]\n",
        "\n",
        "        # 同じラベルが連続するトークンをまとめて、固有表現を抽出する。\n",
        "        entities = []\n",
        "        for label, group \\\n",
        "            in itertools.groupby(enumerate(labels), key=lambda x: x[1]):\n",
        "            \n",
        "            group = list(group)\n",
        "            start = spans[group[0][0]][0]\n",
        "            end = spans[group[-1][0]][1]\n",
        "\n",
        "            if label != 0: # ラベルが0以外ならば、新たな固有表現として追加。\n",
        "                entity = {\n",
        "                    \"name\": text[start:end],\n",
        "                    \"span\": [start, end],\n",
        "                    \"type_id\": label\n",
        "                }\n",
        "                entities.append(entity)\n",
        "\n",
        "        return entities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "90ddx0hdVpkv"
      },
      "outputs": [],
      "source": [
        "# 8-6 インスタンス化\n",
        "tokenizer = NER_tokenizer.from_pretrained(MODEL_NAME)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "etbsSKvMV6o6",
        "outputId": "53b7d199-76aa-4432-ecfa-7f9a6851a5f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_ids': [2, 10271, 28486, 5, 546, 10780, 2464, 13, 5, 1878, 2682, 9, 10750, 308, 10, 8, 3, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], 'labels': [0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n"
          ]
        }
      ],
      "source": [
        "# 8-7\n",
        "text = '昨日のみらい事務所との打ち合わせは順調だった。'\n",
        "entities = [\n",
        "    {'name': 'みらい事務所', 'span': [3,9], 'type_id': 1}\n",
        "]\n",
        "\n",
        "encoding = tokenizer.encode_plus_tagged(\n",
        "    text, entities, max_length=20\n",
        ")\n",
        "print(encoding)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ej-uZLmeZ6im",
        "outputId": "4f4c8615-9ff3-40d9-bf9c-33cc8e69cbdd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# encoding\n",
            "{'input_ids': tensor([[    2,     1, 26280,     5,  1543,   125,     9,  6749, 28550,  2953,\n",
            "         28550, 28566, 21202, 28683, 14050, 12475,    12,    31,     8,     3]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
            "# spans\n",
            "[[-1, -1], [0, 1], [1, 2], [2, 3], [3, 5], [5, 6], [6, 7], [7, 9], [9, 10], [10, 12], [12, 13], [13, 14], [15, 18], [18, 19], [19, 23], [24, 27], [27, 28], [28, 30], [30, 31], [-1, -1]]\n"
          ]
        }
      ],
      "source": [
        "# 8-8\n",
        "text = '騰訊の英語名はTencent Holdings Ltdである。'\n",
        "encoding, spans = tokenizer.encode_plus_untagged(\n",
        "    text, return_tensors='pt'\n",
        ")\n",
        "print('# encoding')\n",
        "print(encoding)\n",
        "print('# spans')\n",
        "print(spans)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4iNnFleXbYpG",
        "outputId": "c473ae97-0098-4cb1-e54c-add7670b3947"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'name': '騰訊', 'span': [0, 2], 'type_id': 1}, {'name': 'Tencent Holdings Ltd', 'span': [7, 27], 'type_id': 1}]\n"
          ]
        }
      ],
      "source": [
        "# 8-9\n",
        "labels_predicted = [0,1,1,0,0,0,0,1,1,1,1,1,1,1,1,1,0,0,0,0]\n",
        "entities = tokenizer.convert_bert_output_to_entities(\n",
        "    text, labels_predicted, spans\n",
        ")\n",
        "print(entities)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "htDDRhvOdpH2",
        "outputId": "0fabc443-3763-48e8-cff3-4238753667a4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at cl-tohoku/bert-base-japanese-whole-word-masking were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at cl-tohoku/bert-base-japanese-whole-word-masking and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "# 8-10\n",
        "tokenizer = NER_tokenizer.from_pretrained(MODEL_NAME)\n",
        "bert_tc = BertForTokenClassification.from_pretrained(\n",
        "    MODEL_NAME, num_labels=4\n",
        ")\n",
        "bert_tc = bert_tc.cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jq8CwzyReyS7",
        "outputId": "01f25ecd-0182-49b4-a91d-deef1de47dab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'name': 'A', 'span': [0, 1], 'type_id': 3}, {'name': 'さん', 'span': [1, 3], 'type_id': 2}, {'name': 'はB', 'span': [3, 5], 'type_id': 3}, {'name': '大学に入学した。', 'span': [5, 13], 'type_id': 2}]\n"
          ]
        }
      ],
      "source": [
        "# 8-11\n",
        "text = 'AさんはB大学に入学した。'\n",
        "\n",
        "# 符号化を行い、各トークンの文章中での位置も特定しておく。\n",
        "encoding, spans = tokenizer.encode_plus_untagged(\n",
        "    text, return_tensors='pt'\n",
        ") \n",
        "encoding = { k: v.cuda() for k, v in encoding.items() } \n",
        "\n",
        "# BERTでトークン毎の分類スコアを出力し、スコアの最も高いラベルを予測値とする。\n",
        "with torch.no_grad():\n",
        "    output = bert_tc(**encoding)\n",
        "    scores = output.logits\n",
        "    labels_predicted = scores[0].argmax(-1).cpu().numpy().tolist()\n",
        "\n",
        "# ラベル列を固有表現に変換\n",
        "entities = tokenizer.convert_bert_output_to_entities(\n",
        "    text, labels_predicted, spans\n",
        ")\n",
        "print(entities)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8c0NRQ5ag46o"
      },
      "outputs": [],
      "source": [
        "# 8-12\n",
        "data = [\n",
        "    {\n",
        "        'text': 'AさんはB大学に入学した。',\n",
        "        'entities': [\n",
        "            {'name': 'A', 'span': [0, 1], 'type_id': 2},\n",
        "            {'name': 'B大学', 'span': [4, 7], 'type_id': 1}\n",
        "        ]\n",
        "    },\n",
        "    {\n",
        "        'text': 'CDE株式会社は新製品「E」を販売する。',\n",
        "        'entities': [\n",
        "            {'name': 'CDE株式会社', 'span': [0, 7], 'type_id': 1},\n",
        "            {'name': 'E', 'span': [12, 13], 'type_id': 3}\n",
        "        ]\n",
        "    }\n",
        "]\n",
        "\n",
        "# 各データを符号化し、データローダを作成する。\n",
        "max_length=32\n",
        "dataset_for_loader = []\n",
        "for sample in data:\n",
        "    text = sample['text']\n",
        "    entities = sample['entities']\n",
        "    encoding = tokenizer.encode_plus_tagged(\n",
        "        text, entities, max_length=max_length\n",
        "    )\n",
        "    encoding = { k: torch.tensor(v) for k, v in encoding.items() }\n",
        "    dataset_for_loader.append(encoding)\n",
        "dataloader = DataLoader(dataset_for_loader, batch_size=len(data))\n",
        "\n",
        "# ミニバッチを取り出し損失を得る。\n",
        "for batch in dataloader:\n",
        "    batch = { k: v.cuda() for k, v in batch.items() } # GPU\n",
        "    output = bert_tc(**batch) # BERTへ入力\n",
        "    loss = output.loss # 損失"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FJ3DYIf5i62q",
        "outputId": "e95f83f8-9048-479e-9837-27f6a3dfb840"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fatal: destination path 'ner-wikipedia-dataset' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "# 8-13\n",
        "!git clone --branch v2.0 https://github.com/stockmarkteam/ner-wikipedia-dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nMTJUQJnjgli"
      },
      "source": [
        "curid:WikipediaのページID、\n",
        "text:文章、\n",
        "entities:文章に含まれる固有表現"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4AWfeQArjUNE"
      },
      "outputs": [],
      "source": [
        "# 8-14\n",
        "# データのロード\n",
        "dataset = json.load(open('ner-wikipedia-dataset/ner.json','r'))\n",
        "\n",
        "# 固有表現のタイプとIDを対応付る辞書 \n",
        "type_id_dict = {\n",
        "    \"人名\": 1,\n",
        "    \"法人名\": 2,\n",
        "    \"政治的組織名\": 3,\n",
        "    \"その他の組織名\": 4,\n",
        "    \"地名\": 5,\n",
        "    \"施設名\": 6,\n",
        "    \"製品名\": 7,\n",
        "    \"イベント名\": 8\n",
        "}\n",
        "\n",
        "# カテゴリーをラベルに変更、文字列の正規化する。\n",
        "for sample in dataset:\n",
        "    sample['text'] = unicodedata.normalize('NFKC', sample['text'])\n",
        "    for e in sample[\"entities\"]:\n",
        "        e['type_id'] = type_id_dict[e['type']]\n",
        "        del e['type']\n",
        "\n",
        "# データセットの分割\n",
        "random.shuffle(dataset)\n",
        "n = len(dataset)\n",
        "n_train = int(n*0.6)\n",
        "n_val = int(n*0.2)\n",
        "dataset_train = dataset[:n_train]\n",
        "dataset_val = dataset[n_train:n_train+n_val]\n",
        "dataset_test = dataset[n_train+n_val:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BY7vwY5olthZ"
      },
      "outputs": [],
      "source": [
        "# 8-15\n",
        "def create_dataset(tokenizer, dataset, max_length):\n",
        "    \"\"\"\n",
        "    データセットをデータローダに入力できる形に整形。\n",
        "    \"\"\"\n",
        "    dataset_for_loader = []\n",
        "    for sample in dataset:\n",
        "        text = sample['text']\n",
        "        entities = sample['entities']\n",
        "        encoding = tokenizer.encode_plus_tagged(\n",
        "            text, entities, max_length=max_length\n",
        "        )\n",
        "        encoding = { k: torch.tensor(v) for k, v in encoding.items() }\n",
        "        dataset_for_loader.append(encoding)\n",
        "    return dataset_for_loader\n",
        "\n",
        "# トークナイザのロード\n",
        "tokenizer = NER_tokenizer.from_pretrained(MODEL_NAME)\n",
        "\n",
        "# データセットの作成\n",
        "max_length = 128\n",
        "dataset_train_for_loader = create_dataset(\n",
        "    tokenizer, dataset_train, max_length\n",
        ")\n",
        "dataset_val_for_loader = create_dataset(\n",
        "    tokenizer, dataset_val, max_length\n",
        ")\n",
        "\n",
        "# データローダの作成\n",
        "dataloader_train = DataLoader(\n",
        "    dataset_train_for_loader, batch_size=32, shuffle=True\n",
        ")\n",
        "dataloader_val = DataLoader(dataset_val_for_loader, batch_size=256)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 767,
          "referenced_widgets": [
            "5aaadcbba4f143bfa33b333504fac34b",
            "cb003b0d92484f16bd176e1b34f59c4b",
            "27990b14f3a549be971cb51c73f7d655",
            "f784f176c05e422b8f6b90e5e27d3f5c",
            "fe2cf5c5b1a54895a201d05c1eb1e814",
            "25a0eec9003b410eba68beb109400909",
            "dab8974a93d14414960393fd0190e943",
            "f08b9bda96284afc8266d0b870163acd",
            "793d3b02993c42be8d77e08fe51455d3",
            "2e78654ff9e34ec095f8b5b4894c5739",
            "daf4cc31e2684f218edad2945674bd10"
          ]
        },
        "id": "4RrV-zTdmF_D",
        "outputId": "187e010e-9c4f-4e07-dac1-5f5bf3a4fb61"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: Checkpoint directory model/ exists and is not empty.\n",
            "  warnings.warn(*args, **kwargs)\n",
            "GPU available: True, used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "Some weights of the model checkpoint at cl-tohoku/bert-base-japanese-whole-word-masking were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at cl-tohoku/bert-base-japanese-whole-word-masking and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\n",
            "  | Name    | Type                       | Params\n",
            "-------------------------------------------------------\n",
            "0 | bert_tc | BertForTokenClassification | 110 M \n",
            "-------------------------------------------------------\n",
            "110 M     Trainable params\n",
            "0         Non-trainable params\n",
            "110 M     Total params\n",
            "440.135   Total estimated model params size (MB)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5aaadcbba4f143bfa33b333504fac34b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation sanity check: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "ename": "RuntimeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-af0b0c752ad8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0mMODEL_NAME\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m )\n\u001b[0;32m---> 45\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0mbest_model_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_model_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, train_dataloader, val_dataloaders, datamodule)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m         \u001b[0;31m# dispath `start_training` or `start_testing` or `start_predicting`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 499\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m         \u001b[0;31m# plugin will finalized fitting (e.g. ddp_spawn will load trained model)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mdispatch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    544\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 546\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    547\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain_or_test_or_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/accelerators/accelerator.py\u001b[0m in \u001b[0;36mstart_training\u001b[0;34m(self, trainer)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstart_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_type_plugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstart_testing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\u001b[0m in \u001b[0;36mstart_training\u001b[0;34m(self, trainer)\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstart_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'Trainer'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0;31m# double dispatch to initiate the training loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstart_testing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'Trainer'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mrun_train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    605\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogress_bar_callback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 607\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_sanity_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlightning_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    608\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m         \u001b[0;31m# set stage for logging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mrun_sanity_check\u001b[0;34m(self, ref_model)\u001b[0m\n\u001b[1;32m    862\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m             \u001b[0;31m# run eval step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 864\u001b[0;31m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_evaluation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_batches\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_sanity_val_batches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    865\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    866\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_sanity_check_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mrun_evaluation\u001b[0;34m(self, max_batches, on_epoch)\u001b[0m\n\u001b[1;32m    724\u001b[0m                 \u001b[0;31m# lightning module methods\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    725\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"evaluation_step_and_end\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 726\u001b[0;31m                     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    727\u001b[0m                     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation_step_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/evaluation_loop.py\u001b[0m in \u001b[0;36mevaluation_step\u001b[0;34m(self, batch, batch_idx, dataloader_idx)\u001b[0m\n\u001b[1;32m    164\u001b[0m             \u001b[0mmodel_ref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_current_fx_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"validation_step\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"validation_step\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidation_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;31m# capture any logged information\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/accelerators/accelerator.py\u001b[0m in \u001b[0;36mvalidation_step\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    170\u001b[0m                     \u001b[0;34m(\u001b[0m\u001b[0monly\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mmultiple\u001b[0m \u001b[0mval\u001b[0m \u001b[0mdataloaders\u001b[0m \u001b[0mused\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m         \"\"\"\n\u001b[0;32m--> 172\u001b[0;31m         \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/accelerators/gpu.py\u001b[0m in \u001b[0;36mto_device\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;31m# TODO: Add support to allow batch transfer to device in Lightning for DP mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_type_plugin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataParallelPlugin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/accelerators/accelerator.py\u001b[0m in \u001b[0;36mto_device\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    336\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mto_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m         \u001b[0;34m\"\"\"Pushes the batch to the root device\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 338\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_to_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/accelerators/accelerator.py\u001b[0m in \u001b[0;36mbatch_to_device\u001b[0;34m(self, batch, device)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_batch_transfer_handler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmove_data_to_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/core/lightning.py\u001b[0m in \u001b[0;36m_apply_batch_transfer_handler\u001b[0;34m(self, batch, device, dataloader_idx)\u001b[0m\n\u001b[1;32m    184\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply_batch_transfer_handler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader_idx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_before_batch_transfer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m         \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransfer_batch_to_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m         \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_after_batch_transfer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/core/hooks.py\u001b[0m in \u001b[0;36mtransfer_batch_to_device\u001b[0;34m(self, batch, device)\u001b[0m\n\u001b[1;32m    645\u001b[0m         \"\"\"\n\u001b[1;32m    646\u001b[0m         \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 647\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmove_data_to_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    648\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    649\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_before_batch_transfer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/apply_func.py\u001b[0m in \u001b[0;36mmove_data_to_device\u001b[0;34m(batch, device)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTransferableDataType\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBatch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m_TORCHTEXT_AVAILABLE\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mTransferableDataType\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mapply_to_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_to\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/apply_func.py\u001b[0m in \u001b[0;36mapply_to_collection\u001b[0;34m(data, dtype, function, wrong_dtype, *args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;31m# Recursively apply to collection items\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mapply_to_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_fields'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# named tuple\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/apply_func.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;31m# Recursively apply to collection items\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mapply_to_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_fields'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# named tuple\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/apply_func.py\u001b[0m in \u001b[0;36mapply_to_collection\u001b[0;34m(data, dtype, function, wrong_dtype, *args, **kwargs)\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0;31m# Breaking condition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mwrong_dtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrong_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;31m# Recursively apply to collection items\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/apply_func.py\u001b[0m in \u001b[0;36mbatch_to\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnon_blocking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTransferableDataType\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBatch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m_TORCHTEXT_AVAILABLE\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mTransferableDataType\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
          ]
        }
      ],
      "source": [
        "# 8-16 PyTorch Lightningでファインチューニング\n",
        "# PyTorch Lightningのモデル\n",
        "class BertForTokenClassification_pl(pl.LightningModule):\n",
        "        \n",
        "    def __init__(self, model_name, num_labels, lr):\n",
        "        super().__init__()\n",
        "        self.save_hyperparameters()\n",
        "        self.bert_tc = BertForTokenClassification.from_pretrained(\n",
        "            model_name,\n",
        "            num_labels=num_labels\n",
        "        )\n",
        "        \n",
        "    def training_step(self, batch, batch_idx):\n",
        "        output = self.bert_tc(**batch)\n",
        "        loss = output.loss\n",
        "        self.log('train_loss', loss)\n",
        "        return loss\n",
        "        \n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        output = self.bert_tc(**batch)\n",
        "        val_loss = output.loss\n",
        "        self.log('val_loss', val_loss)\n",
        "        \n",
        "    def configure_optimizers(self):\n",
        "        return torch.optim.Adam(self.parameters(), lr=self.hparams.lr)\n",
        "\n",
        "checkpoint = pl.callbacks.ModelCheckpoint(\n",
        "    monitor='val_loss',\n",
        "    mode='min',\n",
        "    save_top_k=1,\n",
        "    save_weights_only=True,\n",
        "    dirpath='model/'\n",
        ")\n",
        "\n",
        "trainer = pl.Trainer(\n",
        "    gpus=1,\n",
        "    max_epochs=5,\n",
        "    callbacks=[checkpoint]\n",
        ")\n",
        "\n",
        "# ファインチューニング\n",
        "model = BertForTokenClassification_pl(\n",
        "    MODEL_NAME, num_labels=9, lr=1e-5\n",
        ")\n",
        "trainer.fit(model, dataloader_train, dataloader_val)\n",
        "best_model_path = checkpoint.best_model_path"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4lrqqUiemdFR"
      },
      "source": [
        "## 固有表現抽出の性能評価\n",
        "```\n",
        "・適合率（予測が正解だったものの割合）\n",
        "・再現率（モデルが正しく抽出できた固有表現の割合）\n",
        "・F 値（適合率と再現率の調和平均）\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s66G2UCHmK27",
        "outputId": "a068f987-f6e1-4da3-fd20-4d5acb8939c9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at cl-tohoku/bert-base-japanese-whole-word-masking were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at cl-tohoku/bert-base-japanese-whole-word-masking and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "100%|██████████| 1070/1070 [00:13<00:00, 79.08it/s]\n"
          ]
        }
      ],
      "source": [
        "# 8-17\n",
        "def predict(text, tokenizer, bert_tc):\n",
        "    \"\"\"\n",
        "    BERTで固有表現抽出を行うための関数。\n",
        "    \"\"\"\n",
        "    # 符号化\n",
        "    encoding, spans = tokenizer.encode_plus_untagged(\n",
        "        text, return_tensors='pt'\n",
        "    )\n",
        "    encoding = { k: v.cuda() for k, v in encoding.items() }\n",
        "\n",
        "    # ラベルの予測値の計算\n",
        "    with torch.no_grad():\n",
        "        output = bert_tc(**encoding)\n",
        "        scores = output.logits\n",
        "        labels_predicted = scores[0].argmax(-1).cpu().numpy().tolist() \n",
        "\n",
        "    # ラベル列を固有表現に変換\n",
        "    entities = tokenizer.convert_bert_output_to_entities(\n",
        "        text, labels_predicted, spans\n",
        "    )\n",
        "\n",
        "    return entities\n",
        "\n",
        "# トークナイザのロード\n",
        "tokenizer = NER_tokenizer.from_pretrained(MODEL_NAME)\n",
        "\n",
        "# ファインチューニングしたモデルをロードし、GPUにのせる。\n",
        "model = BertForTokenClassification_pl.load_from_checkpoint(\n",
        "    best_model_path\n",
        ")\n",
        "bert_tc = model.bert_tc.cuda()\n",
        "\n",
        "# 固有表現抽出\n",
        "# 注：以下ではコードのわかりやすさのために、1データづつ処理しているが、\n",
        "# バッチ化して処理を行った方が処理時間は短い\n",
        "entities_list = [] # 正解の固有表現を追加していく。\n",
        "entities_predicted_list = [] # 抽出された固有表現を追加していく。\n",
        "for sample in tqdm(dataset_test):\n",
        "    text = sample['text']\n",
        "    entities_predicted = predict(text, tokenizer, bert_tc) # BERTで予測\n",
        "    entities_list.append(sample['entities'])\n",
        "    entities_predicted_list.append( entities_predicted )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D6RGeJ_Ho7-e",
        "outputId": "01e805f4-49e9-4798-b0a1-dfb0d6001b2f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# 正解\n",
            "[]\n",
            "# 抽出\n",
            "[]\n"
          ]
        }
      ],
      "source": [
        "# 8-18\n",
        "print(\"# 正解\")\n",
        "print(entities_list[0])\n",
        "print(\"# 抽出\")\n",
        "print(entities_predicted_list[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZxJ7mWaqo_Cb"
      },
      "outputs": [],
      "source": [
        "# 8-19\n",
        "def evaluate_model(entities_list, entities_predicted_list, type_id=None):\n",
        "    \"\"\"\n",
        "    正解と予測を比較し、モデルの固有表現抽出の性能を評価する。\n",
        "    type_idがNoneのときは、全ての固有表現のタイプに対して評価する。\n",
        "    type_idが整数を指定すると、その固有表現のタイプのIDに対して評価を行う。\n",
        "    \"\"\"\n",
        "    num_entities = 0 # 固有表現(正解)の個数\n",
        "    num_predictions = 0 # BERTにより予測された固有表現の個数\n",
        "    num_correct = 0 # BERTにより予測のうち正解であった固有表現の数\n",
        "\n",
        "    # それぞれの文章で予測と正解を比較。\n",
        "    # 予測は文章中の位置とタイプIDが一致すれば正解とみなす。\n",
        "    for entities, entities_predicted \\\n",
        "        in zip(entities_list, entities_predicted_list):\n",
        "\n",
        "        if type_id:\n",
        "            entities = [ e for e in entities if e['type_id'] == type_id ]\n",
        "            entities_predicted = [ \n",
        "                e for e in entities_predicted if e['type_id'] == type_id\n",
        "            ]\n",
        "            \n",
        "        get_span_type = lambda e: (e['span'][0], e['span'][1], e['type_id'])\n",
        "        set_entities = set( get_span_type(e) for e in entities )\n",
        "        set_entities_predicted = \\\n",
        "            set( get_span_type(e) for e in entities_predicted )\n",
        "\n",
        "        num_entities += len(entities)\n",
        "        num_predictions += len(entities_predicted)\n",
        "        num_correct += len( set_entities & set_entities_predicted )\n",
        "\n",
        "    # 指標を計算\n",
        "    precision = num_correct/num_predictions # 適合率\n",
        "    recall = num_correct/num_entities # 再現率\n",
        "    f_value = 2*precision*recall/(precision+recall) # F値\n",
        "\n",
        "    result = {\n",
        "        'num_entities': num_entities,\n",
        "        'num_predictions': num_predictions,\n",
        "        'num_correct': num_correct,\n",
        "        'precision': precision,\n",
        "        'recall': recall,\n",
        "        'f_value': f_value\n",
        "    }\n",
        "\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RJNGN-O2pBla",
        "outputId": "1410bba8-9c3a-4e8e-c18f-a80f39138c02"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'num_entities': 2631, 'num_predictions': 2701, 'num_correct': 2293, 'precision': 0.8489448352462051, 'recall': 0.871531736982136, 'f_value': 0.8600900225056263}\n"
          ]
        }
      ],
      "source": [
        "# 8-20\n",
        "print( evaluate_model(entities_list, entities_predicted_list) )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dBJFiehdrM-Z"
      },
      "source": [
        "# BIO法（Viterbiアルゴリズムによって最適なラベル列を効率的に選べる）"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RISICxVKpDl4"
      },
      "outputs": [],
      "source": [
        "# 8-21\n",
        "class NER_tokenizer_BIO(BertJapaneseTokenizer):\n",
        "\n",
        "    # 初期化時に固有表現のカテゴリーの数`num_entity_type`を\n",
        "    # 受け入れるようにする。\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        self.num_entity_type = kwargs.pop('num_entity_type')\n",
        "        super().__init__(*args, **kwargs)\n",
        "\n",
        "    def encode_plus_tagged(self, text, entities, max_length):\n",
        "        \"\"\"\n",
        "        文章とそれに含まれる固有表現が与えられた時に、\n",
        "        符号化とラベル列の作成を行う。\n",
        "        \"\"\"\n",
        "        # 固有表現の前後でtextを分割し、それぞれのラベルをつけておく。\n",
        "        splitted = [] # 分割後の文字列を追加していく\n",
        "        position = 0\n",
        "        for entity in entities:\n",
        "            start = entity['span'][0]\n",
        "            end = entity['span'][1]\n",
        "            label = entity['type_id']\n",
        "            splitted.append({'text':text[position:start], 'label':0})\n",
        "            splitted.append({'text':text[start:end], 'label':label})\n",
        "            position = end\n",
        "        splitted.append({'text': text[position:], 'label':0})\n",
        "        splitted = [ s for s in splitted if s['text'] ]\n",
        "\n",
        "        # 分割されたそれぞれの文章をトークン化し、ラベルをつける。\n",
        "        tokens = [] # トークンを追加していく\n",
        "        labels = [] # ラベルを追加していく\n",
        "        for s in splitted:\n",
        "            tokens_splitted = self.tokenize(s['text'])\n",
        "            label = s['label']\n",
        "            if label > 0: # 固有表現\n",
        "                # まずトークン全てにI-タグを付与\n",
        "                labels_splitted =  \\\n",
        "                    [ label + self.num_entity_type ] * len(tokens_splitted)\n",
        "                # 先頭のトークンをB-タグにする\n",
        "                labels_splitted[0] = label\n",
        "            else: # それ以外\n",
        "                labels_splitted =  [0] * len(tokens_splitted)\n",
        "            \n",
        "            tokens.extend(tokens_splitted)\n",
        "            labels.extend(labels_splitted)\n",
        "\n",
        "        # 符号化を行いBERTに入力できる形式にする。\n",
        "        input_ids = self.convert_tokens_to_ids(tokens)\n",
        "        encoding = self.prepare_for_model(\n",
        "            input_ids, \n",
        "            max_length=max_length, \n",
        "            padding='max_length',\n",
        "            truncation=True\n",
        "        ) \n",
        "\n",
        "        # ラベルに特殊トークンを追加\n",
        "        labels = [0] + labels[:max_length-2] + [0]\n",
        "        labels = labels + [0]*( max_length - len(labels) )\n",
        "        encoding['labels'] = labels\n",
        "\n",
        "        return encoding\n",
        "\n",
        "    def encode_plus_untagged(\n",
        "        self, text, max_length=None, return_tensors=None\n",
        "    ):\n",
        "        \"\"\"\n",
        "        文章をトークン化し、それぞれのトークンの文章中の位置も特定しておく。\n",
        "        IO法のトークナイザのencode_plus_untaggedと同じ\n",
        "        \"\"\"\n",
        "        # 文章のトークン化を行い、\n",
        "        # それぞれのトークンと文章中の文字列を対応づける。\n",
        "        tokens = [] # トークンを追加していく。\n",
        "        tokens_original = [] # トークンに対応する文章中の文字列を追加していく。\n",
        "        words = self.word_tokenizer.tokenize(text) # MeCabで単語に分割\n",
        "        for word in words:\n",
        "            # 単語をサブワードに分割\n",
        "            tokens_word = self.subword_tokenizer.tokenize(word) \n",
        "            tokens.extend(tokens_word)\n",
        "            if tokens_word[0] == '[UNK]': # 未知語への対応\n",
        "                tokens_original.append(word)\n",
        "            else:\n",
        "                tokens_original.extend([\n",
        "                    token.replace('##','') for token in tokens_word\n",
        "                ])\n",
        "\n",
        "        # 各トークンの文章中での位置を調べる。（空白の位置を考慮する）\n",
        "        position = 0\n",
        "        spans = [] # トークンの位置を追加していく。\n",
        "        for token in tokens_original:\n",
        "            l = len(token)\n",
        "            while 1:\n",
        "                if token != text[position:position+l]:\n",
        "                    position += 1\n",
        "                else:\n",
        "                    spans.append([position, position+l])\n",
        "                    position += l\n",
        "                    break\n",
        "\n",
        "        # 符号化を行いBERTに入力できる形式にする。\n",
        "        input_ids = self.convert_tokens_to_ids(tokens) \n",
        "        encoding = self.prepare_for_model(\n",
        "            input_ids, \n",
        "            max_length=max_length, \n",
        "            padding='max_length' if max_length else False, \n",
        "            truncation=True if max_length else False\n",
        "        )\n",
        "        sequence_length = len(encoding['input_ids'])\n",
        "        # 特殊トークン[CLS]に対するダミーのspanを追加。\n",
        "        spans = [[-1, -1]] + spans[:sequence_length-2] \n",
        "        # 特殊トークン[SEP]、[PAD]に対するダミーのspanを追加。\n",
        "        spans = spans + [[-1, -1]] * ( sequence_length - len(spans) ) \n",
        "\n",
        "        # 必要に応じてtorch.Tensorにする。\n",
        "        if return_tensors == 'pt':\n",
        "            encoding = { k: torch.tensor([v]) for k, v in encoding.items() }\n",
        "\n",
        "        return encoding, spans\n",
        "\n",
        "    @staticmethod\n",
        "    def Viterbi(scores_bert, num_entity_type, penalty=10000):\n",
        "        \"\"\"\n",
        "        Viterbiアルゴリズムで最適解を求める。\n",
        "        \"\"\"\n",
        "        m = 2*num_entity_type + 1\n",
        "        penalty_matrix = np.zeros([m, m])\n",
        "        for i in range(m):\n",
        "            for j in range(1+num_entity_type, m):\n",
        "                if not ( (i == j) or (i+num_entity_type == j) ): \n",
        "                    penalty_matrix[i,j] = penalty\n",
        "        \n",
        "        path = [ [i] for i in range(m) ]\n",
        "        scores_path = scores_bert[0] - penalty_matrix[0,:]\n",
        "        scores_bert = scores_bert[1:]\n",
        "\n",
        "        for scores in scores_bert:\n",
        "            assert len(scores) == 2*num_entity_type + 1\n",
        "            score_matrix = np.array(scores_path).reshape(-1,1) \\\n",
        "                + np.array(scores).reshape(1,-1) \\\n",
        "                - penalty_matrix\n",
        "            scores_path = score_matrix.max(axis=0)\n",
        "            argmax = score_matrix.argmax(axis=0)\n",
        "            path_new = []\n",
        "            for i, idx in enumerate(argmax):\n",
        "                path_new.append( path[idx] + [i] )\n",
        "            path = path_new\n",
        "\n",
        "        labels_optimal = path[np.argmax(scores_path)]\n",
        "        return labels_optimal\n",
        "\n",
        "    def convert_bert_output_to_entities(self, text, scores, spans):\n",
        "        \"\"\"\n",
        "        文章、分類スコア、各トークンの位置から固有表現を得る。\n",
        "        分類スコアはサイズが（系列長、ラベル数）の2次元配列\n",
        "        \"\"\"\n",
        "        assert len(spans) == len(scores)\n",
        "        num_entity_type = self.num_entity_type\n",
        "        \n",
        "        # 特殊トークンに対応する部分を取り除く\n",
        "        scores = [score for score, span in zip(scores, spans) if span[0]!=-1]\n",
        "        spans = [span for span in spans if span[0]!=-1]\n",
        "\n",
        "        # Viterbiアルゴリズムでラベルの予測値を決める。\n",
        "        labels = self.Viterbi(scores, num_entity_type)\n",
        "\n",
        "        # 同じラベルが連続するトークンをまとめて、固有表現を抽出する。\n",
        "        entities = []\n",
        "        for label, group \\\n",
        "            in itertools.groupby(enumerate(labels), key=lambda x: x[1]):\n",
        "            \n",
        "            group = list(group)\n",
        "            start = spans[group[0][0]][0]\n",
        "            end = spans[group[-1][0]][1]\n",
        "\n",
        "            if label != 0: # 固有表現であれば\n",
        "                if 1 <= label <= num_entity_type:\n",
        "                     # ラベルが`B-`ならば、新しいentityを追加\n",
        "                    entity = {\n",
        "                        \"name\": text[start:end],\n",
        "                        \"span\": [start, end],\n",
        "                        \"type_id\": label\n",
        "                    }\n",
        "                    entities.append(entity)\n",
        "                else:\n",
        "                    # ラベルが`I-`ならば、直近のentityを更新\n",
        "                    entity['span'][1] = end \n",
        "                    entity['name'] = text[entity['span'][0]:entity['span'][1]]\n",
        "                return entities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c-eU4fsGpMiZ"
      },
      "outputs": [],
      "source": [
        "# 8-22\n",
        "# トークナイザのロード\n",
        "# 固有表現のカテゴリーの数`num_entity_type`を入力に入れる必要がある。\n",
        "tokenizer = NER_tokenizer_BIO.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    num_entity_type=8 \n",
        ")\n",
        "\n",
        "# データセットの作成\n",
        "max_length = 128\n",
        "dataset_train_for_loader = create_dataset(\n",
        "    tokenizer, dataset_train, max_length\n",
        ")\n",
        "dataset_val_for_loader = create_dataset(\n",
        "    tokenizer, dataset_val, max_length\n",
        ")\n",
        "\n",
        "# データローダの作成\n",
        "dataloader_train = DataLoader(\n",
        "    dataset_train_for_loader, batch_size=32, shuffle=True\n",
        ")\n",
        "dataloader_val = DataLoader(dataset_val_for_loader, batch_size=256)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 599
        },
        "id": "5YrdFBr0pNM-",
        "outputId": "b2f9f9eb-77da-4377-9682-38544cddd9a9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: Checkpoint directory model_BIO/ exists and is not empty.\n",
            "  warnings.warn(*args, **kwargs)\n",
            "GPU available: True, used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "Some weights of the model checkpoint at cl-tohoku/bert-base-japanese-whole-word-masking were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at cl-tohoku/bert-base-japanese-whole-word-masking and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-043f65b54183>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m# ファインチューニング\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0mbest_model_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_model_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, train_dataloader, val_dataloaders, datamodule)\u001b[0m\n\u001b[1;32m    458\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_setup_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"on_before_accelerator_backend_setup\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 460\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# note: this sets up self.lightning_module\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m         \u001b[0;31m# ----------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/accelerators/gpu.py\u001b[0m in \u001b[0;36msetup\u001b[0;34m(self, trainer, model)\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_nvidia_flags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_train_start\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/accelerators/accelerator.py\u001b[0m in \u001b[0;36msetup\u001b[0;34m(self, trainer, model)\u001b[0m\n\u001b[1;32m     66\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0mto\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \"\"\"\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect_training_type_plugin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_type_plugin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup_optimizers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect_precision_plugin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprecision_plugin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/accelerators/accelerator.py\u001b[0m in \u001b[0;36mconnect_training_type_plugin\u001b[0;34m(self, plugin, model)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m         \"\"\"\n\u001b[0;32m--> 327\u001b[0;31m         \u001b[0mplugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mconnect_precision_plugin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplugin\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mPrecisionPlugin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/plugins/training_type/single_device.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_to_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/plugins/training_type/single_device.py\u001b[0m in \u001b[0;36mmodel_to_device\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/core/decorators.py\u001b[0m in \u001b[0;36minner_fn\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minner_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0mpre_layer_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_post_move_to_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0mpost_layer_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/device_dtype_mixin.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__update_properties\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    850\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    851\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 852\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    853\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m     def register_backward_hook(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    528\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    528\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    528\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    528\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    550\u001b[0m                 \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m                     \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    553\u001b[0m                 \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    848\u001b[0m                 return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None,\n\u001b[1;32m    849\u001b[0m                             non_blocking, memory_format=convert_to_format)\n\u001b[0;32m--> 850\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    851\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    852\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
          ]
        }
      ],
      "source": [
        "# 8-23\n",
        "\n",
        "# ファインチューニング\n",
        "checkpoint = pl.callbacks.ModelCheckpoint(\n",
        "    monitor='val_loss',\n",
        "    mode='min',\n",
        "    save_top_k=1,\n",
        "    save_weights_only=True,\n",
        "    dirpath='model_BIO/'\n",
        ")\n",
        "\n",
        "trainer = pl.Trainer(\n",
        "    gpus=1,\n",
        "    max_epochs=5,\n",
        "    callbacks=[checkpoint]\n",
        ")\n",
        "\n",
        "# PyTorch Lightningのモデルのロード\n",
        "num_entity_type = 8\n",
        "num_labels = 2*num_entity_type+1\n",
        "model = BertForTokenClassification_pl(\n",
        "    MODEL_NAME, num_labels=num_labels, lr=1e-5\n",
        ")\n",
        "\n",
        "# ファインチューニング\n",
        "trainer.fit(model, dataloader_train, dataloader_val)\n",
        "best_model_path = checkpoint.best_model_path\n",
        "\n",
        "# 性能評価\n",
        "model = BertForTokenClassification_pl.load_from_checkpoint(\n",
        "    best_model_path\n",
        ") \n",
        "bert_tc = model.bert_tc.cuda()\n",
        "\n",
        "entities_list = [] # 正解の固有表現を追加していく\n",
        "entities_predicted_list = [] # 抽出された固有表現を追加していく\n",
        "for sample in tqdm(dataset_test):\n",
        "    text = sample['text']\n",
        "    encoding, spans = tokenizer.encode_plus_untagged(\n",
        "        text, return_tensors='pt'\n",
        "    )\n",
        "    encoding = { k: v.cuda() for k, v in encoding.items() } \n",
        "    \n",
        "    with torch.no_grad():\n",
        "        output = bert_tc(**encoding)\n",
        "        scores = output.logits\n",
        "        scores = scores[0].cpu().numpy().tolist()\n",
        "        \n",
        "    # 分類スコアを固有表現に変換する\n",
        "    entities_predicted = tokenizer.convert_bert_output_to_entities(\n",
        "        text, scores, spans\n",
        "    )\n",
        "\n",
        "    entities_list.append(sample['entities'])\n",
        "    entities_predicted_list.append( entities_predicted )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LirEL6QopPcu"
      },
      "outputs": [],
      "source": [
        "print(evaluate_model(entities_list, entities_predicted_list))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R6JvzCjGuvk0"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "第8章＿固有表現抽出.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM/v/QVZGNnVWtVarxq/lah",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "25a0eec9003b410eba68beb109400909": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "27990b14f3a549be971cb51c73f7d655": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f08b9bda96284afc8266d0b870163acd",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_793d3b02993c42be8d77e08fe51455d3",
            "value": 0
          }
        },
        "2e78654ff9e34ec095f8b5b4894c5739": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5aaadcbba4f143bfa33b333504fac34b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cb003b0d92484f16bd176e1b34f59c4b",
              "IPY_MODEL_27990b14f3a549be971cb51c73f7d655",
              "IPY_MODEL_f784f176c05e422b8f6b90e5e27d3f5c"
            ],
            "layout": "IPY_MODEL_fe2cf5c5b1a54895a201d05c1eb1e814"
          }
        },
        "793d3b02993c42be8d77e08fe51455d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cb003b0d92484f16bd176e1b34f59c4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_25a0eec9003b410eba68beb109400909",
            "placeholder": "​",
            "style": "IPY_MODEL_dab8974a93d14414960393fd0190e943",
            "value": "Validation sanity check:   0%"
          }
        },
        "dab8974a93d14414960393fd0190e943": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "daf4cc31e2684f218edad2945674bd10": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f08b9bda96284afc8266d0b870163acd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f784f176c05e422b8f6b90e5e27d3f5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2e78654ff9e34ec095f8b5b4894c5739",
            "placeholder": "​",
            "style": "IPY_MODEL_daf4cc31e2684f218edad2945674bd10",
            "value": " 0/2 [00:00&lt;?, ?it/s]"
          }
        },
        "fe2cf5c5b1a54895a201d05c1eb1e814": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}