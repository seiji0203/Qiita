{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.3"
    },
    "colab": {
      "name": "RNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/seiji0203/Machine-Learning-Models/blob/master/RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8cNl2QA_Rnv5"
      },
      "source": [
        "# 準備"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YkwjN1jNVAYy"
      },
      "source": [
        "## Googleドライブのマウント"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pvFXpiH3EVC1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea2d6e29-c348-4365-decc-75ec19b97c9d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Ub7RYdeY6pK"
      },
      "source": [
        "## sys.pathの設定"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Ic2JzkvFX59"
      },
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/My Drive/DNN_code')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pzGmsHRwO-bi"
      },
      "source": [
        "# simple RNN after\n",
        "### バイナリ加算"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "KNSG0aKXO-bk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "182be017-fef5-43cd-d454-68f6e6345c29"
      },
      "source": [
        "import numpy as np\n",
        "from common import functions\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def d_tanh(x):\n",
        "    return 1/(np.cosh(x) ** 2)\n",
        "\n",
        "# データを用意\n",
        "# 2進数の桁数\n",
        "binary_dim = 8\n",
        "# 最大値 + 1\n",
        "largest_number = pow(2, binary_dim)\n",
        "# largest_numberまで2進数を用意\n",
        "binary = np.unpackbits(np.array([range(largest_number)],dtype=np.uint8).T,axis=1)\n",
        "\n",
        "input_layer_size = 2\n",
        "hidden_layer_size = 16\n",
        "output_layer_size = 1\n",
        "\n",
        "weight_init_std = 1\n",
        "learning_rate = 0.1\n",
        "\n",
        "iters_num = 10000\n",
        "plot_interval = 100\n",
        "\n",
        "# ウェイト初期化 (バイアスは簡単のため省略)\n",
        "W_in = weight_init_std * np.random.randn(input_layer_size, hidden_layer_size)\n",
        "W_out = weight_init_std * np.random.randn(hidden_layer_size, output_layer_size)\n",
        "W = weight_init_std * np.random.randn(hidden_layer_size, hidden_layer_size)\n",
        "# Xavier\n",
        "# W_in = np.random.randn(input_layer_size, hidden_layer_size) / (np.sqrt(input_layer_size))\n",
        "# W_out = np.random.randn(hidden_layer_size, output_layer_size) / (np.sqrt(hidden_layer_size))\n",
        "# W = np.random.randn(hidden_layer_size, hidden_layer_size) / (np.sqrt(hidden_layer_size))\n",
        "# He\n",
        "# W_in = np.random.randn(input_layer_size, hidden_layer_size) / (np.sqrt(input_layer_size)) * np.sqrt(2)\n",
        "# W_out = np.random.randn(hidden_layer_size, output_layer_size) / (np.sqrt(hidden_layer_size)) * np.sqrt(2)\n",
        "# W = np.random.randn(hidden_layer_size, hidden_layer_size) / (np.sqrt(hidden_layer_size)) * np.sqrt(2)\n",
        "\n",
        "\n",
        "# 勾配\n",
        "W_in_grad = np.zeros_like(W_in)\n",
        "W_out_grad = np.zeros_like(W_out)\n",
        "W_grad = np.zeros_like(W)\n",
        "\n",
        "u = np.zeros((hidden_layer_size, binary_dim + 1))\n",
        "z = np.zeros((hidden_layer_size, binary_dim + 1))\n",
        "y = np.zeros((output_layer_size, binary_dim))\n",
        "\n",
        "delta_out = np.zeros((output_layer_size, binary_dim))\n",
        "delta = np.zeros((hidden_layer_size, binary_dim + 1))\n",
        "\n",
        "all_losses = []\n",
        "\n",
        "for i in range(iters_num):\n",
        "    \n",
        "    # A, B初期化 (a + b = d)\n",
        "    a_int = np.random.randint(largest_number/2)\n",
        "    a_bin = binary[a_int] # binary encoding\n",
        "    b_int = np.random.randint(largest_number/2)\n",
        "    b_bin = binary[b_int] # binary encoding\n",
        "    \n",
        "    # 正解データ\n",
        "    d_int = a_int + b_int\n",
        "    d_bin = binary[d_int]\n",
        "    \n",
        "    # 出力バイナリ\n",
        "    out_bin = np.zeros_like(d_bin)\n",
        "    \n",
        "    # 時系列全体の誤差\n",
        "    all_loss = 0    \n",
        "    \n",
        "    # 時系列ループ\n",
        "    for t in range(binary_dim):\n",
        "        # 入力値\n",
        "        X = np.array([a_bin[ - t - 1], b_bin[ - t - 1]]).reshape(1, -1)\n",
        "        # 時刻tにおける正解データ\n",
        "        dd = np.array([d_bin[binary_dim - t - 1]])\n",
        "        \n",
        "        u[:,t+1] = np.dot(X, W_in) + np.dot(z[:,t].reshape(1, -1), W)\n",
        "        z[:,t+1] = functions.sigmoid(u[:,t+1])\n",
        "#         z[:,t+1] = functions.relu(u[:,t+1])\n",
        "#         z[:,t+1] = np.tanh(u[:,t+1])    \n",
        "        y[:,t] = functions.sigmoid(np.dot(z[:,t+1].reshape(1, -1), W_out))\n",
        "\n",
        "\n",
        "        #誤差\n",
        "        loss = functions.mean_squared_error(dd, y[:,t])\n",
        "        \n",
        "        delta_out[:,t] = functions.d_mean_squared_error(dd, y[:,t]) * functions.d_sigmoid(y[:,t])        \n",
        "        \n",
        "        all_loss += loss\n",
        "\n",
        "        out_bin[binary_dim - t - 1] = np.round(y[:,t])\n",
        "    \n",
        "    \n",
        "    for t in range(binary_dim)[::-1]:\n",
        "        X = np.array([a_bin[-t-1],b_bin[-t-1]]).reshape(1, -1)        \n",
        "\n",
        "        delta[:,t] = (np.dot(delta[:,t+1].T, W.T) + np.dot(delta_out[:,t].T, W_out.T)) * functions.d_sigmoid(u[:,t+1])\n",
        "#         delta[:,t] = (np.dot(delta[:,t+1].T, W.T) + np.dot(delta_out[:,t].T, W_out.T)) * functions.d_relu(u[:,t+1])\n",
        "#         delta[:,t] = (np.dot(delta[:,t+1].T, W.T) + np.dot(delta_out[:,t].T, W_out.T)) * d_tanh(u[:,t+1])    \n",
        "\n",
        "        # 勾配更新\n",
        "        W_out_grad += np.dot(z[:,t+1].reshape(-1,1), delta_out[:,t].reshape(-1,1))\n",
        "        W_grad += np.dot(z[:,t].reshape(-1,1), delta[:,t].reshape(1,-1))\n",
        "        W_in_grad += np.dot(X.T, delta[:,t].reshape(1,-1))\n",
        "    \n",
        "    # 勾配適用\n",
        "    W_in -= learning_rate * W_in_grad\n",
        "    W_out -= learning_rate * W_out_grad\n",
        "    W -= learning_rate * W_grad\n",
        "    \n",
        "    W_in_grad *= 0\n",
        "    W_out_grad *= 0\n",
        "    W_grad *= 0\n",
        "    \n",
        "\n",
        "    if(i % plot_interval == 0):\n",
        "        all_losses.append(all_loss)        \n",
        "        print(\"iters:\" + str(i))\n",
        "        print(\"Loss:\" + str(all_loss))\n",
        "        print(\"Pred:\" + str(out_bin))\n",
        "        print(\"True:\" + str(d_bin))\n",
        "        out_int = 0\n",
        "        for index,x in enumerate(reversed(out_bin)):\n",
        "            out_int += x * pow(2, index)\n",
        "        print(str(a_int) + \" + \" + str(b_int) + \" = \" + str(out_int))\n",
        "        print(\"------------\")\n",
        "\n",
        "lists = range(0, iters_num, plot_interval)\n",
        "plt.plot(lists, all_losses, label=\"loss\")\n",
        "plt.show()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iters:0\n",
            "Loss:2.300523512865106\n",
            "Pred:[1 1 1 1 1 1 1 1]\n",
            "True:[0 1 0 0 1 0 0 0]\n",
            "71 + 1 = 255\n",
            "------------\n",
            "iters:100\n",
            "Loss:0.9648927827402647\n",
            "Pred:[1 1 1 0 0 1 0 1]\n",
            "True:[0 0 1 0 1 0 0 1]\n",
            "15 + 26 = 229\n",
            "------------\n",
            "iters:200\n",
            "Loss:0.8511243341420346\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 0 1 0 0 0 1 1]\n",
            "7 + 28 = 0\n",
            "------------\n",
            "iters:300\n",
            "Loss:1.0922484538544333\n",
            "Pred:[1 1 0 1 0 1 0 1]\n",
            "True:[1 1 0 1 1 0 0 0]\n",
            "94 + 122 = 213\n",
            "------------\n",
            "iters:400\n",
            "Loss:0.9827694528631776\n",
            "Pred:[1 0 0 1 0 0 0 1]\n",
            "True:[1 1 0 0 0 1 0 0]\n",
            "88 + 108 = 145\n",
            "------------\n",
            "iters:500\n",
            "Loss:1.1123068739087465\n",
            "Pred:[0 1 1 1 0 1 1 1]\n",
            "True:[1 0 1 1 1 0 0 1]\n",
            "126 + 59 = 119\n",
            "------------\n",
            "iters:600\n",
            "Loss:1.1185114631517288\n",
            "Pred:[0 0 1 0 0 1 0 1]\n",
            "True:[0 1 1 1 1 1 1 0]\n",
            "38 + 88 = 37\n",
            "------------\n",
            "iters:700\n",
            "Loss:0.9206392886341017\n",
            "Pred:[0 1 0 0 0 1 1 0]\n",
            "True:[0 1 0 1 1 1 1 1]\n",
            "36 + 59 = 70\n",
            "------------\n",
            "iters:800\n",
            "Loss:1.0549632956629598\n",
            "Pred:[1 0 1 0 0 1 0 1]\n",
            "True:[1 0 0 0 0 1 1 0]\n",
            "22 + 112 = 165\n",
            "------------\n",
            "iters:900\n",
            "Loss:0.8220049475345588\n",
            "Pred:[1 1 1 1 0 1 0 1]\n",
            "True:[1 1 1 1 0 1 0 1]\n",
            "122 + 123 = 245\n",
            "------------\n",
            "iters:1000\n",
            "Loss:1.0530378620766494\n",
            "Pred:[1 1 0 0 1 1 0 1]\n",
            "True:[0 1 1 1 0 0 1 1]\n",
            "79 + 36 = 205\n",
            "------------\n",
            "iters:1100\n",
            "Loss:0.859652977160548\n",
            "Pred:[1 0 0 0 0 1 0 1]\n",
            "True:[1 0 0 0 1 1 0 0]\n",
            "74 + 66 = 133\n",
            "------------\n",
            "iters:1200\n",
            "Loss:0.9310865264387469\n",
            "Pred:[0 0 0 0 0 1 0 0]\n",
            "True:[1 0 0 0 0 1 0 1]\n",
            "94 + 39 = 4\n",
            "------------\n",
            "iters:1300\n",
            "Loss:0.9273414058040589\n",
            "Pred:[0 1 0 0 1 0 0 0]\n",
            "True:[1 0 0 1 0 0 0 0]\n",
            "108 + 36 = 72\n",
            "------------\n",
            "iters:1400\n",
            "Loss:0.7561323556892801\n",
            "Pred:[1 0 1 0 0 0 1 0]\n",
            "True:[1 0 1 0 0 1 1 0]\n",
            "81 + 85 = 162\n",
            "------------\n",
            "iters:1500\n",
            "Loss:1.0331026358477027\n",
            "Pred:[1 0 0 0 0 1 0 0]\n",
            "True:[1 0 0 0 1 0 1 1]\n",
            "75 + 64 = 132\n",
            "------------\n",
            "iters:1600\n",
            "Loss:0.8533446424680955\n",
            "Pred:[1 1 1 1 1 1 1 1]\n",
            "True:[1 1 1 0 0 1 1 1]\n",
            "105 + 126 = 255\n",
            "------------\n",
            "iters:1700\n",
            "Loss:0.9603378074452144\n",
            "Pred:[1 1 0 0 0 0 1 1]\n",
            "True:[1 1 0 1 1 1 0 1]\n",
            "108 + 113 = 195\n",
            "------------\n",
            "iters:1800\n",
            "Loss:0.8020366273096305\n",
            "Pred:[0 0 1 1 0 0 1 1]\n",
            "True:[0 1 1 1 0 0 1 1]\n",
            "26 + 89 = 51\n",
            "------------\n",
            "iters:1900\n",
            "Loss:0.7432910100924954\n",
            "Pred:[0 0 0 1 0 1 0 1]\n",
            "True:[0 0 0 1 1 1 0 1]\n",
            "2 + 27 = 21\n",
            "------------\n",
            "iters:2000\n",
            "Loss:0.8937084900048878\n",
            "Pred:[0 0 0 0 0 1 0 0]\n",
            "True:[0 1 0 0 1 1 0 1]\n",
            "11 + 66 = 4\n",
            "------------\n",
            "iters:2100\n",
            "Loss:0.8582708712638685\n",
            "Pred:[1 1 1 0 0 1 0 1]\n",
            "True:[1 1 1 1 0 0 0 1]\n",
            "122 + 119 = 229\n",
            "------------\n",
            "iters:2200\n",
            "Loss:0.824765343672921\n",
            "Pred:[0 0 0 1 1 0 0 0]\n",
            "True:[0 0 1 0 0 0 0 0]\n",
            "12 + 20 = 24\n",
            "------------\n",
            "iters:2300\n",
            "Loss:0.9828977213907346\n",
            "Pred:[0 1 1 0 1 1 1 0]\n",
            "True:[0 1 1 1 0 0 0 0]\n",
            "57 + 55 = 110\n",
            "------------\n",
            "iters:2400\n",
            "Loss:0.37148580464341135\n",
            "Pred:[1 0 0 1 0 0 0 0]\n",
            "True:[1 0 0 1 0 0 0 0]\n",
            "72 + 72 = 144\n",
            "------------\n",
            "iters:2500\n",
            "Loss:1.0770273543345716\n",
            "Pred:[1 0 1 1 1 1 1 0]\n",
            "True:[1 1 0 0 0 0 0 0]\n",
            "125 + 67 = 190\n",
            "------------\n",
            "iters:2600\n",
            "Loss:0.9257625011698158\n",
            "Pred:[0 1 1 1 0 1 1 0]\n",
            "True:[0 1 1 1 1 0 0 0]\n",
            "15 + 105 = 118\n",
            "------------\n",
            "iters:2700\n",
            "Loss:0.6284677979220373\n",
            "Pred:[1 0 0 0 1 1 0 0]\n",
            "True:[1 0 0 0 1 1 1 0]\n",
            "66 + 76 = 140\n",
            "------------\n",
            "iters:2800\n",
            "Loss:0.8211007886862365\n",
            "Pred:[0 1 1 0 0 0 1 1]\n",
            "True:[0 1 1 1 0 0 1 1]\n",
            "81 + 34 = 99\n",
            "------------\n",
            "iters:2900\n",
            "Loss:0.8732217261916195\n",
            "Pred:[1 1 1 0 1 1 0 1]\n",
            "True:[1 0 1 1 0 0 0 1]\n",
            "62 + 115 = 237\n",
            "------------\n",
            "iters:3000\n",
            "Loss:0.6705159477756684\n",
            "Pred:[1 0 1 0 0 1 0 0]\n",
            "True:[1 0 0 0 1 1 0 0]\n",
            "90 + 50 = 164\n",
            "------------\n",
            "iters:3100\n",
            "Loss:0.8505199132104903\n",
            "Pred:[0 0 1 1 1 0 0 1]\n",
            "True:[0 1 0 0 0 0 0 1]\n",
            "18 + 47 = 57\n",
            "------------\n",
            "iters:3200\n",
            "Loss:0.49495119466648513\n",
            "Pred:[1 0 0 1 1 0 0 0]\n",
            "True:[1 0 0 1 0 0 1 0]\n",
            "68 + 78 = 152\n",
            "------------\n",
            "iters:3300\n",
            "Loss:0.8275360867743876\n",
            "Pred:[1 1 1 1 0 1 1 1]\n",
            "True:[1 0 1 0 0 1 1 1]\n",
            "105 + 62 = 247\n",
            "------------\n",
            "iters:3400\n",
            "Loss:0.2963949463715356\n",
            "Pred:[1 0 0 1 1 1 0 1]\n",
            "True:[1 0 0 1 1 1 0 1]\n",
            "71 + 86 = 157\n",
            "------------\n",
            "iters:3500\n",
            "Loss:0.6434986269985674\n",
            "Pred:[1 0 0 1 1 0 0 0]\n",
            "True:[1 0 0 1 1 0 1 1]\n",
            "53 + 102 = 152\n",
            "------------\n",
            "iters:3600\n",
            "Loss:0.16356610915143366\n",
            "Pred:[1 1 1 0 1 1 1 0]\n",
            "True:[1 1 1 0 1 1 1 0]\n",
            "125 + 113 = 238\n",
            "------------\n",
            "iters:3700\n",
            "Loss:0.5681756155061107\n",
            "Pred:[1 1 0 0 0 1 1 1]\n",
            "True:[1 0 0 0 0 1 1 1]\n",
            "97 + 38 = 199\n",
            "------------\n",
            "iters:3800\n",
            "Loss:0.1675410010775926\n",
            "Pred:[0 1 0 0 1 1 0 1]\n",
            "True:[0 1 0 0 1 1 0 1]\n",
            "64 + 13 = 77\n",
            "------------\n",
            "iters:3900\n",
            "Loss:0.39520593484896904\n",
            "Pred:[1 0 0 0 0 0 1 0]\n",
            "True:[1 0 0 0 0 0 1 0]\n",
            "95 + 35 = 130\n",
            "------------\n",
            "iters:4000\n",
            "Loss:0.11467161816743465\n",
            "Pred:[1 0 1 0 0 1 0 0]\n",
            "True:[1 0 1 0 0 1 0 0]\n",
            "92 + 72 = 164\n",
            "------------\n",
            "iters:4100\n",
            "Loss:0.17225858344007666\n",
            "Pred:[0 1 1 1 0 1 0 0]\n",
            "True:[0 1 1 1 0 1 0 0]\n",
            "94 + 22 = 116\n",
            "------------\n",
            "iters:4200\n",
            "Loss:0.2624016061602456\n",
            "Pred:[1 0 1 0 0 1 1 0]\n",
            "True:[1 0 1 0 0 1 1 0]\n",
            "46 + 120 = 166\n",
            "------------\n",
            "iters:4300\n",
            "Loss:0.1180240192812467\n",
            "Pred:[1 0 0 1 1 0 0 0]\n",
            "True:[1 0 0 1 1 0 0 0]\n",
            "116 + 36 = 152\n",
            "------------\n",
            "iters:4400\n",
            "Loss:0.16588371219278797\n",
            "Pred:[0 1 1 1 1 0 1 0]\n",
            "True:[0 1 1 1 1 0 1 0]\n",
            "50 + 72 = 122\n",
            "------------\n",
            "iters:4500\n",
            "Loss:0.06908797669550516\n",
            "Pred:[0 1 0 0 0 1 1 0]\n",
            "True:[0 1 0 0 0 1 1 0]\n",
            "43 + 27 = 70\n",
            "------------\n",
            "iters:4600\n",
            "Loss:0.10617794879073184\n",
            "Pred:[1 0 1 1 1 0 1 0]\n",
            "True:[1 0 1 1 1 0 1 0]\n",
            "118 + 68 = 186\n",
            "------------\n",
            "iters:4700\n",
            "Loss:0.09715047481167247\n",
            "Pred:[0 0 1 1 1 1 1 0]\n",
            "True:[0 0 1 1 1 1 1 0]\n",
            "28 + 34 = 62\n",
            "------------\n",
            "iters:4800\n",
            "Loss:0.09973983204165826\n",
            "Pred:[1 0 0 1 1 1 0 0]\n",
            "True:[1 0 0 1 1 1 0 0]\n",
            "86 + 70 = 156\n",
            "------------\n",
            "iters:4900\n",
            "Loss:0.05140538466584129\n",
            "Pred:[0 1 1 0 1 1 0 0]\n",
            "True:[0 1 1 0 1 1 0 0]\n",
            "4 + 104 = 108\n",
            "------------\n",
            "iters:5000\n",
            "Loss:0.03282998063262588\n",
            "Pred:[0 1 1 1 1 0 0 1]\n",
            "True:[0 1 1 1 1 0 0 1]\n",
            "80 + 41 = 121\n",
            "------------\n",
            "iters:5100\n",
            "Loss:0.04187859809101084\n",
            "Pred:[0 1 0 0 1 0 1 1]\n",
            "True:[0 1 0 0 1 0 1 1]\n",
            "25 + 50 = 75\n",
            "------------\n",
            "iters:5200\n",
            "Loss:0.16387005320463208\n",
            "Pred:[1 0 0 1 1 1 1 1]\n",
            "True:[1 0 0 1 1 1 1 1]\n",
            "67 + 92 = 159\n",
            "------------\n",
            "iters:5300\n",
            "Loss:0.04692883058855207\n",
            "Pred:[1 1 0 0 1 1 0 0]\n",
            "True:[1 1 0 0 1 1 0 0]\n",
            "108 + 96 = 204\n",
            "------------\n",
            "iters:5400\n",
            "Loss:0.034632074117331976\n",
            "Pred:[0 0 1 0 1 0 0 0]\n",
            "True:[0 0 1 0 1 0 0 0]\n",
            "12 + 28 = 40\n",
            "------------\n",
            "iters:5500\n",
            "Loss:0.0063562097682331046\n",
            "Pred:[0 1 0 1 1 1 1 0]\n",
            "True:[0 1 0 1 1 1 1 0]\n",
            "83 + 11 = 94\n",
            "------------\n",
            "iters:5600\n",
            "Loss:0.017624274766047346\n",
            "Pred:[0 0 1 0 1 1 0 1]\n",
            "True:[0 0 1 0 1 1 0 1]\n",
            "16 + 29 = 45\n",
            "------------\n",
            "iters:5700\n",
            "Loss:0.046365240376051504\n",
            "Pred:[1 1 0 0 0 1 1 1]\n",
            "True:[1 1 0 0 0 1 1 1]\n",
            "108 + 91 = 199\n",
            "------------\n",
            "iters:5800\n",
            "Loss:0.012960230712696788\n",
            "Pred:[1 1 1 0 1 0 0 1]\n",
            "True:[1 1 1 0 1 0 0 1]\n",
            "114 + 119 = 233\n",
            "------------\n",
            "iters:5900\n",
            "Loss:0.00846888661551715\n",
            "Pred:[1 0 0 1 0 0 1 0]\n",
            "True:[1 0 0 1 0 0 1 0]\n",
            "41 + 105 = 146\n",
            "------------\n",
            "iters:6000\n",
            "Loss:0.03619272016064149\n",
            "Pred:[0 1 1 1 0 1 1 0]\n",
            "True:[0 1 1 1 0 1 1 0]\n",
            "66 + 52 = 118\n",
            "------------\n",
            "iters:6100\n",
            "Loss:0.022789011869535105\n",
            "Pred:[1 1 0 0 1 0 1 1]\n",
            "True:[1 1 0 0 1 0 1 1]\n",
            "115 + 88 = 203\n",
            "------------\n",
            "iters:6200\n",
            "Loss:0.014865658412563102\n",
            "Pred:[1 0 1 1 1 0 1 1]\n",
            "True:[1 0 1 1 1 0 1 1]\n",
            "80 + 107 = 187\n",
            "------------\n",
            "iters:6300\n",
            "Loss:0.010080775022165108\n",
            "Pred:[1 0 1 0 1 1 0 1]\n",
            "True:[1 0 1 0 1 1 0 1]\n",
            "50 + 123 = 173\n",
            "------------\n",
            "iters:6400\n",
            "Loss:0.00736402052537609\n",
            "Pred:[0 1 0 0 1 1 0 1]\n",
            "True:[0 1 0 0 1 1 0 1]\n",
            "74 + 3 = 77\n",
            "------------\n",
            "iters:6500\n",
            "Loss:0.014551919597310347\n",
            "Pred:[1 1 1 0 0 1 1 1]\n",
            "True:[1 1 1 0 0 1 1 1]\n",
            "114 + 117 = 231\n",
            "------------\n",
            "iters:6600\n",
            "Loss:0.008402576197737998\n",
            "Pred:[0 0 0 1 0 0 1 1]\n",
            "True:[0 0 0 1 0 0 1 1]\n",
            "14 + 5 = 19\n",
            "------------\n",
            "iters:6700\n",
            "Loss:0.004015972462658591\n",
            "Pred:[1 0 1 0 0 1 1 0]\n",
            "True:[1 0 1 0 0 1 1 0]\n",
            "117 + 49 = 166\n",
            "------------\n",
            "iters:6800\n",
            "Loss:0.01251371701223021\n",
            "Pred:[1 1 1 0 0 0 1 1]\n",
            "True:[1 1 1 0 0 0 1 1]\n",
            "117 + 110 = 227\n",
            "------------\n",
            "iters:6900\n",
            "Loss:0.01046083797046709\n",
            "Pred:[1 0 0 1 0 1 1 1]\n",
            "True:[1 0 0 1 0 1 1 1]\n",
            "82 + 69 = 151\n",
            "------------\n",
            "iters:7000\n",
            "Loss:0.00654315714873531\n",
            "Pred:[0 0 1 0 0 1 0 1]\n",
            "True:[0 0 1 0 0 1 0 1]\n",
            "22 + 15 = 37\n",
            "------------\n",
            "iters:7100\n",
            "Loss:0.0191257217590865\n",
            "Pred:[1 0 0 1 0 1 0 0]\n",
            "True:[1 0 0 1 0 1 0 0]\n",
            "56 + 92 = 148\n",
            "------------\n",
            "iters:7200\n",
            "Loss:0.009362808978099423\n",
            "Pred:[0 1 1 1 1 0 1 1]\n",
            "True:[0 1 1 1 1 0 1 1]\n",
            "86 + 37 = 123\n",
            "------------\n",
            "iters:7300\n",
            "Loss:0.00401503981890441\n",
            "Pred:[0 0 1 0 1 1 0 1]\n",
            "True:[0 0 1 0 1 1 0 1]\n",
            "38 + 7 = 45\n",
            "------------\n",
            "iters:7400\n",
            "Loss:0.005911159087967432\n",
            "Pred:[0 1 1 0 0 1 0 1]\n",
            "True:[0 1 1 0 0 1 0 1]\n",
            "22 + 79 = 101\n",
            "------------\n",
            "iters:7500\n",
            "Loss:0.005998791319207797\n",
            "Pred:[0 1 1 1 0 1 1 1]\n",
            "True:[0 1 1 1 0 1 1 1]\n",
            "32 + 87 = 119\n",
            "------------\n",
            "iters:7600\n",
            "Loss:0.007714745725556742\n",
            "Pred:[0 1 0 0 0 1 1 1]\n",
            "True:[0 1 0 0 0 1 1 1]\n",
            "17 + 54 = 71\n",
            "------------\n",
            "iters:7700\n",
            "Loss:0.013771689564460433\n",
            "Pred:[0 1 1 1 1 1 0 0]\n",
            "True:[0 1 1 1 1 1 0 0]\n",
            "116 + 8 = 124\n",
            "------------\n",
            "iters:7800\n",
            "Loss:0.0038869505896588583\n",
            "Pred:[1 0 0 1 0 1 0 1]\n",
            "True:[1 0 0 1 0 1 0 1]\n",
            "116 + 33 = 149\n",
            "------------\n",
            "iters:7900\n",
            "Loss:0.005161101176541912\n",
            "Pred:[1 0 1 0 1 0 1 1]\n",
            "True:[1 0 1 0 1 0 1 1]\n",
            "46 + 125 = 171\n",
            "------------\n",
            "iters:8000\n",
            "Loss:0.008915236499995816\n",
            "Pred:[0 1 1 0 1 1 1 1]\n",
            "True:[0 1 1 0 1 1 1 1]\n",
            "27 + 84 = 111\n",
            "------------\n",
            "iters:8100\n",
            "Loss:0.005867830698022967\n",
            "Pred:[1 0 1 0 1 1 0 1]\n",
            "True:[1 0 1 0 1 1 0 1]\n",
            "63 + 110 = 173\n",
            "------------\n",
            "iters:8200\n",
            "Loss:0.0021266285233085616\n",
            "Pred:[0 1 0 1 0 0 0 0]\n",
            "True:[0 1 0 1 0 0 0 0]\n",
            "45 + 35 = 80\n",
            "------------\n",
            "iters:8300\n",
            "Loss:0.003803330823650688\n",
            "Pred:[0 1 1 1 1 0 1 1]\n",
            "True:[0 1 1 1 1 0 1 1]\n",
            "1 + 122 = 123\n",
            "------------\n",
            "iters:8400\n",
            "Loss:0.008731557026603599\n",
            "Pred:[0 1 1 0 1 1 1 0]\n",
            "True:[0 1 1 0 1 1 1 0]\n",
            "18 + 92 = 110\n",
            "------------\n",
            "iters:8500\n",
            "Loss:0.003205479743568911\n",
            "Pred:[1 1 0 1 1 1 0 1]\n",
            "True:[1 1 0 1 1 1 0 1]\n",
            "94 + 127 = 221\n",
            "------------\n",
            "iters:8600\n",
            "Loss:0.003310550428028842\n",
            "Pred:[0 1 1 1 0 0 1 1]\n",
            "True:[0 1 1 1 0 0 1 1]\n",
            "66 + 49 = 115\n",
            "------------\n",
            "iters:8700\n",
            "Loss:0.0014318357938227389\n",
            "Pred:[1 1 1 0 0 0 1 0]\n",
            "True:[1 1 1 0 0 0 1 0]\n",
            "109 + 117 = 226\n",
            "------------\n",
            "iters:8800\n",
            "Loss:0.00676912910359797\n",
            "Pred:[0 0 0 1 1 0 1 0]\n",
            "True:[0 0 0 1 1 0 1 0]\n",
            "20 + 6 = 26\n",
            "------------\n",
            "iters:8900\n",
            "Loss:0.004162964139534515\n",
            "Pred:[1 0 1 0 0 0 0 1]\n",
            "True:[1 0 1 0 0 0 0 1]\n",
            "119 + 42 = 161\n",
            "------------\n",
            "iters:9000\n",
            "Loss:0.0036559603489360695\n",
            "Pred:[0 1 0 1 0 1 1 1]\n",
            "True:[0 1 0 1 0 1 1 1]\n",
            "7 + 80 = 87\n",
            "------------\n",
            "iters:9100\n",
            "Loss:0.0033063991671768525\n",
            "Pred:[1 0 1 0 1 0 1 1]\n",
            "True:[1 0 1 0 1 0 1 1]\n",
            "70 + 101 = 171\n",
            "------------\n",
            "iters:9200\n",
            "Loss:0.002818591583711534\n",
            "Pred:[0 0 1 0 0 1 0 1]\n",
            "True:[0 0 1 0 0 1 0 1]\n",
            "10 + 27 = 37\n",
            "------------\n",
            "iters:9300\n",
            "Loss:0.003015066749123061\n",
            "Pred:[0 1 0 0 0 0 1 1]\n",
            "True:[0 1 0 0 0 0 1 1]\n",
            "5 + 62 = 67\n",
            "------------\n",
            "iters:9400\n",
            "Loss:0.002412313772558469\n",
            "Pred:[1 1 0 0 1 0 0 1]\n",
            "True:[1 1 0 0 1 0 0 1]\n",
            "95 + 106 = 201\n",
            "------------\n",
            "iters:9500\n",
            "Loss:0.005521687449334053\n",
            "Pred:[1 0 0 0 1 1 0 0]\n",
            "True:[1 0 0 0 1 1 0 0]\n",
            "66 + 74 = 140\n",
            "------------\n",
            "iters:9600\n",
            "Loss:0.0006373470323019693\n",
            "Pred:[0 1 0 1 0 1 0 0]\n",
            "True:[0 1 0 1 0 1 0 0]\n",
            "75 + 9 = 84\n",
            "------------\n",
            "iters:9700\n",
            "Loss:0.0004696662490513482\n",
            "Pred:[0 1 1 0 0 1 0 0]\n",
            "True:[0 1 1 0 0 1 0 0]\n",
            "51 + 49 = 100\n",
            "------------\n",
            "iters:9800\n",
            "Loss:0.0043226137881878885\n",
            "Pred:[0 1 0 1 1 0 1 0]\n",
            "True:[0 1 0 1 1 0 1 0]\n",
            "50 + 40 = 90\n",
            "------------\n",
            "iters:9900\n",
            "Loss:0.0023018328861391687\n",
            "Pred:[0 1 0 1 0 0 1 1]\n",
            "True:[0 1 0 1 0 0 1 1]\n",
            "40 + 43 = 83\n",
            "------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#weight_init_stdやlearning_rate, hidden_layer_sizeを変更\n",
        "\n",
        "```\n",
        "hidden_layer_size = 16 -> 32\n",
        "weight_init_std = 1 -> 2\n",
        "learning_rate = 0.1 -> 0.2\n",
        "```"
      ],
      "metadata": {
        "id": "3m0fRkLEKeBR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from common import functions\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def d_tanh(x):\n",
        "    return 1/(np.cosh(x) ** 2)\n",
        "\n",
        "# データを用意\n",
        "# 2進数の桁数\n",
        "binary_dim = 8\n",
        "# 最大値 + 1\n",
        "largest_number = pow(2, binary_dim)\n",
        "# largest_numberまで2進数を用意\n",
        "binary = np.unpackbits(np.array([range(largest_number)],dtype=np.uint8).T,axis=1)\n",
        "\n",
        "input_layer_size = 2\n",
        "hidden_layer_size = 32\n",
        "output_layer_size = 1\n",
        "\n",
        "weight_init_std = 0.8\n",
        "learning_rate = 0.1\n",
        "\n",
        "iters_num = 10000\n",
        "plot_interval = 100\n",
        "\n",
        "# ウェイト初期化 (バイアスは簡単のため省略)\n",
        "W_in = weight_init_std * np.random.randn(input_layer_size, hidden_layer_size)\n",
        "W_out = weight_init_std * np.random.randn(hidden_layer_size, output_layer_size)\n",
        "W = weight_init_std * np.random.randn(hidden_layer_size, hidden_layer_size)\n",
        "# Xavier\n",
        "# W_in = np.random.randn(input_layer_size, hidden_layer_size) / (np.sqrt(input_layer_size))\n",
        "# W_out = np.random.randn(hidden_layer_size, output_layer_size) / (np.sqrt(hidden_layer_size))\n",
        "# W = np.random.randn(hidden_layer_size, hidden_layer_size) / (np.sqrt(hidden_layer_size))\n",
        "# He\n",
        "# W_in = np.random.randn(input_layer_size, hidden_layer_size) / (np.sqrt(input_layer_size)) * np.sqrt(2)\n",
        "# W_out = np.random.randn(hidden_layer_size, output_layer_size) / (np.sqrt(hidden_layer_size)) * np.sqrt(2)\n",
        "# W = np.random.randn(hidden_layer_size, hidden_layer_size) / (np.sqrt(hidden_layer_size)) * np.sqrt(2)\n",
        "\n",
        "\n",
        "# 勾配\n",
        "W_in_grad = np.zeros_like(W_in)\n",
        "W_out_grad = np.zeros_like(W_out)\n",
        "W_grad = np.zeros_like(W)\n",
        "\n",
        "u = np.zeros((hidden_layer_size, binary_dim + 1))\n",
        "z = np.zeros((hidden_layer_size, binary_dim + 1))\n",
        "y = np.zeros((output_layer_size, binary_dim))\n",
        "\n",
        "delta_out = np.zeros((output_layer_size, binary_dim))\n",
        "delta = np.zeros((hidden_layer_size, binary_dim + 1))\n",
        "\n",
        "all_losses = []\n",
        "\n",
        "for i in range(iters_num):\n",
        "    \n",
        "    # A, B初期化 (a + b = d)\n",
        "    a_int = np.random.randint(largest_number/2)\n",
        "    a_bin = binary[a_int] # binary encoding\n",
        "    b_int = np.random.randint(largest_number/2)\n",
        "    b_bin = binary[b_int] # binary encoding\n",
        "    \n",
        "    # 正解データ\n",
        "    d_int = a_int + b_int\n",
        "    d_bin = binary[d_int]\n",
        "    \n",
        "    # 出力バイナリ\n",
        "    out_bin = np.zeros_like(d_bin)\n",
        "    \n",
        "    # 時系列全体の誤差\n",
        "    all_loss = 0    \n",
        "    \n",
        "    # 時系列ループ\n",
        "    for t in range(binary_dim):\n",
        "        # 入力値\n",
        "        X = np.array([a_bin[ - t - 1], b_bin[ - t - 1]]).reshape(1, -1)\n",
        "        # 時刻tにおける正解データ\n",
        "        dd = np.array([d_bin[binary_dim - t - 1]])\n",
        "        \n",
        "        u[:,t+1] = np.dot(X, W_in) + np.dot(z[:,t].reshape(1, -1), W)\n",
        "        z[:,t+1] = functions.sigmoid(u[:,t+1])\n",
        "#         z[:,t+1] = functions.relu(u[:,t+1])\n",
        "#         z[:,t+1] = np.tanh(u[:,t+1])    \n",
        "        y[:,t] = functions.sigmoid(np.dot(z[:,t+1].reshape(1, -1), W_out))\n",
        "\n",
        "\n",
        "        #誤差\n",
        "        loss = functions.mean_squared_error(dd, y[:,t])\n",
        "        \n",
        "        delta_out[:,t] = functions.d_mean_squared_error(dd, y[:,t]) * functions.d_sigmoid(y[:,t])        \n",
        "        \n",
        "        all_loss += loss\n",
        "\n",
        "        out_bin[binary_dim - t - 1] = np.round(y[:,t])\n",
        "    \n",
        "    \n",
        "    for t in range(binary_dim)[::-1]:\n",
        "        X = np.array([a_bin[-t-1],b_bin[-t-1]]).reshape(1, -1)        \n",
        "\n",
        "        delta[:,t] = (np.dot(delta[:,t+1].T, W.T) + np.dot(delta_out[:,t].T, W_out.T)) * functions.d_sigmoid(u[:,t+1])\n",
        "#         delta[:,t] = (np.dot(delta[:,t+1].T, W.T) + np.dot(delta_out[:,t].T, W_out.T)) * functions.d_relu(u[:,t+1])\n",
        "#         delta[:,t] = (np.dot(delta[:,t+1].T, W.T) + np.dot(delta_out[:,t].T, W_out.T)) * d_tanh(u[:,t+1])    \n",
        "\n",
        "        # 勾配更新\n",
        "        W_out_grad += np.dot(z[:,t+1].reshape(-1,1), delta_out[:,t].reshape(-1,1))\n",
        "        W_grad += np.dot(z[:,t].reshape(-1,1), delta[:,t].reshape(1,-1))\n",
        "        W_in_grad += np.dot(X.T, delta[:,t].reshape(1,-1))\n",
        "    \n",
        "    # 勾配適用\n",
        "    W_in -= learning_rate * W_in_grad\n",
        "    W_out -= learning_rate * W_out_grad\n",
        "    W -= learning_rate * W_grad\n",
        "    \n",
        "    W_in_grad *= 0\n",
        "    W_out_grad *= 0\n",
        "    W_grad *= 0\n",
        "    \n",
        "\n",
        "    if(i % plot_interval == 0):\n",
        "        all_losses.append(all_loss)        \n",
        "        print(\"iters:\" + str(i))\n",
        "        print(\"Loss:\" + str(all_loss))\n",
        "        print(\"Pred:\" + str(out_bin))\n",
        "        print(\"True:\" + str(d_bin))\n",
        "        out_int = 0\n",
        "        for index,x in enumerate(reversed(out_bin)):\n",
        "            out_int += x * pow(2, index)\n",
        "        print(str(a_int) + \" + \" + str(b_int) + \" = \" + str(out_int))\n",
        "        print(\"------------\")\n",
        "\n",
        "lists = range(0, iters_num, plot_interval)\n",
        "plt.plot(lists, all_losses, label=\"loss\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "cBvIwCwRKw-o",
        "outputId": "cb9ceb46-fbf3-4c46-f5b2-2bb860db3f36"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iters:0\n",
            "Loss:1.4915053842214898\n",
            "Pred:[1 1 1 1 1 1 1 1]\n",
            "True:[0 1 1 0 1 1 1 0]\n",
            "48 + 62 = 255\n",
            "------------\n",
            "iters:100\n",
            "Loss:0.9276612355824881\n",
            "Pred:[1 1 1 1 1 1 1 1]\n",
            "True:[0 1 1 1 0 1 0 1]\n",
            "55 + 62 = 255\n",
            "------------\n",
            "iters:200\n",
            "Loss:1.0116062889630062\n",
            "Pred:[0 1 1 1 0 1 1 0]\n",
            "True:[1 1 1 0 0 0 0 0]\n",
            "119 + 105 = 118\n",
            "------------\n",
            "iters:300\n",
            "Loss:1.1402076259073834\n",
            "Pred:[1 1 1 1 1 1 1 1]\n",
            "True:[0 1 1 1 0 1 0 1]\n",
            "60 + 57 = 255\n",
            "------------\n",
            "iters:400\n",
            "Loss:1.0704430198171457\n",
            "Pred:[0 1 0 1 1 0 1 0]\n",
            "True:[1 0 0 0 0 1 1 1]\n",
            "26 + 109 = 90\n",
            "------------\n",
            "iters:500\n",
            "Loss:0.999351832478478\n",
            "Pred:[0 0 0 0 0 0 0 1]\n",
            "True:[1 1 0 0 0 0 1 1]\n",
            "125 + 70 = 1\n",
            "------------\n",
            "iters:600\n",
            "Loss:1.0127057921338798\n",
            "Pred:[0 0 0 0 1 1 1 1]\n",
            "True:[0 0 0 0 1 0 0 1]\n",
            "6 + 3 = 15\n",
            "------------\n",
            "iters:700\n",
            "Loss:0.8750106918476598\n",
            "Pred:[1 0 1 0 1 0 0 0]\n",
            "True:[1 0 0 1 1 0 0 1]\n",
            "69 + 84 = 168\n",
            "------------\n",
            "iters:800\n",
            "Loss:1.4351727758335928\n",
            "Pred:[1 1 1 1 1 1 1 1]\n",
            "True:[1 0 0 1 0 1 0 0]\n",
            "35 + 113 = 255\n",
            "------------\n",
            "iters:900\n",
            "Loss:1.0911530050441536\n",
            "Pred:[1 1 1 1 1 0 1 1]\n",
            "True:[0 1 1 0 1 0 0 0]\n",
            "60 + 44 = 251\n",
            "------------\n",
            "iters:1000\n",
            "Loss:1.205895658248095\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 1 1 0 1 0 1 1]\n",
            "105 + 2 = 0\n",
            "------------\n",
            "iters:1100\n",
            "Loss:1.1247332825133451\n",
            "Pred:[1 1 1 1 1 1 1 1]\n",
            "True:[0 1 0 1 1 1 0 0]\n",
            "23 + 69 = 255\n",
            "------------\n",
            "iters:1200\n",
            "Loss:0.6470432251779688\n",
            "Pred:[1 1 1 0 1 1 1 1]\n",
            "True:[1 1 0 0 1 0 1 1]\n",
            "98 + 105 = 239\n",
            "------------\n",
            "iters:1300\n",
            "Loss:0.8800317219321129\n",
            "Pred:[1 1 0 1 0 0 1 0]\n",
            "True:[1 1 1 0 0 0 1 0]\n",
            "106 + 120 = 210\n",
            "------------\n",
            "iters:1400\n",
            "Loss:0.8038202293043184\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 0 1 1 0 0 1 0]\n",
            "0 + 50 = 0\n",
            "------------\n",
            "iters:1500\n",
            "Loss:1.1450106596584564\n",
            "Pred:[1 1 1 1 1 1 1 1]\n",
            "True:[1 1 0 0 0 1 0 1]\n",
            "78 + 119 = 255\n",
            "------------\n",
            "iters:1600\n",
            "Loss:0.746472439001968\n",
            "Pred:[1 1 1 1 1 1 1 1]\n",
            "True:[1 0 1 0 1 1 1 1]\n",
            "59 + 116 = 255\n",
            "------------\n",
            "iters:1700\n",
            "Loss:1.0040539576709495\n",
            "Pred:[1 1 0 1 0 1 0 0]\n",
            "True:[1 0 1 0 0 1 1 0]\n",
            "123 + 43 = 212\n",
            "------------\n",
            "iters:1800\n",
            "Loss:1.0101264930574316\n",
            "Pred:[0 0 0 1 1 0 0 0]\n",
            "True:[0 1 1 1 0 0 1 1]\n",
            "71 + 44 = 24\n",
            "------------\n",
            "iters:1900\n",
            "Loss:0.8530768275914457\n",
            "Pred:[0 0 1 1 1 0 1 0]\n",
            "True:[0 0 1 0 0 0 1 0]\n",
            "14 + 20 = 58\n",
            "------------\n",
            "iters:2000\n",
            "Loss:0.8829471108109268\n",
            "Pred:[1 1 1 0 1 0 0 0]\n",
            "True:[1 0 1 1 0 0 0 0]\n",
            "120 + 56 = 232\n",
            "------------\n",
            "iters:2100\n",
            "Loss:0.7472368876348129\n",
            "Pred:[1 1 1 1 1 1 1 0]\n",
            "True:[1 0 1 0 1 1 1 0]\n",
            "114 + 60 = 254\n",
            "------------\n",
            "iters:2200\n",
            "Loss:0.8995082418722377\n",
            "Pred:[1 0 0 0 0 0 0 0]\n",
            "True:[1 1 0 0 0 1 0 1]\n",
            "84 + 113 = 128\n",
            "------------\n",
            "iters:2300\n",
            "Loss:1.4164723828506818\n",
            "Pred:[0 1 1 1 1 0 1 1]\n",
            "True:[1 0 0 0 0 0 0 1]\n",
            "4 + 125 = 123\n",
            "------------\n",
            "iters:2400\n",
            "Loss:0.5494960636588112\n",
            "Pred:[0 1 0 1 0 1 1 1]\n",
            "True:[0 1 0 1 0 1 0 1]\n",
            "13 + 72 = 87\n",
            "------------\n",
            "iters:2500\n",
            "Loss:0.6235972104707448\n",
            "Pred:[0 1 0 0 1 0 0 1]\n",
            "True:[0 1 0 0 1 0 1 1]\n",
            "24 + 51 = 73\n",
            "------------\n",
            "iters:2600\n",
            "Loss:0.8649939445272405\n",
            "Pred:[1 1 1 0 1 0 0 0]\n",
            "True:[1 0 0 0 1 0 0 0]\n",
            "49 + 87 = 232\n",
            "------------\n",
            "iters:2700\n",
            "Loss:0.7758530496940255\n",
            "Pred:[1 1 0 1 0 1 1 0]\n",
            "True:[1 0 1 0 0 1 1 0]\n",
            "41 + 125 = 214\n",
            "------------\n",
            "iters:2800\n",
            "Loss:0.3081591988526615\n",
            "Pred:[0 1 0 1 0 1 1 1]\n",
            "True:[0 1 0 1 0 1 1 1]\n",
            "16 + 71 = 87\n",
            "------------\n",
            "iters:2900\n",
            "Loss:0.4971992315241682\n",
            "Pred:[1 1 0 1 1 1 1 0]\n",
            "True:[1 1 0 1 0 1 1 0]\n",
            "101 + 113 = 222\n",
            "------------\n",
            "iters:3000\n",
            "Loss:0.39207655580737294\n",
            "Pred:[0 1 0 0 1 0 0 1]\n",
            "True:[0 1 0 0 1 1 0 1]\n",
            "70 + 7 = 73\n",
            "------------\n",
            "iters:3100\n",
            "Loss:0.1668407017685473\n",
            "Pred:[0 1 1 1 0 0 0 1]\n",
            "True:[0 1 1 1 0 0 0 1]\n",
            "96 + 17 = 113\n",
            "------------\n",
            "iters:3200\n",
            "Loss:0.3490996815463777\n",
            "Pred:[1 1 0 1 1 0 0 0]\n",
            "True:[1 1 0 1 1 0 0 0]\n",
            "118 + 98 = 216\n",
            "------------\n",
            "iters:3300\n",
            "Loss:0.15889830135970154\n",
            "Pred:[0 1 1 1 1 0 1 1]\n",
            "True:[0 1 1 1 1 0 1 1]\n",
            "32 + 91 = 123\n",
            "------------\n",
            "iters:3400\n",
            "Loss:0.10370201120907731\n",
            "Pred:[0 1 1 0 1 1 1 0]\n",
            "True:[0 1 1 0 1 1 1 0]\n",
            "32 + 78 = 110\n",
            "------------\n",
            "iters:3500\n",
            "Loss:0.5660249466088008\n",
            "Pred:[0 1 1 0 0 1 1 1]\n",
            "True:[0 1 0 0 0 1 1 1]\n",
            "17 + 54 = 103\n",
            "------------\n",
            "iters:3600\n",
            "Loss:0.22691067238306073\n",
            "Pred:[1 0 0 1 0 0 1 0]\n",
            "True:[1 0 0 1 0 0 1 0]\n",
            "80 + 66 = 146\n",
            "------------\n",
            "iters:3700\n",
            "Loss:0.13155791013248797\n",
            "Pred:[0 1 0 0 1 0 1 1]\n",
            "True:[0 1 0 0 1 0 1 1]\n",
            "34 + 41 = 75\n",
            "------------\n",
            "iters:3800\n",
            "Loss:0.28705122006575207\n",
            "Pred:[1 0 1 0 1 0 0 0]\n",
            "True:[1 0 1 0 1 0 0 0]\n",
            "111 + 57 = 168\n",
            "------------\n",
            "iters:3900\n",
            "Loss:0.07047852938305417\n",
            "Pred:[1 0 1 0 1 1 1 0]\n",
            "True:[1 0 1 0 1 1 1 0]\n",
            "125 + 49 = 174\n",
            "------------\n",
            "iters:4000\n",
            "Loss:0.12182633767701545\n",
            "Pred:[0 1 1 1 1 0 0 1]\n",
            "True:[0 1 1 1 1 0 0 1]\n",
            "77 + 44 = 121\n",
            "------------\n",
            "iters:4100\n",
            "Loss:0.03149362490275564\n",
            "Pred:[0 1 1 1 1 1 1 1]\n",
            "True:[0 1 1 1 1 1 1 1]\n",
            "52 + 75 = 127\n",
            "------------\n",
            "iters:4200\n",
            "Loss:0.14165317102260766\n",
            "Pred:[0 1 1 1 1 1 0 0]\n",
            "True:[0 1 1 1 1 1 0 0]\n",
            "118 + 6 = 124\n",
            "------------\n",
            "iters:4300\n",
            "Loss:0.025274231456444557\n",
            "Pred:[1 0 1 0 1 0 0 0]\n",
            "True:[1 0 1 0 1 0 0 0]\n",
            "81 + 87 = 168\n",
            "------------\n",
            "iters:4400\n",
            "Loss:0.041616350450928756\n",
            "Pred:[1 0 1 0 0 0 0 1]\n",
            "True:[1 0 1 0 0 0 0 1]\n",
            "86 + 75 = 161\n",
            "------------\n",
            "iters:4500\n",
            "Loss:0.0155975735342772\n",
            "Pred:[0 1 1 1 0 0 1 1]\n",
            "True:[0 1 1 1 0 0 1 1]\n",
            "16 + 99 = 115\n",
            "------------\n",
            "iters:4600\n",
            "Loss:0.059246574781689564\n",
            "Pred:[0 1 0 1 0 0 0 0]\n",
            "True:[0 1 0 1 0 0 0 0]\n",
            "51 + 29 = 80\n",
            "------------\n",
            "iters:4700\n",
            "Loss:0.08523038201126866\n",
            "Pred:[0 0 1 1 0 1 0 0]\n",
            "True:[0 0 1 1 0 1 0 0]\n",
            "30 + 22 = 52\n",
            "------------\n",
            "iters:4800\n",
            "Loss:0.032316393994590735\n",
            "Pred:[1 0 1 1 0 1 0 1]\n",
            "True:[1 0 1 1 0 1 0 1]\n",
            "80 + 101 = 181\n",
            "------------\n",
            "iters:4900\n",
            "Loss:0.04541548426135803\n",
            "Pred:[1 1 0 0 0 1 1 1]\n",
            "True:[1 1 0 0 0 1 1 1]\n",
            "93 + 106 = 199\n",
            "------------\n",
            "iters:5000\n",
            "Loss:0.04128483565450847\n",
            "Pred:[1 0 1 1 1 0 0 0]\n",
            "True:[1 0 1 1 1 0 0 0]\n",
            "86 + 98 = 184\n",
            "------------\n",
            "iters:5100\n",
            "Loss:0.03813314447139633\n",
            "Pred:[0 0 1 0 1 0 0 0]\n",
            "True:[0 0 1 0 1 0 0 0]\n",
            "14 + 26 = 40\n",
            "------------\n",
            "iters:5200\n",
            "Loss:0.02906529695551374\n",
            "Pred:[0 0 1 0 0 1 1 1]\n",
            "True:[0 0 1 0 0 1 1 1]\n",
            "14 + 25 = 39\n",
            "------------\n",
            "iters:5300\n",
            "Loss:0.009570953908387901\n",
            "Pred:[1 0 1 0 1 1 0 0]\n",
            "True:[1 0 1 0 1 1 0 0]\n",
            "113 + 59 = 172\n",
            "------------\n",
            "iters:5400\n",
            "Loss:0.015636105328158952\n",
            "Pred:[0 0 1 1 0 1 0 0]\n",
            "True:[0 0 1 1 0 1 0 0]\n",
            "52 + 0 = 52\n",
            "------------\n",
            "iters:5500\n",
            "Loss:0.04676896426163175\n",
            "Pred:[0 1 1 0 0 0 0 0]\n",
            "True:[0 1 1 0 0 0 0 0]\n",
            "25 + 71 = 96\n",
            "------------\n",
            "iters:5600\n",
            "Loss:0.00928077148672727\n",
            "Pred:[0 1 1 0 1 0 0 1]\n",
            "True:[0 1 1 0 1 0 0 1]\n",
            "69 + 36 = 105\n",
            "------------\n",
            "iters:5700\n",
            "Loss:0.011794207411391736\n",
            "Pred:[1 0 0 0 1 1 0 1]\n",
            "True:[1 0 0 0 1 1 0 1]\n",
            "26 + 115 = 141\n",
            "------------\n",
            "iters:5800\n",
            "Loss:0.010194589138372748\n",
            "Pred:[1 0 1 1 0 1 0 1]\n",
            "True:[1 0 1 1 0 1 0 1]\n",
            "79 + 102 = 181\n",
            "------------\n",
            "iters:5900\n",
            "Loss:0.010000604805096822\n",
            "Pred:[1 0 0 1 0 1 0 0]\n",
            "True:[1 0 0 1 0 1 0 0]\n",
            "125 + 23 = 148\n",
            "------------\n",
            "iters:6000\n",
            "Loss:0.015446812190847963\n",
            "Pred:[1 0 1 1 0 0 0 0]\n",
            "True:[1 0 1 1 0 0 0 0]\n",
            "102 + 74 = 176\n",
            "------------\n",
            "iters:6100\n",
            "Loss:0.010273898224849568\n",
            "Pred:[1 1 0 1 1 1 1 0]\n",
            "True:[1 1 0 1 1 1 1 0]\n",
            "112 + 110 = 222\n",
            "------------\n",
            "iters:6200\n",
            "Loss:0.003644521251351814\n",
            "Pred:[1 0 0 0 1 1 0 0]\n",
            "True:[1 0 0 0 1 1 0 0]\n",
            "67 + 73 = 140\n",
            "------------\n",
            "iters:6300\n",
            "Loss:0.00905705582280337\n",
            "Pred:[0 1 1 1 1 0 0 1]\n",
            "True:[0 1 1 1 1 0 0 1]\n",
            "88 + 33 = 121\n",
            "------------\n",
            "iters:6400\n",
            "Loss:0.006295134447937876\n",
            "Pred:[0 0 1 0 1 0 0 1]\n",
            "True:[0 0 1 0 1 0 0 1]\n",
            "41 + 0 = 41\n",
            "------------\n",
            "iters:6500\n",
            "Loss:0.00927427558436638\n",
            "Pred:[1 1 0 1 1 0 0 1]\n",
            "True:[1 1 0 1 1 0 0 1]\n",
            "92 + 125 = 217\n",
            "------------\n",
            "iters:6600\n",
            "Loss:0.0025783691256103304\n",
            "Pred:[1 0 1 1 0 0 1 0]\n",
            "True:[1 0 1 1 0 0 1 0]\n",
            "125 + 53 = 178\n",
            "------------\n",
            "iters:6700\n",
            "Loss:0.0038103363765130804\n",
            "Pred:[1 0 0 0 1 0 0 1]\n",
            "True:[1 0 0 0 1 0 0 1]\n",
            "72 + 65 = 137\n",
            "------------\n",
            "iters:6800\n",
            "Loss:0.011065061408459429\n",
            "Pred:[0 1 1 0 1 1 1 1]\n",
            "True:[0 1 1 0 1 1 1 1]\n",
            "29 + 82 = 111\n",
            "------------\n",
            "iters:6900\n",
            "Loss:0.0044117093415465885\n",
            "Pred:[1 0 0 1 1 1 0 0]\n",
            "True:[1 0 0 1 1 1 0 0]\n",
            "111 + 45 = 156\n",
            "------------\n",
            "iters:7000\n",
            "Loss:0.004248701170495086\n",
            "Pred:[0 1 0 0 0 1 1 1]\n",
            "True:[0 1 0 0 0 1 1 1]\n",
            "38 + 33 = 71\n",
            "------------\n",
            "iters:7100\n",
            "Loss:0.005158191317078832\n",
            "Pred:[1 0 1 0 1 1 0 1]\n",
            "True:[1 0 1 0 1 1 0 1]\n",
            "127 + 46 = 173\n",
            "------------\n",
            "iters:7200\n",
            "Loss:0.004405075258018569\n",
            "Pred:[1 0 1 0 0 1 0 1]\n",
            "True:[1 0 1 0 0 1 0 1]\n",
            "76 + 89 = 165\n",
            "------------\n",
            "iters:7300\n",
            "Loss:0.004252220933933296\n",
            "Pred:[0 0 1 1 0 1 0 1]\n",
            "True:[0 0 1 1 0 1 0 1]\n",
            "42 + 11 = 53\n",
            "------------\n",
            "iters:7400\n",
            "Loss:0.005568073465438748\n",
            "Pred:[0 1 0 1 1 1 1 1]\n",
            "True:[0 1 0 1 1 1 1 1]\n",
            "69 + 26 = 95\n",
            "------------\n",
            "iters:7500\n",
            "Loss:0.0037345360141984242\n",
            "Pred:[0 0 1 0 0 1 0 1]\n",
            "True:[0 0 1 0 0 1 0 1]\n",
            "23 + 14 = 37\n",
            "------------\n",
            "iters:7600\n",
            "Loss:0.004743550526268324\n",
            "Pred:[1 1 0 0 0 1 1 0]\n",
            "True:[1 1 0 0 0 1 1 0]\n",
            "112 + 86 = 198\n",
            "------------\n",
            "iters:7700\n",
            "Loss:0.0046688000111777955\n",
            "Pred:[1 0 0 1 0 0 1 0]\n",
            "True:[1 0 0 1 0 0 1 0]\n",
            "46 + 100 = 146\n",
            "------------\n",
            "iters:7800\n",
            "Loss:0.00277803506961026\n",
            "Pred:[1 0 1 0 1 1 0 1]\n",
            "True:[1 0 1 0 1 1 0 1]\n",
            "123 + 50 = 173\n",
            "------------\n",
            "iters:7900\n",
            "Loss:0.005336677256213513\n",
            "Pred:[1 0 0 0 0 1 0 0]\n",
            "True:[1 0 0 0 0 1 0 0]\n",
            "18 + 114 = 132\n",
            "------------\n",
            "iters:8000\n",
            "Loss:0.0022588915935884196\n",
            "Pred:[1 0 0 0 0 1 1 0]\n",
            "True:[1 0 0 0 0 1 1 0]\n",
            "79 + 55 = 134\n",
            "------------\n",
            "iters:8100\n",
            "Loss:0.00240412577532765\n",
            "Pred:[1 1 0 1 1 1 0 1]\n",
            "True:[1 1 0 1 1 1 0 1]\n",
            "118 + 103 = 221\n",
            "------------\n",
            "iters:8200\n",
            "Loss:0.002197206819304079\n",
            "Pred:[0 1 0 1 0 0 0 1]\n",
            "True:[0 1 0 1 0 0 0 1]\n",
            "81 + 0 = 81\n",
            "------------\n",
            "iters:8300\n",
            "Loss:0.004387895592395778\n",
            "Pred:[0 1 0 0 1 0 1 0]\n",
            "True:[0 1 0 0 1 0 1 0]\n",
            "20 + 54 = 74\n",
            "------------\n",
            "iters:8400\n",
            "Loss:0.0021914866355731387\n",
            "Pred:[1 0 0 0 1 0 0 1]\n",
            "True:[1 0 0 0 1 0 0 1]\n",
            "29 + 108 = 137\n",
            "------------\n",
            "iters:8500\n",
            "Loss:0.0021591988970563977\n",
            "Pred:[0 1 0 1 0 0 1 1]\n",
            "True:[0 1 0 1 0 0 1 1]\n",
            "72 + 11 = 83\n",
            "------------\n",
            "iters:8600\n",
            "Loss:0.0039332348130674015\n",
            "Pred:[1 0 0 1 1 0 0 0]\n",
            "True:[1 0 0 1 1 0 0 0]\n",
            "112 + 40 = 152\n",
            "------------\n",
            "iters:8700\n",
            "Loss:0.0015083716964740175\n",
            "Pred:[1 0 0 0 0 1 0 0]\n",
            "True:[1 0 0 0 0 1 0 0]\n",
            "77 + 55 = 132\n",
            "------------\n",
            "iters:8800\n",
            "Loss:0.00382107718079696\n",
            "Pred:[0 1 1 0 0 1 1 0]\n",
            "True:[0 1 1 0 0 1 1 0]\n",
            "88 + 14 = 102\n",
            "------------\n",
            "iters:8900\n",
            "Loss:0.002467733842231788\n",
            "Pred:[0 1 0 1 1 0 0 1]\n",
            "True:[0 1 0 1 1 0 0 1]\n",
            "44 + 45 = 89\n",
            "------------\n",
            "iters:9000\n",
            "Loss:0.002728566646875564\n",
            "Pred:[0 0 1 1 1 1 1 0]\n",
            "True:[0 0 1 1 1 1 1 0]\n",
            "48 + 14 = 62\n",
            "------------\n",
            "iters:9100\n",
            "Loss:0.0020544235966507614\n",
            "Pred:[0 1 1 0 1 0 0 1]\n",
            "True:[0 1 1 0 1 0 0 1]\n",
            "90 + 15 = 105\n",
            "------------\n",
            "iters:9200\n",
            "Loss:0.0018462132049780835\n",
            "Pred:[0 0 1 1 1 0 0 1]\n",
            "True:[0 0 1 1 1 0 0 1]\n",
            "22 + 35 = 57\n",
            "------------\n",
            "iters:9300\n",
            "Loss:0.0019984913079141436\n",
            "Pred:[1 0 0 0 0 1 0 1]\n",
            "True:[1 0 0 0 0 1 0 1]\n",
            "104 + 29 = 133\n",
            "------------\n",
            "iters:9400\n",
            "Loss:0.0014220702290751253\n",
            "Pred:[0 0 1 1 0 1 0 1]\n",
            "True:[0 0 1 1 0 1 0 1]\n",
            "9 + 44 = 53\n",
            "------------\n",
            "iters:9500\n",
            "Loss:0.0018368254744837503\n",
            "Pred:[1 1 0 0 0 0 1 1]\n",
            "True:[1 1 0 0 0 0 1 1]\n",
            "123 + 72 = 195\n",
            "------------\n",
            "iters:9600\n",
            "Loss:0.0013947332541814157\n",
            "Pred:[1 0 1 1 0 1 0 1]\n",
            "True:[1 0 1 1 0 1 0 1]\n",
            "116 + 65 = 181\n",
            "------------\n",
            "iters:9700\n",
            "Loss:0.0005484357525730878\n",
            "Pred:[0 1 1 1 0 1 0 0]\n",
            "True:[0 1 1 1 0 1 0 0]\n",
            "83 + 33 = 116\n",
            "------------\n",
            "iters:9800\n",
            "Loss:0.0016754989116118662\n",
            "Pred:[1 0 0 0 0 1 0 1]\n",
            "True:[1 0 0 0 0 1 0 1]\n",
            "88 + 45 = 133\n",
            "------------\n",
            "iters:9900\n",
            "Loss:0.001382971033479832\n",
            "Pred:[1 1 0 0 0 1 0 1]\n",
            "True:[1 1 0 0 0 1 0 1]\n",
            "82 + 115 = 197\n",
            "------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#重みの初期化方法を変更(Xavier)"
      ],
      "metadata": {
        "id": "D-hM16K_Kd5y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from common import functions\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def d_tanh(x):\n",
        "    return 1/(np.cosh(x) ** 2)\n",
        "\n",
        "# データを用意\n",
        "# 2進数の桁数\n",
        "binary_dim = 8\n",
        "# 最大値 + 1\n",
        "largest_number = pow(2, binary_dim)\n",
        "# largest_numberまで2進数を用意\n",
        "binary = np.unpackbits(np.array([range(largest_number)],dtype=np.uint8).T,axis=1)\n",
        "\n",
        "input_layer_size = 2\n",
        "hidden_layer_size = 16\n",
        "output_layer_size = 1\n",
        "\n",
        "weight_init_std = 1\n",
        "learning_rate = 0.1\n",
        "\n",
        "iters_num = 10000\n",
        "plot_interval = 100\n",
        "\n",
        "# ウェイト初期化\n",
        "# Xavier\n",
        "W_in = np.random.randn(input_layer_size, hidden_layer_size) / (np.sqrt(input_layer_size))\n",
        "W_out = np.random.randn(hidden_layer_size, output_layer_size) / (np.sqrt(hidden_layer_size))\n",
        "W = np.random.randn(hidden_layer_size, hidden_layer_size) / (np.sqrt(hidden_layer_size))\n",
        "\n",
        "\n",
        "# 勾配\n",
        "W_in_grad = np.zeros_like(W_in)\n",
        "W_out_grad = np.zeros_like(W_out)\n",
        "W_grad = np.zeros_like(W)\n",
        "\n",
        "u = np.zeros((hidden_layer_size, binary_dim + 1))\n",
        "z = np.zeros((hidden_layer_size, binary_dim + 1))\n",
        "y = np.zeros((output_layer_size, binary_dim))\n",
        "\n",
        "delta_out = np.zeros((output_layer_size, binary_dim))\n",
        "delta = np.zeros((hidden_layer_size, binary_dim + 1))\n",
        "\n",
        "all_losses = []\n",
        "\n",
        "for i in range(iters_num):\n",
        "    \n",
        "    # A, B初期化 (a + b = d)\n",
        "    a_int = np.random.randint(largest_number/2)\n",
        "    a_bin = binary[a_int] # binary encoding\n",
        "    b_int = np.random.randint(largest_number/2)\n",
        "    b_bin = binary[b_int] # binary encoding\n",
        "    \n",
        "    # 正解データ\n",
        "    d_int = a_int + b_int\n",
        "    d_bin = binary[d_int]\n",
        "    \n",
        "    # 出力バイナリ\n",
        "    out_bin = np.zeros_like(d_bin)\n",
        "    \n",
        "    # 時系列全体の誤差\n",
        "    all_loss = 0    \n",
        "    \n",
        "    # 時系列ループ\n",
        "    for t in range(binary_dim):\n",
        "        # 入力値\n",
        "        X = np.array([a_bin[ - t - 1], b_bin[ - t - 1]]).reshape(1, -1)\n",
        "        # 時刻tにおける正解データ\n",
        "        dd = np.array([d_bin[binary_dim - t - 1]])\n",
        "        \n",
        "        u[:,t+1] = np.dot(X, W_in) + np.dot(z[:,t].reshape(1, -1), W)\n",
        "        z[:,t+1] = functions.sigmoid(u[:,t+1])\n",
        "#         z[:,t+1] = functions.relu(u[:,t+1])\n",
        "#         z[:,t+1] = np.tanh(u[:,t+1])    \n",
        "        y[:,t] = functions.sigmoid(np.dot(z[:,t+1].reshape(1, -1), W_out))\n",
        "\n",
        "\n",
        "        #誤差\n",
        "        loss = functions.mean_squared_error(dd, y[:,t])\n",
        "        \n",
        "        delta_out[:,t] = functions.d_mean_squared_error(dd, y[:,t]) * functions.d_sigmoid(y[:,t])        \n",
        "        \n",
        "        all_loss += loss\n",
        "\n",
        "        out_bin[binary_dim - t - 1] = np.round(y[:,t])\n",
        "    \n",
        "    \n",
        "    for t in range(binary_dim)[::-1]:\n",
        "        X = np.array([a_bin[-t-1],b_bin[-t-1]]).reshape(1, -1)        \n",
        "\n",
        "        delta[:,t] = (np.dot(delta[:,t+1].T, W.T) + np.dot(delta_out[:,t].T, W_out.T)) * functions.d_sigmoid(u[:,t+1])\n",
        "#         delta[:,t] = (np.dot(delta[:,t+1].T, W.T) + np.dot(delta_out[:,t].T, W_out.T)) * functions.d_relu(u[:,t+1])\n",
        "#         delta[:,t] = (np.dot(delta[:,t+1].T, W.T) + np.dot(delta_out[:,t].T, W_out.T)) * d_tanh(u[:,t+1])    \n",
        "\n",
        "        # 勾配更新\n",
        "        W_out_grad += np.dot(z[:,t+1].reshape(-1,1), delta_out[:,t].reshape(-1,1))\n",
        "        W_grad += np.dot(z[:,t].reshape(-1,1), delta[:,t].reshape(1,-1))\n",
        "        W_in_grad += np.dot(X.T, delta[:,t].reshape(1,-1))\n",
        "    \n",
        "    # 勾配適用\n",
        "    W_in -= learning_rate * W_in_grad\n",
        "    W_out -= learning_rate * W_out_grad\n",
        "    W -= learning_rate * W_grad\n",
        "    \n",
        "    W_in_grad *= 0\n",
        "    W_out_grad *= 0\n",
        "    W_grad *= 0\n",
        "    \n",
        "\n",
        "    if(i % plot_interval == 0):\n",
        "        all_losses.append(all_loss)        \n",
        "        print(\"iters:\" + str(i))\n",
        "        print(\"Loss:\" + str(all_loss))\n",
        "        print(\"Pred:\" + str(out_bin))\n",
        "        print(\"True:\" + str(d_bin))\n",
        "        out_int = 0\n",
        "        for index,x in enumerate(reversed(out_bin)):\n",
        "            out_int += x * pow(2, index)\n",
        "        print(str(a_int) + \" + \" + str(b_int) + \" = \" + str(out_int))\n",
        "        print(\"------------\")\n",
        "\n",
        "lists = range(0, iters_num, plot_interval)\n",
        "plt.plot(lists, all_losses, label=\"loss\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7stWXJCUKx9p",
        "outputId": "83a3b78a-baf8-443e-da3f-dceba7b22d25"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iters:0\n",
            "Loss:0.91067418563386\n",
            "Pred:[1 1 1 1 1 1 1 1]\n",
            "True:[1 1 0 0 0 1 1 1]\n",
            "75 + 124 = 255\n",
            "------------\n",
            "iters:100\n",
            "Loss:0.9768967176620593\n",
            "Pred:[1 1 1 1 1 1 1 1]\n",
            "True:[0 1 1 1 0 0 1 1]\n",
            "107 + 8 = 255\n",
            "------------\n",
            "iters:200\n",
            "Loss:1.005295312895308\n",
            "Pred:[0 0 0 0 1 0 0 0]\n",
            "True:[0 0 0 1 0 1 1 1]\n",
            "15 + 8 = 8\n",
            "------------\n",
            "iters:300\n",
            "Loss:0.9961310248796305\n",
            "Pred:[1 1 1 1 1 1 1 1]\n",
            "True:[0 1 1 0 1 1 0 0]\n",
            "54 + 54 = 255\n",
            "------------\n",
            "iters:400\n",
            "Loss:1.0326293792032573\n",
            "Pred:[1 1 1 1 1 1 1 1]\n",
            "True:[1 0 0 0 1 1 1 0]\n",
            "30 + 112 = 255\n",
            "------------\n",
            "iters:500\n",
            "Loss:0.963598347982655\n",
            "Pred:[0 0 1 1 1 1 1 1]\n",
            "True:[0 0 0 1 1 1 0 1]\n",
            "18 + 11 = 63\n",
            "------------\n",
            "iters:600\n",
            "Loss:0.9898961793655133\n",
            "Pred:[0 0 0 0 0 0 0 1]\n",
            "True:[0 0 1 1 0 1 1 1]\n",
            "2 + 53 = 1\n",
            "------------\n",
            "iters:700\n",
            "Loss:0.8220190034490723\n",
            "Pred:[1 1 1 1 1 1 1 1]\n",
            "True:[0 1 1 1 1 1 1 0]\n",
            "55 + 71 = 255\n",
            "------------\n",
            "iters:800\n",
            "Loss:0.9955415505993319\n",
            "Pred:[1 1 1 1 1 1 1 1]\n",
            "True:[0 1 1 0 0 0 0 1]\n",
            "65 + 32 = 255\n",
            "------------\n",
            "iters:900\n",
            "Loss:0.9574322366250202\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 1 0 1 1 0 1 0]\n",
            "53 + 37 = 0\n",
            "------------\n",
            "iters:1000\n",
            "Loss:0.9762698179134324\n",
            "Pred:[0 0 0 0 0 0 1 0]\n",
            "True:[0 1 1 0 0 0 0 0]\n",
            "85 + 11 = 2\n",
            "------------\n",
            "iters:1100\n",
            "Loss:1.021904368636483\n",
            "Pred:[1 0 0 0 1 0 0 1]\n",
            "True:[1 1 0 0 1 1 1 1]\n",
            "118 + 89 = 137\n",
            "------------\n",
            "iters:1200\n",
            "Loss:0.8966578535576463\n",
            "Pred:[1 1 1 1 1 1 1 1]\n",
            "True:[1 1 0 1 1 0 0 1]\n",
            "102 + 115 = 255\n",
            "------------\n",
            "iters:1300\n",
            "Loss:0.8968200603553103\n",
            "Pred:[1 1 1 1 1 1 1 1]\n",
            "True:[1 0 1 1 1 1 0 1]\n",
            "91 + 98 = 255\n",
            "------------\n",
            "iters:1400\n",
            "Loss:1.017320758228967\n",
            "Pred:[0 0 1 1 1 1 0 0]\n",
            "True:[0 1 0 0 0 1 0 0]\n",
            "8 + 60 = 60\n",
            "------------\n",
            "iters:1500\n",
            "Loss:0.8699756581136647\n",
            "Pred:[1 1 1 1 0 0 1 1]\n",
            "True:[0 1 1 1 1 0 1 1]\n",
            "40 + 83 = 243\n",
            "------------\n",
            "iters:1600\n",
            "Loss:0.9736587258815967\n",
            "Pred:[1 1 1 1 0 1 1 1]\n",
            "True:[1 0 1 0 1 1 0 1]\n",
            "122 + 51 = 247\n",
            "------------\n",
            "iters:1700\n",
            "Loss:1.0030586942228636\n",
            "Pred:[0 1 0 1 1 1 1 1]\n",
            "True:[0 1 0 1 0 0 1 0]\n",
            "46 + 36 = 95\n",
            "------------\n",
            "iters:1800\n",
            "Loss:0.9382777452078398\n",
            "Pred:[0 1 1 0 1 0 1 0]\n",
            "True:[0 1 0 1 0 0 1 0]\n",
            "21 + 61 = 106\n",
            "------------\n",
            "iters:1900\n",
            "Loss:1.132380830574118\n",
            "Pred:[1 1 1 1 1 1 1 1]\n",
            "True:[1 0 1 0 0 0 1 1]\n",
            "52 + 111 = 255\n",
            "------------\n",
            "iters:2000\n",
            "Loss:1.0872469011237678\n",
            "Pred:[1 0 1 1 0 1 0 0]\n",
            "True:[0 1 1 0 1 0 0 0]\n",
            "14 + 90 = 180\n",
            "------------\n",
            "iters:2100\n",
            "Loss:1.051535230234053\n",
            "Pred:[0 0 0 0 0 1 1 1]\n",
            "True:[0 0 1 0 1 1 0 0]\n",
            "33 + 11 = 7\n",
            "------------\n",
            "iters:2200\n",
            "Loss:0.8069462302799403\n",
            "Pred:[1 0 0 1 1 1 1 1]\n",
            "True:[0 1 0 1 1 1 0 1]\n",
            "14 + 79 = 159\n",
            "------------\n",
            "iters:2300\n",
            "Loss:0.9313194098268525\n",
            "Pred:[0 1 0 0 0 1 1 1]\n",
            "True:[1 0 0 0 1 1 1 1]\n",
            "40 + 103 = 71\n",
            "------------\n",
            "iters:2400\n",
            "Loss:0.896046760916662\n",
            "Pred:[0 1 1 1 1 1 1 1]\n",
            "True:[0 1 0 0 1 1 1 0]\n",
            "51 + 27 = 127\n",
            "------------\n",
            "iters:2500\n",
            "Loss:0.7646610054607735\n",
            "Pred:[1 1 1 1 1 1 1 1]\n",
            "True:[1 0 1 0 1 1 1 1]\n",
            "109 + 66 = 255\n",
            "------------\n",
            "iters:2600\n",
            "Loss:0.8551626661486347\n",
            "Pred:[1 0 1 1 0 1 0 0]\n",
            "True:[1 0 1 0 0 1 1 1]\n",
            "76 + 91 = 180\n",
            "------------\n",
            "iters:2700\n",
            "Loss:0.9753942704485681\n",
            "Pred:[1 1 0 1 1 0 0 0]\n",
            "True:[0 1 1 1 0 0 0 1]\n",
            "109 + 4 = 216\n",
            "------------\n",
            "iters:2800\n",
            "Loss:0.8059123527007239\n",
            "Pred:[0 0 0 1 0 0 1 0]\n",
            "True:[0 0 0 1 1 1 0 0]\n",
            "11 + 17 = 18\n",
            "------------\n",
            "iters:2900\n",
            "Loss:0.7156833780987012\n",
            "Pred:[0 0 0 0 1 1 0 0]\n",
            "True:[0 0 0 1 1 0 0 0]\n",
            "2 + 22 = 12\n",
            "------------\n",
            "iters:3000\n",
            "Loss:0.5172241245201223\n",
            "Pred:[0 0 0 1 1 1 0 1]\n",
            "True:[0 0 0 1 1 0 0 1]\n",
            "11 + 14 = 29\n",
            "------------\n",
            "iters:3100\n",
            "Loss:0.8155708053031382\n",
            "Pred:[0 0 1 1 1 1 1 1]\n",
            "True:[0 1 0 1 1 1 0 1]\n",
            "5 + 88 = 63\n",
            "------------\n",
            "iters:3200\n",
            "Loss:0.6971089152053943\n",
            "Pred:[1 1 1 1 0 0 1 1]\n",
            "True:[1 0 1 1 0 0 1 1]\n",
            "121 + 58 = 243\n",
            "------------\n",
            "iters:3300\n",
            "Loss:0.4273327792253578\n",
            "Pred:[1 0 0 1 1 1 1 1]\n",
            "True:[1 0 0 0 1 1 1 1]\n",
            "66 + 77 = 159\n",
            "------------\n",
            "iters:3400\n",
            "Loss:0.5488207406446489\n",
            "Pred:[1 1 0 1 0 0 0 0]\n",
            "True:[1 1 0 1 0 0 1 0]\n",
            "110 + 100 = 208\n",
            "------------\n",
            "iters:3500\n",
            "Loss:0.7152868521735649\n",
            "Pred:[0 1 1 1 1 0 1 1]\n",
            "True:[0 1 1 1 1 0 1 1]\n",
            "64 + 59 = 123\n",
            "------------\n",
            "iters:3600\n",
            "Loss:0.44453004339825897\n",
            "Pred:[0 0 0 1 1 0 1 0]\n",
            "True:[0 0 0 1 1 0 1 0]\n",
            "18 + 8 = 26\n",
            "------------\n",
            "iters:3700\n",
            "Loss:0.7375398846932096\n",
            "Pred:[1 0 1 0 1 0 1 0]\n",
            "True:[1 1 0 0 0 0 1 0]\n",
            "119 + 75 = 170\n",
            "------------\n",
            "iters:3800\n",
            "Loss:0.29755859428895115\n",
            "Pred:[0 1 1 1 1 0 1 0]\n",
            "True:[0 1 1 1 1 0 1 0]\n",
            "94 + 28 = 122\n",
            "------------\n",
            "iters:3900\n",
            "Loss:0.39655071128227076\n",
            "Pred:[0 1 1 0 1 0 0 0]\n",
            "True:[0 1 1 0 1 0 0 0]\n",
            "59 + 45 = 104\n",
            "------------\n",
            "iters:4000\n",
            "Loss:0.27596762175100087\n",
            "Pred:[1 1 0 1 1 0 1 1]\n",
            "True:[1 1 0 1 1 0 0 1]\n",
            "104 + 113 = 219\n",
            "------------\n",
            "iters:4100\n",
            "Loss:0.12993656958693853\n",
            "Pred:[1 1 1 0 1 0 1 0]\n",
            "True:[1 1 1 0 1 0 1 0]\n",
            "119 + 115 = 234\n",
            "------------\n",
            "iters:4200\n",
            "Loss:0.339358641913708\n",
            "Pred:[0 1 1 0 1 0 0 1]\n",
            "True:[0 1 1 0 1 0 1 1]\n",
            "30 + 77 = 105\n",
            "------------\n",
            "iters:4300\n",
            "Loss:0.23038189850258034\n",
            "Pred:[1 1 0 1 0 1 1 0]\n",
            "True:[1 1 0 1 0 1 1 0]\n",
            "88 + 126 = 214\n",
            "------------\n",
            "iters:4400\n",
            "Loss:0.08793916691738443\n",
            "Pred:[1 0 1 1 0 1 0 0]\n",
            "True:[1 0 1 1 0 1 0 0]\n",
            "99 + 81 = 180\n",
            "------------\n",
            "iters:4500\n",
            "Loss:0.08402773600058638\n",
            "Pred:[0 1 0 1 0 1 0 0]\n",
            "True:[0 1 0 1 0 1 0 0]\n",
            "4 + 80 = 84\n",
            "------------\n",
            "iters:4600\n",
            "Loss:0.15460790517645376\n",
            "Pred:[1 0 0 1 1 0 1 0]\n",
            "True:[1 0 0 1 1 0 1 0]\n",
            "60 + 94 = 154\n",
            "------------\n",
            "iters:4700\n",
            "Loss:0.0478739890936257\n",
            "Pred:[1 0 1 1 1 0 0 1]\n",
            "True:[1 0 1 1 1 0 0 1]\n",
            "121 + 64 = 185\n",
            "------------\n",
            "iters:4800\n",
            "Loss:0.06756356986487629\n",
            "Pred:[0 1 0 1 0 0 1 1]\n",
            "True:[0 1 0 1 0 0 1 1]\n",
            "13 + 70 = 83\n",
            "------------\n",
            "iters:4900\n",
            "Loss:0.029696396192013266\n",
            "Pred:[0 1 1 0 1 1 0 1]\n",
            "True:[0 1 1 0 1 1 0 1]\n",
            "54 + 55 = 109\n",
            "------------\n",
            "iters:5000\n",
            "Loss:0.043856522749144894\n",
            "Pred:[0 1 0 1 0 0 0 0]\n",
            "True:[0 1 0 1 0 0 0 0]\n",
            "64 + 16 = 80\n",
            "------------\n",
            "iters:5100\n",
            "Loss:0.05175105386397943\n",
            "Pred:[1 0 1 0 1 1 0 0]\n",
            "True:[1 0 1 0 1 1 0 0]\n",
            "104 + 68 = 172\n",
            "------------\n",
            "iters:5200\n",
            "Loss:0.03711454004425725\n",
            "Pred:[1 0 1 0 0 0 0 1]\n",
            "True:[1 0 1 0 0 0 0 1]\n",
            "74 + 87 = 161\n",
            "------------\n",
            "iters:5300\n",
            "Loss:0.03734206123144244\n",
            "Pred:[1 0 0 0 1 1 0 1]\n",
            "True:[1 0 0 0 1 1 0 1]\n",
            "19 + 122 = 141\n",
            "------------\n",
            "iters:5400\n",
            "Loss:0.024239041258126058\n",
            "Pred:[1 0 1 0 0 1 0 1]\n",
            "True:[1 0 1 0 0 1 0 1]\n",
            "83 + 82 = 165\n",
            "------------\n",
            "iters:5500\n",
            "Loss:0.016273312706045564\n",
            "Pred:[0 1 1 0 1 1 1 1]\n",
            "True:[0 1 1 0 1 1 1 1]\n",
            "74 + 37 = 111\n",
            "------------\n",
            "iters:5600\n",
            "Loss:0.02408401736767535\n",
            "Pred:[0 1 1 1 1 0 0 1]\n",
            "True:[0 1 1 1 1 0 0 1]\n",
            "21 + 100 = 121\n",
            "------------\n",
            "iters:5700\n",
            "Loss:0.06300395280843572\n",
            "Pred:[1 0 0 1 0 0 0 0]\n",
            "True:[1 0 0 1 0 0 0 0]\n",
            "102 + 42 = 144\n",
            "------------\n",
            "iters:5800\n",
            "Loss:0.026493916923386672\n",
            "Pred:[1 0 1 1 1 1 1 1]\n",
            "True:[1 0 1 1 1 1 1 1]\n",
            "79 + 112 = 191\n",
            "------------\n",
            "iters:5900\n",
            "Loss:0.016744465002275277\n",
            "Pred:[1 0 0 1 1 0 1 1]\n",
            "True:[1 0 0 1 1 0 1 1]\n",
            "56 + 99 = 155\n",
            "------------\n",
            "iters:6000\n",
            "Loss:0.01809858127638752\n",
            "Pred:[1 1 0 0 0 0 1 1]\n",
            "True:[1 1 0 0 0 0 1 1]\n",
            "77 + 118 = 195\n",
            "------------\n",
            "iters:6100\n",
            "Loss:0.019028272927851614\n",
            "Pred:[0 1 1 0 0 1 1 1]\n",
            "True:[0 1 1 0 0 1 1 1]\n",
            "92 + 11 = 103\n",
            "------------\n",
            "iters:6200\n",
            "Loss:0.016083852927160896\n",
            "Pred:[1 0 0 1 0 1 1 1]\n",
            "True:[1 0 0 1 0 1 1 1]\n",
            "98 + 53 = 151\n",
            "------------\n",
            "iters:6300\n",
            "Loss:0.010924439991429866\n",
            "Pred:[0 1 1 1 0 1 1 1]\n",
            "True:[0 1 1 1 0 1 1 1]\n",
            "92 + 27 = 119\n",
            "------------\n",
            "iters:6400\n",
            "Loss:0.01122226298239856\n",
            "Pred:[0 1 1 0 1 1 1 1]\n",
            "True:[0 1 1 0 1 1 1 1]\n",
            "32 + 79 = 111\n",
            "------------\n",
            "iters:6500\n",
            "Loss:0.01774315498185722\n",
            "Pred:[0 1 0 0 1 0 1 1]\n",
            "True:[0 1 0 0 1 0 1 1]\n",
            "13 + 62 = 75\n",
            "------------\n",
            "iters:6600\n",
            "Loss:0.018746326315704165\n",
            "Pred:[0 0 1 0 1 1 1 0]\n",
            "True:[0 0 1 0 1 1 1 0]\n",
            "20 + 26 = 46\n",
            "------------\n",
            "iters:6700\n",
            "Loss:0.02056940616075143\n",
            "Pred:[0 1 1 1 0 0 1 0]\n",
            "True:[0 1 1 1 0 0 1 0]\n",
            "50 + 64 = 114\n",
            "------------\n",
            "iters:6800\n",
            "Loss:0.00946042546244499\n",
            "Pred:[1 0 0 0 0 1 1 1]\n",
            "True:[1 0 0 0 0 1 1 1]\n",
            "31 + 104 = 135\n",
            "------------\n",
            "iters:6900\n",
            "Loss:0.01721905783453409\n",
            "Pred:[1 0 1 0 1 0 0 0]\n",
            "True:[1 0 1 0 1 0 0 0]\n",
            "104 + 64 = 168\n",
            "------------\n",
            "iters:7000\n",
            "Loss:0.009134452983901916\n",
            "Pred:[0 1 1 0 1 0 0 1]\n",
            "True:[0 1 1 0 1 0 0 1]\n",
            "83 + 22 = 105\n",
            "------------\n",
            "iters:7100\n",
            "Loss:0.015320513026147764\n",
            "Pred:[0 0 1 0 0 1 0 0]\n",
            "True:[0 0 1 0 0 1 0 0]\n",
            "28 + 8 = 36\n",
            "------------\n",
            "iters:7200\n",
            "Loss:0.00813158873666218\n",
            "Pred:[0 1 1 1 0 1 1 1]\n",
            "True:[0 1 1 1 0 1 1 1]\n",
            "64 + 55 = 119\n",
            "------------\n",
            "iters:7300\n",
            "Loss:0.007131688803483925\n",
            "Pred:[1 0 0 0 1 0 0 1]\n",
            "True:[1 0 0 0 1 0 0 1]\n",
            "15 + 122 = 137\n",
            "------------\n",
            "iters:7400\n",
            "Loss:0.015933593594596174\n",
            "Pred:[1 0 1 0 0 0 1 0]\n",
            "True:[1 0 1 0 0 0 1 0]\n",
            "82 + 80 = 162\n",
            "------------\n",
            "iters:7500\n",
            "Loss:0.004758490664425197\n",
            "Pred:[0 1 0 1 1 1 0 1]\n",
            "True:[0 1 0 1 1 1 0 1]\n",
            "30 + 63 = 93\n",
            "------------\n",
            "iters:7600\n",
            "Loss:0.01089695694663858\n",
            "Pred:[0 1 1 0 0 1 0 0]\n",
            "True:[0 1 1 0 0 1 0 0]\n",
            "36 + 64 = 100\n",
            "------------\n",
            "iters:7700\n",
            "Loss:0.004032700034776357\n",
            "Pred:[1 0 1 1 1 1 0 1]\n",
            "True:[1 0 1 1 1 1 0 1]\n",
            "89 + 100 = 189\n",
            "------------\n",
            "iters:7800\n",
            "Loss:0.003714474031569249\n",
            "Pred:[1 0 0 1 1 0 0 1]\n",
            "True:[1 0 0 1 1 0 0 1]\n",
            "84 + 69 = 153\n",
            "------------\n",
            "iters:7900\n",
            "Loss:0.003746250042154255\n",
            "Pred:[0 1 0 1 0 0 1 1]\n",
            "True:[0 1 0 1 0 0 1 1]\n",
            "66 + 17 = 83\n",
            "------------\n",
            "iters:8000\n",
            "Loss:0.001886530181971928\n",
            "Pred:[1 0 0 1 0 1 0 0]\n",
            "True:[1 0 0 1 0 1 0 0]\n",
            "87 + 61 = 148\n",
            "------------\n",
            "iters:8100\n",
            "Loss:0.0015741910037057778\n",
            "Pred:[0 1 0 1 1 0 0 0]\n",
            "True:[0 1 0 1 1 0 0 0]\n",
            "61 + 27 = 88\n",
            "------------\n",
            "iters:8200\n",
            "Loss:0.008945164644870843\n",
            "Pred:[1 0 0 0 1 0 1 0]\n",
            "True:[1 0 0 0 1 0 1 0]\n",
            "32 + 106 = 138\n",
            "------------\n",
            "iters:8300\n",
            "Loss:0.00847562024400186\n",
            "Pred:[0 0 1 0 0 0 1 0]\n",
            "True:[0 0 1 0 0 0 1 0]\n",
            "14 + 20 = 34\n",
            "------------\n",
            "iters:8400\n",
            "Loss:0.007101636126146502\n",
            "Pred:[0 1 1 1 1 1 1 0]\n",
            "True:[0 1 1 1 1 1 1 0]\n",
            "116 + 10 = 126\n",
            "------------\n",
            "iters:8500\n",
            "Loss:0.007320517419664386\n",
            "Pred:[1 0 1 1 1 0 1 0]\n",
            "True:[1 0 1 1 1 0 1 0]\n",
            "96 + 90 = 186\n",
            "------------\n",
            "iters:8600\n",
            "Loss:0.007253130346637601\n",
            "Pred:[1 0 1 1 1 1 1 0]\n",
            "True:[1 0 1 1 1 1 1 0]\n",
            "74 + 116 = 190\n",
            "------------\n",
            "iters:8700\n",
            "Loss:0.0026547759482814957\n",
            "Pred:[0 0 0 0 1 1 0 1]\n",
            "True:[0 0 0 0 1 1 0 1]\n",
            "13 + 0 = 13\n",
            "------------\n",
            "iters:8800\n",
            "Loss:0.002277536329436108\n",
            "Pred:[0 1 1 0 0 1 0 1]\n",
            "True:[0 1 1 0 0 1 0 1]\n",
            "101 + 0 = 101\n",
            "------------\n",
            "iters:8900\n",
            "Loss:0.0006549308098993702\n",
            "Pred:[0 1 1 1 1 0 0 0]\n",
            "True:[0 1 1 1 1 0 0 0]\n",
            "43 + 77 = 120\n",
            "------------\n",
            "iters:9000\n",
            "Loss:0.0027247383532372094\n",
            "Pred:[0 0 1 0 0 1 0 1]\n",
            "True:[0 0 1 0 0 1 0 1]\n",
            "31 + 6 = 37\n",
            "------------\n",
            "iters:9100\n",
            "Loss:0.0021532680599400107\n",
            "Pred:[0 0 0 0 0 1 0 1]\n",
            "True:[0 0 0 0 0 1 0 1]\n",
            "4 + 1 = 5\n",
            "------------\n",
            "iters:9200\n",
            "Loss:0.005722295900849966\n",
            "Pred:[1 0 1 0 0 0 0 0]\n",
            "True:[1 0 1 0 0 0 0 0]\n",
            "48 + 112 = 160\n",
            "------------\n",
            "iters:9300\n",
            "Loss:0.006854244008375366\n",
            "Pred:[0 1 0 0 1 0 0 0]\n",
            "True:[0 1 0 0 1 0 0 0]\n",
            "26 + 46 = 72\n",
            "------------\n",
            "iters:9400\n",
            "Loss:0.001756951886169851\n",
            "Pred:[0 0 1 0 0 1 0 1]\n",
            "True:[0 0 1 0 0 1 0 1]\n",
            "11 + 26 = 37\n",
            "------------\n",
            "iters:9500\n",
            "Loss:0.002744060371479623\n",
            "Pred:[1 0 0 1 1 1 1 1]\n",
            "True:[1 0 0 1 1 1 1 1]\n",
            "78 + 81 = 159\n",
            "------------\n",
            "iters:9600\n",
            "Loss:0.0003290891735287845\n",
            "Pred:[0 0 1 0 1 1 0 0]\n",
            "True:[0 0 1 0 1 1 0 0]\n",
            "33 + 11 = 44\n",
            "------------\n",
            "iters:9700\n",
            "Loss:0.0018612430496242384\n",
            "Pred:[0 1 0 0 1 1 1 1]\n",
            "True:[0 1 0 0 1 1 1 1]\n",
            "76 + 3 = 79\n",
            "------------\n",
            "iters:9800\n",
            "Loss:0.0006608765960262237\n",
            "Pred:[1 1 0 1 0 1 1 0]\n",
            "True:[1 1 0 1 0 1 1 0]\n",
            "91 + 123 = 214\n",
            "------------\n",
            "iters:9900\n",
            "Loss:0.0017004991933936445\n",
            "Pred:[0 1 0 1 1 1 0 1]\n",
            "True:[0 1 0 1 1 1 0 1]\n",
            "49 + 44 = 93\n",
            "------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3de3xcZ3ng8d8z94vuI1myZMuSbwlOArmYkAvhTgi0TdouhaTl1tKmlELp0u1u2O6yLG23u2U/pdCmhHBpF9olSaG0bgibNhAgSeMQhyTGjuNYtmxLsnW3NKPLjOby7h/nnNFIM6NLNGNpRs/389EnM+ccjd6jcZ559JznvK8YY1BKKVVdXOs9AKWUUqWnwV0ppaqQBnellKpCGtyVUqoKaXBXSqkq5FmvH9zc3Gy6urrW68crpVRFeuaZZ0aNMS3LHbduwb2rq4tDhw6t149XSqmKJCJnVnKclmWUUqoKaXBXSqkqpMFdKaWqkAZ3pZSqQhrclVKqCmlwV0qpKqTBXSmlqpAG9w3sn54bYCSWWO9hKKUqkAb3DWpyJsnH7nuO//3w8fUeilKqAmlw36CGY3EA/vnwOaYSqXUejVKq0mhw36BGpqxyzMxcmgefP7fOo1FKVRoN7hvU6NQcALUBD/c93bfOo1FKVRoN7hvUqH0h9QM3dPFc3wQvDkbXeURKqUqiwX2DGplK4HULH7ihC69buF+zd6XUKmhw36BGYwkiYT+RGj83X9bGt58dIJ5Mr/ewlFIVQoP7BjU6laC51gfA7a/ezsRMkoePDq7zqJRSlUKD+wY1OjVHS40fgBt3NdMVCfGlx05hjFnnkSmlKoEG9w1qJJag2Q7uLpfw4Tfu5shAlEePD6/zyJRSlUCD+wZkjGFsOkFzrT+77Reu6mBbY5DPPXJCs3el1LI0uG9Ak7NJkmmTzdwBvG4Xv/3G3TzfP8kPXxpZx9EppSqBBvcNaNS+O7W5xrdg+7+7ehvt9QE+9z3N3pVSS9PgvgGNxKy7U1tyyjIAPo+L33rjbp49O8ETPWPrMTSlVIXQ4L4BOfPKtNT48/a9a/826oNeHjys880opYrT4L4BOVMPNBcI7n6Pm631Acam5y72sJRSFWRTBPdkOrPeQ1iV0akEHpdQH/QW3N8Q8jI5k7zIo1JKVZKqD+7HB2Nc8amHefzE6HoPZcVGpxJEany4XFJwf0PQx4UZzdyVUsVVfXD/y0d7iCcz/MsLpb11f3YuzYUylUZGYom8i6m5GsNeJmY1c1dKFVfVwf3UyBTfOXwOEXjyZGm7S/7DN5/nji8dXPKYmbnUy/qLYXRqrmC93VEf9DE5k9R2SKVUUcsGdxH5qogMi8iRIvtFRD4vIj0iclhEri79MF+eL/zgJF63i1+7sZsTw1MlW2x6JJbg4SODvDQUYy5VvJ5/34/7eM9XnmI4Gl/V649OJZYM7o0hL3PpDDNzOkukUqqwlWTufwPcssT+twN77K87gS+sfVirl84YDp0eJ2VfPO2/MMO3nx3gjms7ufVV7QA8eao02fu3n+0nlTFkDAxMzBY9rmdkCoC+CzMrfm1jzLLBvSFkXWjV0oxSqphlg7sx5kfA+BKH3AZ8zVgOAg0isrVUA1ypv3q0h3fe8yQ3f/ZHHHj+HF/4wUlE4M7X7eSy9jpq/Z6SlGaMMdz/dB+1AQ8Ap8emix7bO2Lt679Q/APg1MgUb/vsj7IrLc1PPeAr+j31QWtfuWr+SqnKV4qaeweQu0xQv70tj4jcKSKHROTQyEjp5kc5PTrNXzzaw7XdTXjdLn7nG8/yd0+dtW7Xbwjicbu4truJgyvM3P/x2QGeKnLsT85e4OTINB96/S4AzowWD+5O4D83UbgsY4zhvx04yvGhGA8+fx6Yn3pgyQuqduY+qZm7UqqIi3pB1RhzrzFmvzFmf0tLS6lek//6T0fwu138xR1X8dDHbuJzt1/JW17RykffvCd73PW7IvSOTnN+0sqiMxnD3Y/20DMcy3vNP/rOMX7v75/PlnhyPfB0PyGfm/ff0EXI5+b0WOGSy+xcmvOTVlAfmCh8zMNHB3nsxCg+j4vHTlgfdtmpB5Ysy9iZu7ZDKqWKKEVwHwC25zzfZm+7KP758HkeOzHKf3jbJbTWBXC7hNuu7ODL799PR0Mwe9z1uyLAfNfM3z51hs88fJxvPrNwqMl0hrHpBP0XZnnoyML2yelEigcPn+NnX7mVGr+HHZEwZ4qUZXLLNQMFyjIzcyk+/c8vcGlbLb/5up0cHpjkwvTc/KRhK8jcJ/RGJqVUEaUI7geA99ldM9cBk8aY8yV43WVNzib5wwdf4JXb6nnPdTuWPPYVbXU0hLw8eXKMs2Mz/MlDLwIwtKiTZXQqgdNh+MUfnlzQbvidw+eZnkvz7ldbn2VdkRBnimTuvXa5pqMhWLAsc/ejPZybjPPp2y7nDZdswRj4t5Nj2Y6eJVshs8F9bZm7MYZMRtsplapGK2mF/AbwJHCJiPSLyAdF5EMi8iH7kIeAU0AP8CXgw2Ub7SLfeqafkViCP/r5y3EXuZvT4XIJr+lu4t9OjvH733wej0vobg4zOLkw8A5FreD61n2tHD0Xzc6+eG5ilj9/5CV2b6nh6s5GAHZEwvRdmClYvnGC+427IwxMzC74kOgbn+FLP+rlF6/q4NruJl61rZ7agIfHToxkpx5oKDL1AFjzy4R87jVn7geeP8f+P35EF95WqgqtpFvmDmPMVmOM1xizzRjzFWPMPcaYe+z9xhjz28aYXcaYK4wxh8o/bMvjPaPsbA7zym0NKzr+hl3NDEzM8lTvOP/1Z/exb2tdXubuPP/Q63eypdbPPT88yehUgvd85Sli8RR//u4rEbE+SLoiIZJpk62t5+odnWZLrZ+9rbVMJVJEZ1PZfQdPjTGXzvBbb7AuynrcLm7YFeGxE6PLTj3gaAiu/S7VQ6cvMD49l/cBp5SqfBV7h2oyneHgqTFu3N284u+5wa67v+GSFn5p/zZa6wIMRuMLsmrnhqPtjSF+7bXdPN4zyi/d8yQDF2b5ygdezeUd9dljd0TCQOF2yNOj03Q1h2m36/65/fAnhqfweVx0N4ez227a08LAxCxPn76wZEnGUR/yrbks4/x1MbjKm6yUUhtfxQb35/ommJlLryq472mt5S/uuIrPvsvKvtvq/czMpZlKzGfVQ9EELoFIjZ9ffk0nNX4PfeMz3PPea7i2u2nB63U1hwAKdsycHpumOxLOXtTNDe7HB2PsaqnB457/9b9uj9U91Ds6vaLg3hjyrrks4wT3xX+9KKUqn2e9B/ByPX5iFJfA9Tsjq/q+n7PvVgVorQsAVnCrDXizj1tq/bhdQl3Ayxffew1ul3BdgZ/TWhvA73Hl9bpH40lGp+bobpnP3M/lZu5DsbwPis5IiM6mEGfHZ1YU3BtCXo4P5rdxrlQ8meac3RaqwV2p6lOxmfvjPaNcsa0h2znycrTZwX1wcn7OmaFYIhv0AW7c3VwwsIN1kXZHJJSXuZ+2g31XJExzjQ+fx5XN3GPxJOcm4+xprc17vZv2WH+FLHUDk6Mh5FvTTUxnx2eyXUG556+Uqg4VGdxj8STP9U1w0ypKMoU4QTy35jwcjbOlNlDsW/LsiIQ5O74wc3fKHTtbwogIHQ3BbK/7S0PWfDOXLBHcl5p6wNEQtMoyL3dmyFP21AgugaGYZu5KVZuKDO5PnRonnTGrqrcX0lY/X5ZxDEXjtNYtnzk7nF733H7x3tFpRKCzyarJdzQEs5n7iSGrlLK3QHB/7Z4WrtvZVPQvhVyNIR+pjFlwveDkyBQ9w1MrGrdzEXhfex1D2i2jVNWpyOD+eM8oAa+Lq3esrAWymIDXTX3Qm20FTKTSXJhJLijLLGdHJEwilVmQ/faOTtNeHyTgdQMLg/vxoRhBr5ttjcG816rxe7jvzusXdOQUU1/gLtW7vnWY93z5KRKp5fvWe0emaa7xsbulRjN3papQRQb3J3pGubY7gt/jXvNrtdUFspm7c3fo6jJ3ux1ydL7ufnp0ekGbY3tDkJFYgkQqzYmhKfa01izbx74c5yan3OB+cmSawWicB57uK/ZtWb1j1hhb6wMMRRO68IdSVabigvtQNM6J4Sleu3t1XTLFWMEtbr+2Fdy3rCpzt0ovzhwzxhh6R6ezbZIAHXaWfn4izktDsYIlmdVqDFt1+YlZq9d9cjbJuD0F8N2Pnlw2e+8dnaYrEqa1NsBcKsMFnadGqapSccH9iR5r2bq11tsdbXX+7AVV5wam1lVcUG1vCOJ1S7ZjZnx6jmg8RXdzTc4x1usdPRdlOJZgb2tNwddaDSdzd4Ky8+Hy3ut2LJu9TyVSjMQSdLeEC153UEpVvooL7gGvm5v2NPOKtrqSvF5rXYCRWIJUOpMNcKspy7hdwvamUDa4Ohcqu3My920N1uMfHB8GCl9MXS1n2t9J+y5V58PlV67rZP+ORv7qB8Wzd6dVszsSzp6r3qWqVHWpuOD+jiu28vUPvmbNNWtHa12AjLEWpR6KJfC6hcbQ8q2IuboiYY6cm+Tbz/bz7WcHstscbfUBROAHL1lztpciuNcvztztgL2jKczvvmUv5yfjPHCov+D3Oq2a3S3h7MXj1a7zqpTa2CouuJdaW06v+5Dd477aD47L2uvoG5/l39//PH978CwNIS/bm+Yzd5/HxZZaPyOxBLV+D1vrV172KcbncRHOmRny9NgMbXUBgj43N+6OcOX2Bv7u4JmC39ub80Hg9PTrjUxKVZeKnX6gVJya8+BknOFogi2rKMk4fvcte/nFq7chWGWahpAXr3vh52ZHQ5ChaII9rTXZWSXXqiHky15QPT02nb24KyK8uquRrz15BmNM3s87PTpNe731QQAQCfu0LKNUldn0mXu2LBGzMvfVXEx1uO254buaw2xvCmXnqcnlzDFTipKMoyFn8rAzY9MLSkGdTSESqUy2vTPXKXvGSkdrXUDLMkpVmU0f3CNhHx6XMDgZX/XdqavhtEOWMrg32tP+xuyJynIDtlMWOjNeZMbKBcHdr5m7UlVm0wd3l0vYUuvnzNgM0XhqVT3uq9FRhsy93s7cnaX+uiLzdX5nrvmziyY1uzA9x8RMckFwb7NvZFJKVY9NH9zBupHp+f4J63GZgvvr97Zw875Wrupc25QJuRpD1mpMTvvljpyyTEdDEBFr9sdcvdlWzfljt9QGGJtOkCywXKBSqjJpcMfqmOm3Z20sV1lmRyTMve/bT9hfumvYDUGrLNNrz/CYe1esz+OivT6YF9yz0xEvytyNoWB9XilVmTS4szBbL1fmXg4NIS8ZA0fOTbKl1k/It/CDw1n8I9epkWnrxqvG+Q+CtgJTHyulKpsGd+bbIWF1Uw+sN+cu1ef6JhZ0yjgKBfcXzkfZ3VKDzzP/1jvtnzr1r1LVQ4M786UYv8dFXbByWv+d+WWGoolsj3uuzkiIkViCmbn5Od+PDExyWcfCqRva6nR+GaWqjQZ35ksxrXWBkt1gdDE0huf76XNr6A6nHbJv3LqeMByNMxxLcHn7wvniG0M+vG5hUDtmlKoaGtyZz1zLdTG1XOqD83PgFCrL7LCDu1OaOXouCpC3GIjVDqo3MilVTTS4M19zL1ePe7k05iwOXrAs07RwrvkjA5MAvGJrfq+93sikVHXR4A6EfB62NQbZu6V0NxhdDM7MkFC4LNMQ8lLr99CXk7l3N4cLTo/QVh9YUXAfn57TVZuUqgArCu4icouIHBeRHhG5q8D+ThF5VESeFZHDIvKO0g+1vB762E18+I271nsYq+Jxu6j1e2iu8VNToH9eROiMzHfMHDk3yWXthefBt+aXWbrmPhyNc+0fP5KdulgptXEtG9xFxA3cDbwd2AfcISL7Fh32X4AHjDFXAbcDf1XqgZZbXSB/JsdK0BD2Lph2YLHOphBnxmeYmJmj/8Js0cW3W+sCTCVSTCVSBfcDnJuMk8oYDvdNrnncSqnyWkk0uxboMcacMsbMAfcBty06xgBOSlgPnCvdENVS3nXNdt61f3vR/Z1NIfrHZ/mpXW8vlrlvsyc2c+rzhcTi1gyUvaNTL3e4SqmLZCVN3R1A7oKc/cBrFh3zKeBfROSjQBh4S6EXEpE7gTsBOjs7VztWVcBH37xnyf2dkRBz6QzfO2Yt8XdZe+HM3dl+9Fy06DGxuJXVO4t9KKU2rlLVIe4A/sYYsw14B/B1Ecl7bWPMvcaY/caY/S0tLSX60WopTsfM/zsySEdDkKZw4SUEdzSFqPF7ODpQvOTiZO6nRqf1oqpSG9xKgvsAkPt3/zZ7W64PAg8AGGOeBAJAcykGqNbGCe6D0XjRkgxYve772us4YvfCF+Jk7rF4itGpudIOVClVUisJ7k8De0SkW0R8WBdMDyw65izwZgAReQVWcNeWig2gvSGI214Ttli5xXF5ez0vnIuSzhTOyqPx+YutWppRamNbNrgbY1LAR4CHgWNYXTFHReTTInKrfdjvAb8hIs8D3wA+YPTv9g3B63bR3mDdnHV5R/HM3dk/m0wXvWDqlGVAL6oqtdGtaJYsY8xDwEOLtn0y5/ELwI2lHZoqlc6mEH3jxdsgHU5mf2Qgyu4CN3RFZ1O01vm5MJ3klGbuSm1oldfYrVbtsvZ6OptCbKldeu6cXS1h/B5XdpqCxWLxJA1BHzsioewCIUqpjaly5rdVL9vH37qX337D7mVnvPS4Xbxiax1HzhUL7ilqAx6awj6tuSu1wWnmvgkEvG7qQ/nzyRRyeUcdRweiZApcVI0lktQGPHS3hDkzNlP0wqtSav1pcFcLXN5eTyyRou/CTN6+WDxFXdDLzuYwc+kM5yZm12GESqmV0OCuFnAuuh4ZyO93d8oy3c01AGu6qPqTsxd4omf0ZX+/UmppGtzVAntaa/C6Ja/ubowhFk9SG/DSbU8v3Dvy8tshP/uvL/En3z22prEqpYrT4K4W8Hvc7G2tzeuYSaQyJNOG2oCH5hoftX7Pmi6qRmeTzMyl1zpcpVQRGtxVnsvb6zl6Lrpg/piofQNTbcCLiNDdEl5TWSYWTzGrwV2pstHgrvJc3lHH+PQc5ybnV2aKzlpTD9QFrO7Z7ubwijL3+58+W7C2Ho2nmE1qcFeqXDS4qzw7W6wLpmfH5jtmYtnMfT64D0zMEl8mQH/m4Zf4+pNn8rZH40nN3JUqIw3uKk9zjXUn69j0/LJ7zoyQzvqr3c1hjCG7hF8hyXSGselEtqTjiCfTzKUyJFKZgv30Sqm10+Cu8kRqrDnfR2OFgruVue902iGXmIZgOJbAGJicXRjcYzmzS2ppRqny0OCu8jSGfLiEBXO2O2WZOjtz395kLcs3sMSNTIN2zT4/uM8/1+CuVHlocFd53C6hKewvUpaxMve6gBeR/MCdayhqBffoUpm71t2VKgsN7qqg5hofI7GFmbsIhH1WcHe5hBq/Jy9w53Iy91gitaC2nluDX+6CrFLq5dHgrgpqrvEzOjWfuUfjKWr8Hlyu+Zkl64PeFWXuxizM1nMf641MSpWHBndVUHONb0Fwj8VT2Xq7oz7oXTpzj+b0yedk67nfozV3pcpDg7sqqLnGz1jOBdVoPJmttzuWy9wHc26Cyj1Ou2WUKj8N7qqgSI2f2WSa6YQViGMFgntdYPmyjLP608LgnlNz17KMUmWhwV0V1Oz0utulGWu63wJlmXjh4G6M4fxknEvarLVYc0sxUa25K1V2GtxVQc12xu30ujtzueeqDxXP3CdnkyRSGfa21mafO6LxJD6P9U9PyzJKlYcGd1VQc9gJ7k7mnsy7oFoX8BBPZkik8gO0czH1kgLBPRZPZcs12gqpVHlocFcFNdfOl2WshToKZO5BK9gXyt6di6k7W8K4XZLXLeMEd72JSany0OCuCorYmfvY1BzxZIZUxuTV3Ovs4O5MB5zL6XFvrQvkddXE4imawj68bmFGM3elykKDuyrI53FRH/QyOpXIm+7XsXTmbpVzWusC1AU8Cz4AovZyfUGvWzN3pcpEg7sqKmLfyBRdNK+MYz5zLxDco3EiYV/2Q2Jx5l4X8BD0ubXmrlSZrCi4i8gtInJcRHpE5K4ix7xLRF4QkaMi8n9LO0y1HqwpCOay9fJCd6hC4cx9KBqntS5gfV9OcM9daDvodWu3jFJl4lnuABFxA3cDbwX6gadF5IAx5oWcY/YAnwBuNMZcEJEt5RqwunhaavwcG4zmzQjpcIJ7oV73wck4bfXzwd2ZGnh6Lk3GQF3QQ8Dr1j53pcpkJZn7tUCPMeaUMWYOuA+4bdExvwHcbYy5AGCMGS7tMNV6iNT4GI3l1twXt0LamfvM0pl77hw0ua8V0rKMUmWzkuDeAfTlPO+3t+XaC+wVkSdE5KCI3FLohUTkThE5JCKHRkZGXt6I1UXTXOMnGk8xPm3dyLQ4c/d5XAS97ryyTCKVZmx6jjanLGNPU2CMyV5YrbVr7npBVanyKNUFVQ+wB3gDcAfwJRFpWHyQMeZeY8x+Y8z+lpaWEv1oVS7OWqq9o9ZSes4F1FyFpiAYjlqdMlvr5zP3ZNoQT2YWrOikNXelymclwX0A2J7zfJu9LVc/cMAYkzTG9AIvYQV7VcGc+WVOj07jEgj73HnHFJoZ0rk7tTUnuIN14TW3fh/QVkilymYlwf1pYI+IdIuID7gdOLDomH/EytoRkWasMs2pEo5TrYNITuZe4/cgInnH1AU9+cHdvjs1W5YJWuWcydnkfOdN0Kq5a+auVHksG9yNMSngI8DDwDHgAWPMURH5tIjcah/2MDAmIi8AjwK/b4wZK9eg1cXRYgf3vguzeRdTHVbmvvAOVefu1La6hZl7NJ5c0DOvZRmlymfZVkgAY8xDwEOLtn0y57EBPm5/qSrhzC+Tzpi8i6mOuqCXY+djC7YNTsYJeF3ZjD1blplJLqi5B3zaCqlUuegdqqqokM/KriH/BiZHoaX2BqNx2uoC2TJOtmVyNkl0NoXP7cJvd9rMpTKkcxbPVkqVhgZ3tSQney+auQe8xBKpBQE6t8cdFpZlnBWdRISQfYFWe92VKj0N7mpJTjtkseDuBO7cpfMGo/N3p+Z+r3VBdX7qYOevAq27K1V6GtzVkpypf5e6oArz88uk0hkGJ+O0NwSzx3jcLmr8HrsVMpntlw84wV3r7kqVnAZ3taQWuyzjXBxdrG5RcB+YmCWZNnRHwguOs2rzqQWLfgR9mrkrVS4a3NWS5ssyK8vcnbtZu5oXBvfagMe+oDq/XJ9Tc9fMXanS0+CulrTSmrszZ8zpbHAP5R0Xte9QdV4roDV3pcpGg7taUqTG6ZZZWeZ+emyGsM+dvQEq9zjrJqZk9rWCWnNXqmw0uKslba23LoxGwr6C+3OnFgCrLNPdEs6bqqAu6GV8eo6ZuXS2LKM1d6XKR4O7WtLVnQ389QdezfU7IwX3B71uvG7Jydyn6Vp0MRWszH04Zs0W6ZRlQl7rv5q5K1V6GtzVkkSEN166BZcrf9IwZ79TckmmM/RfmKW7uXBwd2RbIX3WPz/N3JUqPQ3uas2cxTj6xmdIZ0zBzL0u54Js3k1MmrkrVXIa3NWa1dmdMMXaIAHqQ/OZu96hqlT5aXBXa1a/KLgvW5axL6h63C58bpcGd6XKQIO7WjNnNabTY9PUBTw0hvLbJnNnlcx9HPC6tCyjVBlocFdr5qzGdHp0hu7m/DZIWJi5594QpYtkK1UeGtzVmlndMimrx71AScY5xrEguOtqTEqVhQZ3tWb1QS/pjGFgYrbgxVSYb38M+dx43PP/7II+jwZ3pcpAg7tas9waerHMPeB14/O48lZ0CnpduliHUmWgwV2tWW7JpVCPe+5xiycgC+o6qkqVhQZ3tWYLgnuRzB2sG5nygrtXL6gqVQ6F53FVahWcenpT2Lcg0C+2t7U2vyzj82hZRqky0OCu1swJ6F2R0JLH/dWvXJ23LejVm5iUKgcN7mrNnMx9qZIMULD/PejVmrtS5aA1d7VmtX4PbXUB9u9oWvX3Bnza565UOWjmrtbM5RKeuOtNFJkVeEkhr4e5VIZ0xuB+OS+glCpoRZm7iNwiIsdFpEdE7lriuH8nIkZE9pduiKoSuF1SsOyynKA9p7teVFWqtJYN7iLiBu4G3g7sA+4QkX0FjqsFPgY8VepBqurlTPurdXelSmslmfu1QI8x5pQxZg64D7itwHF/CPwvIF7C8akqF7CDu2buSpXWSoJ7B9CX87zf3pYlIlcD240x31nqhUTkThE5JCKHRkZGVj1YVX1CPnsdVTu4f+3J0/z83U+s44iUqg5r7pYRERfwZ8DvLXesMeZeY8x+Y8z+lpaWtf5oVQWcmrtzl+qjLw7zXN8EkzPJ9RyWUhVvJcF9ANie83ybvc1RC1wO/EBETgPXAQf0oqpaicCimvvxwRgAvWPT6zYmparBSoL708AeEekWER9wO3DA2WmMmTTGNBtjuowxXcBB4FZjzKGyjFhVlWBOzX1yJsm5SeuSzelRDe5KrcWywd0YkwI+AjwMHAMeMMYcFZFPi8it5R6gqm65NffjQ7Hs9lMa3JVakxXdxGSMeQh4aNG2TxY59g1rH5baLJzMfXYuzYuDUQDCPrdm7kqtkd6hqtZVwL6gOpNM8+JgjPqgl1duq+e01tyVWhOdW0atq2zNfS7Ni+ejXNpWS3dzmN6RaYwx6zw6pSqXBne1rpzgPj2X4vhgjEvbaumKhIklUoxNz63z6JSqXBrc1bryuF343C56hqeYnktz6dY6ulusqYN7te6u1MumwV2tu4DXxbNnJwC4pK2W7sjSwf25vgn2/9EjDMd0pgulitHgrtZd0OdmYGIWgEtaa9nWGMTjkqIdM0cGJhmdSnC4b/JiDlOpiqLBXa07p9e9sylE2O/B43bR2RQqmrmP27X4E8NTF22MSlUaDe5q3TlTEFzaVpvd1tUcLhrcx6YSAPRocFeqKA3uat0FvdY/wwXBPRLmzNgMmUx+O6TTRdMzosFdqWI0uKt1F/TZmfvWuuy27pYws8k0QwUumo5NWcH95PCU9sIrVYQGd7Xugl6r5n5JTua+VMeMU3OfSqQYjGrHjFKFaHBX6y7oc+P3uOiyAzpAV3MIgNOjM6wb7JEAABMFSURBVHnHj00n2NlsHat1d6UK0+Cu1t3PvXIrH33Tbtyu+QW22+uD+DwuekcXBu9MxjA+PcdrdjYBcGJIg7tShejEYWrd3XxZGzdf1rZgm8sldEVC9C7K3Cdmk2QM7NlSS0PIqxdVlSpCM3e1YXVFwnmzQ45PW22QkRofu1tq6NHMXamCNLirDau7JcyZsWnSOe2Qo3anTHONnz2tNZq5K1WEBne1YW1vDJFMmwVzyDidMk1hH7taahifnsve1KSUmqfBXW1YHY1BAAYuzGa3OYE8UuNj95YaQDtmlCpEg7vasLY12MF9Iie425l7Y8jHnlarL15LM0rl0+CuNiwnc+9fkLnP0RDy4nW7aK8PEPK5NXNXqgAN7mrDCvk8NIa8CzL38ek5msI+AESEXS01GtyVKkCDu9rQ2huCnMsJ7qNTCZrD/uzzPVs0uCtViAZ3taF1NAQXXFAdn54jUuPLPt+1pYbzk3Fi8eR6DE+pDUuDu9rQOhqDDEzMZmd/HMspywDZjpmTI7reqlK5NLirDa2jIcjMXJqJmSTpjOHCzByRmvmyjDPZWN94/gRjSm1mOreM2tC2Nc63Q6aNwRiI5GTuhTpqlFIrzNxF5BYROS4iPSJyV4H9HxeRF0TksIh8T0R2lH6oajPqaLCm/u2/MJu9OzW35l7j99AQ8jIwoZm7UrmWDe4i4gbuBt4O7APuEJF9iw57FthvjHkl8E3gT0s9ULU5deRk7qP23am5NXewsnvN3JVaaCWZ+7VAjzHmlDFmDrgPuC33AGPMo8YYJ3U6CGwr7TDVZtUY8hL0uhnIydybc2rukN9Ro5RaWXDvAPpynvfb24r5IPDdQjtE5E4ROSQih0ZGRlY+SrVpiQjtDQEGJmaya6fmZ+4h+i/M6nqqSuUoabeMiLwH2A98ptB+Y8y9xpj9xpj9LS0tpfzRqop1NIY4NxFnbHoOEWtemVzbGoPMJtPZzF4ptbLgPgBsz3m+zd62gIi8BfgD4FZjjM7Bqkqmo8HqdR+bStAY8i1Yjs/ZDwsnGFNqs1tJcH8a2CMi3SLiA24HDuQeICJXAV/ECuzDpR+m2sy2NQYZn56j/8LsgjbI+f3zHTVKKcuywd0YkwI+AjwMHAMeMMYcFZFPi8it9mGfAWqAvxeR50TkQJGXU2rVnMz8pwOTefV2yO1113ZIpRwruonJGPMQ8NCibZ/MefyWEo9LqSwneI9Pz+V1ygDUB73UBjzaMaNUDp1+QG14TuYO+Z0yDqdjRill0eCuNrzWukD2Imru3am5OhqK38iUyRju+tZhnuubKNsYldpoNLirDc/tEtrqAgAFL6iCddE1d/bIXMcGo9z3dB8HnjtX1nEqtZFocFcVwam7RwrU3MEK7lOJFJOz+fO6Hzw1DsCJ4Vj5BqjUBqPBXVUEZ7Hs4jX34rNDHjw1BqArNqlNRYO7qghO5t5cpOZerNc9kzH8uHccj0s4Pxknqis2qU1Cg7uqCPu7muhoCNKe0zmTy+moWdzrfmwwyuRskrdd3gZo9q42Dw3uqiK8fm8LT9z1JkK+wrdmNIS8hH3uvMzdqbe/9zpriYGeIQ3uanPQ4K6qgoiwrTGUN7/MwVNj7IiEeHVXEwGvSy+qqk1Dg7uqGh2LFu1w6u3XdUdwu4RdLTW8pJm72iQ0uKuqYa3INF9zd+rt1+1qAmDPlhqtuatNQ4O7qhodDUFi8fled6fe/pruCAB7WmsZmJhlKpFatzEqdbFocFdVw2mHdCYQe8qutzsdNnu21ABwUrN3tQmsaFZIpSrBjogV3N/9xSe5srOBZ89O8DNXbM3u39NaC8BLQzFetb1hXcao1MWimbuqGpe11/H5O67iZ1/VzkgsQTyZ5q37WrP7tzcG8XlcWndXm4Jm7qpqiAi3vqqdW1/VDljdMq6cJfk8bhc7m8Oc0OCuNgHN3FXVci1aaxWs0kxur/s//KSfIwOTF3NYSl0UGtzVprJ3Sw1947PMzKX4yuO9fPyB5/nd+58jk8mfKrjURmIJfvPrh+gb1+UAVflpcFebyp5Wq2Pmc4+c4A8ffIGdzWF6hqf43ovlX9f9K4/38vDRIT7/vRNl/1lKaXBXm8ruLVbHzBd/dIpru5r454++lm2NQe754cmCxx87H+X3//55fu+B59fUHz+VSPF3T53B53bx7WcHdDFvVXYa3NWmsiMSIuB1sbe1hi+9bz9hv4ffuGknz5y5wNOnx7PHPXNmnPd+5Sne/rnHePDweb79bD/v/MK/veygfP/TfcTiKT5/x5WIwBd/eKpUp6RUQRrc1abidbu4787rue/O66kPeQF41/7tNIV93PODkxhj+Orjvbzriwc5PhjjP95yCQc/8Wb+5levZWBiltv+8gkOPH+OH740wvdfHOLoueUvxqbSGb76eC/XdjVxy+Vbeec127j/UB/D0Xi5T1dtYtoKqTadKxfdwBT0uXn/9V189pGX+I2vHeKRY8PcvK+VP3v3ldT4rf9FXre3hW9/+EZ+/f88ze9849kF33/n63by+2+7BK+7cK703SODDEzM8qlbLwPgt16/mwcO9fOlx07xBz+zrwxnqJQGd6UAeN/1O7jnhyd55NgwH3/rXj7yxt15rZS7t9Twnd+5iRfOR3EJuET41k/6ufdHp/hx7zh/ccdVbG8KLfgeYwxfeuwUO5vDvPnSLQB0RkLc+qp2/vbgWX79pp202ot/K1VKUmi1+Ith//795tChQ+vys5Uq5IcvjeB1CTfsbl7V9z14+Byf+NZPyRjDL7+mk1+9sZv2hiBHz03y5cd6+fazA/zxL1zOr7xmR/Z7eoZjvONzj+P3uPjtN+3mAzd0EfC6s/uNMSRSGaYTKWoDXnye1VdQU+kME7NJBifjDMfieN0uXru7GZH8/n9VOUTkGWPM/mWP0+Cu1NqdHZvhM/9ynId+eh7Bulnq2PkoIZ+bO67t5D/dcmlegD4xFON/fvdFvvfiMFvrA3Q0BBmfmWNiJkksniSZtv7f9LiEruYwe1truLqzkTdeuoWdzeEFQTqRSvP9Y8N86ycDPN8/wVQ8xWwynTfOG3dH+OOfv4Ku5jDReJL7f9zHwVNjvOOKrfzcq9qzY+wbn+HJk2Nc291EV3O44DlPzib5x2cHuKStlut2Rkr0m1TLKWlwF5FbgM8BbuDLxpj/uWi/H/gacA0wBrzbGHN6qdfU4K6qUf+FGf76idP8uHecn3vVVt796k7qg94lv+ffeka550enSKUzNIZ9NIa81AW8hP0ewj43w7EELw1N8dJQjLP2DVA7IiF2t9SQyhhSmQxHBqy561vr/LxuTwsNIS81fi/1QQ9t9QG21AU4OjDJn/6/48ylM7x1XyuPvjjM9Fyallo/I7EEbXUBbruqnUOnL/DMmQvZ8d20p5lfvraTvW211AY8CMLfHjzDV5/oJRa32kN/6Zpt/Od3vIKGkJefnJ3goZ+eJ+Rz885rtrEjUvjDYSUmZuY4eGoMEcHncRHwuGkIeWkK+7K/14wxpO2b0EQEtwhBn3upl61oJQvuIuIGXgLeCvQDTwN3GGNeyDnmw8ArjTEfEpHbgV8wxrx7qdfV4K7U6vWNz/CD48M8enyEoWgcj0twu4TOphC/cPU2Xru7GXeBaRccQ9E4nzpwlO+/OMzPXLGVX3ttN5e11/GDl0a494enePLUGJe21XLrle28bk8L339xmG/8+CznJ/M7e265rI3ffP1O/vWFIe790Snqg15Cfjd947P4PC5S6QwZAzfsinDDrghetwuP20Xu8PweN611flrrAkRqfNYxLqFvfJavHzzNPz13jkQqs+rf045IiBt2NXPDrgjtDQH7dV3Uh7w01/jwe9wYYxibnuPcxCzxZAa/x4Xf62J8ao7DA5P8tH+S02PTRONJJmeS+DxuXrenmTdcuoWrtjeQSGWYSqRIpTN0NAZprQ1kr9PMpTJE40nCPg8Bryv7V1YqbX2P3+N+2R9ApQzu1wOfMsa8zX7+CQBjzJ/kHPOwfcyTIuIBBoEWs8SLa3BXav0YYwrW3qPxJHWBhX9ppNIZfnx6nJFYgmg8xexcitfubmFfe132mGPno/yPh47hsidvu/myVqYSKb71TD/3H+qjb3x28Y9aVtDr5uev6uCd13Tg97iZS2eIJ9NMziSz5SsAt8vK1gEMhrlUhuf6Jnjq1DixIjee1QY8zKUyS35wbG8KsrulhoaQj7qAhwszSR47McIF++cu5vO42FLrJzqbJBqf/7k+t4vagIfZZJqZOatU9ie/eAV3XNu56t8JlDa4vxO4xRjz6/bz9wKvMcZ8JOeYI/Yx/fbzk/Yxo4te607gToDOzs5rzpw5s7qzUkpVHGMMc+kMqbQhlTFkMgbnc2VmLs1QNM5QNM74dJJUxjou7Hdzy+Vbly1pLSWVzvDC+SgXZpKk0hmS6QyTs0lGYglGYgl8HhcdDUHaG4KEfB4SqTSJVIYav4crOuppDPvyXjOdMTzfP8HxwRghn5vagAeXCP0XZjk7PsNQNE5D0Eukxk990Mv0nLUyWCyeIui1jq8NeLlxd4RL2+oKjHp5Kw3uF7UV0hhzL3AvWJn7xfzZSqn1ISL4PW78BaJNQ4jsSlml5nG7eOW20i7K4nYJV3c2cnVnY0lftxxW0l81AGzPeb7N3lbwGLssU491YVUppdQ6WElwfxrYIyLdIuIDbgcOLDrmAPB++/E7ge8vVW9XSilVXsuWZYwxKRH5CPAwVivkV40xR0Xk08AhY8wB4CvA10WkBxjH+gBQSim1TlZUczfGPAQ8tGjbJ3Mex4FfKu3QlFJKvVw6K6RSSlUhDe5KKVWFNLgrpVQV0uCulFJVaN1mhRSREeDl3qLaDIwue1T12YznvRnPGTbneW/Gc4bVn/cOY0zLcgetW3BfCxE5tJLbb6vNZjzvzXjOsDnPezOeM5TvvLUso5RSVUiDu1JKVaFKDe73rvcA1slmPO/NeM6wOc97M54zlOm8K7LmrpRSammVmrkrpZRaggZ3pZSqQhUX3EXkFhE5LiI9InLXeo9nLURku4g8KiIviMhREfmYvb1JRP5VRE7Y/220t4uIfN4+98MicnXOa73fPv6EiLy/2M/cKETELSLPisiD9vNuEXnKPrf77emlERG//bzH3t+V8xqfsLcfF5G3rc+ZrJyINIjIN0XkRRE5JiLXV/t7LSL/3v63fUREviEigWp8r0XkqyIybK9K52wr2XsrIteIyE/t7/m8SIE1EhczxlTMF9aUwyeBnYAPeB7Yt97jWsP5bAWuth/XYi1Evg/4U+Aue/tdwP+yH78D+C4gwHXAU/b2JuCU/d9G+3Hjep/fMuf+ceD/Ag/azx8Abrcf3wP8lv34w8A99uPbgfvtx/vs998PdNv/LtzrfV7LnPP/AX7dfuwDGqr5vQY6gF4gmPMef6Aa32vgdcDVwJGcbSV7b4Ef28eK/b1vX3ZM6/1LWeUv8Hrg4ZznnwA+sd7jKuH5/RPwVuA4sNXethU4bj/+InBHzvHH7f13AF/M2b7guI32hbWa1/eANwEP2v9gRwHP4vcZax2B6+3HHvs4Wfze5x63Eb+wVifrxW5iWPweVuN7bQf3PjtYeez3+m3V+l4DXYuCe0neW3vfiznbFxxX7KvSyjLOPxZHv72t4tl/gl4FPAW0GmPO27sGgVb7cbHzr7Tfy58D/xFwlp6PABPGGGfJ+NzxZ8/N3j9pH19p59wNjAB/bZejviwiYar4vTbGDAD/GzgLnMd6756h+t9rR6ne2w778eLtS6q04F6VRKQG+Bbwu8aYaO4+Y31UV02/qoj8LDBsjHlmvcdykXmw/mz/gjHmKmAa60/1rCp8rxuB27A+2NqBMHDLug5qnazHe1tpwX0li3VXFBHxYgX2vzPG/IO9eUhEttr7twLD9vZi519Jv5cbgVtF5DRwH1Zp5nNAg1iLq8PC8RdbfL2SzhmsbKvfGPOU/fybWMG+mt/rtwC9xpgRY0wS+Aes97/a32tHqd7bAfvx4u1LqrTgvpLFuiuGfcX7K8AxY8yf5ezKXXD8/Vi1eGf7++yr7dcBk/affQ8DN4tIo50t3Wxv23CMMZ8wxmwzxnRhvX/fN8b8CvAo1uLqkH/OhRZfPwDcbndYdAN7sC46bUjGmEGgT0QusTe9GXiBKn6vscox14lIyP637pxzVb/XOUry3tr7oiJynf17fF/OaxW33hchXsZFi3dgdZWcBP5gvcezxnN5LdafaoeB5+yvd2DVGb8HnAAeAZrs4wW42z73nwL7c17r14Ae++tX1/vcVnj+b2C+W2Yn1v+wPcDfA357e8B+3mPv35nz/X9g/y6Os4LugfX+Aq4EDtnv9z9idURU9XsN/HfgReAI8HWsjpeqe6+Bb2BdV0hi/ZX2wVK+t8B++3d4EvhLFl2YL/Sl0w8opVQVqrSyjFJKqRXQ4K6UUlVIg7tSSlUhDe5KKVWFNLgrpVQV0uCulFJVSIO7UkpVof8PxF+dL/zb0uMAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#重みの初期化方法を変更(He)\n"
      ],
      "metadata": {
        "id": "Wdkuh0QlM6Qo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from common import functions\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def d_tanh(x):\n",
        "    return 1/(np.cosh(x) ** 2)\n",
        "\n",
        "# データを用意\n",
        "# 2進数の桁数\n",
        "binary_dim = 8\n",
        "# 最大値 + 1\n",
        "largest_number = pow(2, binary_dim)\n",
        "# largest_numberまで2進数を用意\n",
        "binary = np.unpackbits(np.array([range(largest_number)],dtype=np.uint8).T,axis=1)\n",
        "\n",
        "input_layer_size = 2\n",
        "hidden_layer_size = 16\n",
        "output_layer_size = 1\n",
        "\n",
        "weight_init_std = 1\n",
        "learning_rate = 0.1\n",
        "\n",
        "iters_num = 10000\n",
        "plot_interval = 100\n",
        "\n",
        "# ウェイト初期化 \n",
        "# He\n",
        "W_in = np.random.randn(input_layer_size, hidden_layer_size) / (np.sqrt(input_layer_size)) * np.sqrt(2)\n",
        "W_out = np.random.randn(hidden_layer_size, output_layer_size) / (np.sqrt(hidden_layer_size)) * np.sqrt(2)\n",
        "W = np.random.randn(hidden_layer_size, hidden_layer_size) / (np.sqrt(hidden_layer_size)) * np.sqrt(2)\n",
        "\n",
        "\n",
        "# 勾配\n",
        "W_in_grad = np.zeros_like(W_in)\n",
        "W_out_grad = np.zeros_like(W_out)\n",
        "W_grad = np.zeros_like(W)\n",
        "\n",
        "u = np.zeros((hidden_layer_size, binary_dim + 1))\n",
        "z = np.zeros((hidden_layer_size, binary_dim + 1))\n",
        "y = np.zeros((output_layer_size, binary_dim))\n",
        "\n",
        "delta_out = np.zeros((output_layer_size, binary_dim))\n",
        "delta = np.zeros((hidden_layer_size, binary_dim + 1))\n",
        "\n",
        "all_losses = []\n",
        "\n",
        "for i in range(iters_num):\n",
        "    \n",
        "    # A, B初期化 (a + b = d)\n",
        "    a_int = np.random.randint(largest_number/2)\n",
        "    a_bin = binary[a_int] # binary encoding\n",
        "    b_int = np.random.randint(largest_number/2)\n",
        "    b_bin = binary[b_int] # binary encoding\n",
        "    \n",
        "    # 正解データ\n",
        "    d_int = a_int + b_int\n",
        "    d_bin = binary[d_int]\n",
        "    \n",
        "    # 出力バイナリ\n",
        "    out_bin = np.zeros_like(d_bin)\n",
        "    \n",
        "    # 時系列全体の誤差\n",
        "    all_loss = 0    \n",
        "    \n",
        "    # 時系列ループ\n",
        "    for t in range(binary_dim):\n",
        "        # 入力値\n",
        "        X = np.array([a_bin[ - t - 1], b_bin[ - t - 1]]).reshape(1, -1)\n",
        "        # 時刻tにおける正解データ\n",
        "        dd = np.array([d_bin[binary_dim - t - 1]])\n",
        "        \n",
        "        u[:,t+1] = np.dot(X, W_in) + np.dot(z[:,t].reshape(1, -1), W)\n",
        "        z[:,t+1] = functions.sigmoid(u[:,t+1])\n",
        "#         z[:,t+1] = functions.relu(u[:,t+1])\n",
        "#         z[:,t+1] = np.tanh(u[:,t+1])    \n",
        "        y[:,t] = functions.sigmoid(np.dot(z[:,t+1].reshape(1, -1), W_out))\n",
        "\n",
        "\n",
        "        #誤差\n",
        "        loss = functions.mean_squared_error(dd, y[:,t])\n",
        "        \n",
        "        delta_out[:,t] = functions.d_mean_squared_error(dd, y[:,t]) * functions.d_sigmoid(y[:,t])        \n",
        "        \n",
        "        all_loss += loss\n",
        "\n",
        "        out_bin[binary_dim - t - 1] = np.round(y[:,t])\n",
        "    \n",
        "    \n",
        "    for t in range(binary_dim)[::-1]:\n",
        "        X = np.array([a_bin[-t-1],b_bin[-t-1]]).reshape(1, -1)        \n",
        "\n",
        "        delta[:,t] = (np.dot(delta[:,t+1].T, W.T) + np.dot(delta_out[:,t].T, W_out.T)) * functions.d_sigmoid(u[:,t+1])\n",
        "#         delta[:,t] = (np.dot(delta[:,t+1].T, W.T) + np.dot(delta_out[:,t].T, W_out.T)) * functions.d_relu(u[:,t+1])\n",
        "#         delta[:,t] = (np.dot(delta[:,t+1].T, W.T) + np.dot(delta_out[:,t].T, W_out.T)) * d_tanh(u[:,t+1])    \n",
        "\n",
        "        # 勾配更新\n",
        "        W_out_grad += np.dot(z[:,t+1].reshape(-1,1), delta_out[:,t].reshape(-1,1))\n",
        "        W_grad += np.dot(z[:,t].reshape(-1,1), delta[:,t].reshape(1,-1))\n",
        "        W_in_grad += np.dot(X.T, delta[:,t].reshape(1,-1))\n",
        "    \n",
        "    # 勾配適用\n",
        "    W_in -= learning_rate * W_in_grad\n",
        "    W_out -= learning_rate * W_out_grad\n",
        "    W -= learning_rate * W_grad\n",
        "    \n",
        "    W_in_grad *= 0\n",
        "    W_out_grad *= 0\n",
        "    W_grad *= 0\n",
        "    \n",
        "\n",
        "    if(i % plot_interval == 0):\n",
        "        all_losses.append(all_loss)        \n",
        "        print(\"iters:\" + str(i))\n",
        "        print(\"Loss:\" + str(all_loss))\n",
        "        print(\"Pred:\" + str(out_bin))\n",
        "        print(\"True:\" + str(d_bin))\n",
        "        out_int = 0\n",
        "        for index,x in enumerate(reversed(out_bin)):\n",
        "            out_int += x * pow(2, index)\n",
        "        print(str(a_int) + \" + \" + str(b_int) + \" = \" + str(out_int))\n",
        "        print(\"------------\")\n",
        "\n",
        "lists = range(0, iters_num, plot_interval)\n",
        "plt.plot(lists, all_losses, label=\"loss\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "j1uHmfzMM4IY",
        "outputId": "34420f04-4b92-4c92-e04b-6277334182e7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iters:0\n",
            "Loss:1.276521522888044\n",
            "Pred:[1 1 1 1 1 1 1 1]\n",
            "True:[1 0 1 0 0 1 1 0]\n",
            "123 + 43 = 255\n",
            "------------\n",
            "iters:100\n",
            "Loss:1.054167364729869\n",
            "Pred:[1 1 1 1 1 1 1 1]\n",
            "True:[0 1 0 0 0 1 0 1]\n",
            "34 + 35 = 255\n",
            "------------\n",
            "iters:200\n",
            "Loss:1.230499604005018\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[1 0 1 1 1 1 1 0]\n",
            "100 + 90 = 0\n",
            "------------\n",
            "iters:300\n",
            "Loss:1.0244708888577088\n",
            "Pred:[1 1 1 1 1 1 1 1]\n",
            "True:[1 1 0 0 0 1 0 1]\n",
            "76 + 121 = 255\n",
            "------------\n",
            "iters:400\n",
            "Loss:1.0203107465825167\n",
            "Pred:[0 1 1 1 1 1 1 0]\n",
            "True:[1 0 1 1 0 0 0 0]\n",
            "113 + 63 = 126\n",
            "------------\n",
            "iters:500\n",
            "Loss:0.8989330336777318\n",
            "Pred:[1 0 1 1 0 1 1 0]\n",
            "True:[1 0 1 1 0 1 1 0]\n",
            "99 + 83 = 182\n",
            "------------\n",
            "iters:600\n",
            "Loss:1.3556834183657758\n",
            "Pred:[1 1 1 1 1 1 1 1]\n",
            "True:[1 0 0 1 0 0 0 0]\n",
            "87 + 57 = 255\n",
            "------------\n",
            "iters:700\n",
            "Loss:1.0472784963006712\n",
            "Pred:[0 1 1 0 1 1 0 0]\n",
            "True:[1 0 0 0 0 0 0 1]\n",
            "11 + 118 = 108\n",
            "------------\n",
            "iters:800\n",
            "Loss:0.937384526476593\n",
            "Pred:[1 1 1 1 1 1 1 1]\n",
            "True:[1 0 0 1 0 1 1 1]\n",
            "71 + 80 = 255\n",
            "------------\n",
            "iters:900\n",
            "Loss:0.9919128985820922\n",
            "Pred:[0 0 1 0 0 0 0 0]\n",
            "True:[0 1 0 0 1 1 0 1]\n",
            "17 + 60 = 32\n",
            "------------\n",
            "iters:1000\n",
            "Loss:0.8999053393489088\n",
            "Pred:[0 1 0 1 1 1 1 1]\n",
            "True:[0 1 1 0 1 1 1 1]\n",
            "4 + 107 = 95\n",
            "------------\n",
            "iters:1100\n",
            "Loss:1.068670726685515\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[1 0 1 1 0 1 0 0]\n",
            "111 + 69 = 0\n",
            "------------\n",
            "iters:1200\n",
            "Loss:1.094689943942442\n",
            "Pred:[1 1 1 1 1 1 1 1]\n",
            "True:[0 1 1 1 0 0 0 1]\n",
            "30 + 83 = 255\n",
            "------------\n",
            "iters:1300\n",
            "Loss:0.9175858135633845\n",
            "Pred:[1 0 0 1 1 1 1 0]\n",
            "True:[1 0 0 1 0 0 1 0]\n",
            "71 + 75 = 158\n",
            "------------\n",
            "iters:1400\n",
            "Loss:0.7199082845718968\n",
            "Pred:[1 0 0 0 0 0 0 0]\n",
            "True:[1 0 1 1 0 0 0 0]\n",
            "104 + 72 = 128\n",
            "------------\n",
            "iters:1500\n",
            "Loss:0.7295212549971107\n",
            "Pred:[1 1 1 1 1 1 0 0]\n",
            "True:[0 1 1 1 1 1 0 0]\n",
            "92 + 32 = 252\n",
            "------------\n",
            "iters:1600\n",
            "Loss:0.947217697560703\n",
            "Pred:[0 0 1 0 1 1 1 0]\n",
            "True:[0 1 1 1 1 1 1 1]\n",
            "87 + 40 = 46\n",
            "------------\n",
            "iters:1700\n",
            "Loss:1.2618059862666906\n",
            "Pred:[1 1 1 1 1 1 1 1]\n",
            "True:[1 0 1 0 0 0 0 1]\n",
            "107 + 54 = 255\n",
            "------------\n",
            "iters:1800\n",
            "Loss:0.9591688266282662\n",
            "Pred:[0 0 1 1 1 0 0 0]\n",
            "True:[0 1 0 0 1 0 1 0]\n",
            "14 + 60 = 56\n",
            "------------\n",
            "iters:1900\n",
            "Loss:1.0031107974860471\n",
            "Pred:[0 1 1 0 0 1 1 0]\n",
            "True:[1 0 0 0 1 1 1 0]\n",
            "83 + 59 = 102\n",
            "------------\n",
            "iters:2000\n",
            "Loss:0.8452050866829721\n",
            "Pred:[0 0 0 1 0 0 1 1]\n",
            "True:[0 1 0 1 0 1 0 1]\n",
            "12 + 73 = 19\n",
            "------------\n",
            "iters:2100\n",
            "Loss:0.7954751471461613\n",
            "Pred:[0 1 0 0 0 0 0 0]\n",
            "True:[1 0 0 0 1 0 0 0]\n",
            "97 + 39 = 64\n",
            "------------\n",
            "iters:2200\n",
            "Loss:0.7018146276703822\n",
            "Pred:[0 1 1 1 1 0 0 0]\n",
            "True:[0 0 1 1 1 0 0 0]\n",
            "48 + 8 = 120\n",
            "------------\n",
            "iters:2300\n",
            "Loss:0.7955624993891443\n",
            "Pred:[0 0 1 1 1 0 0 0]\n",
            "True:[0 1 0 0 1 0 0 0]\n",
            "60 + 12 = 56\n",
            "------------\n",
            "iters:2400\n",
            "Loss:0.7572084173505904\n",
            "Pred:[0 0 0 1 0 0 0 1]\n",
            "True:[0 0 0 1 1 1 1 1]\n",
            "17 + 14 = 17\n",
            "------------\n",
            "iters:2500\n",
            "Loss:1.073663862761266\n",
            "Pred:[0 1 1 1 1 1 1 0]\n",
            "True:[1 0 0 0 1 1 0 0]\n",
            "125 + 15 = 126\n",
            "------------\n",
            "iters:2600\n",
            "Loss:0.6772538413148532\n",
            "Pred:[1 1 1 1 1 1 1 0]\n",
            "True:[0 1 1 0 1 1 1 0]\n",
            "32 + 78 = 254\n",
            "------------\n",
            "iters:2700\n",
            "Loss:1.1187454891135853\n",
            "Pred:[0 0 1 1 1 1 1 0]\n",
            "True:[0 1 0 0 0 0 1 0]\n",
            "23 + 43 = 62\n",
            "------------\n",
            "iters:2800\n",
            "Loss:0.603626487046806\n",
            "Pred:[0 1 1 1 1 1 0 1]\n",
            "True:[0 1 1 1 1 0 0 1]\n",
            "30 + 91 = 125\n",
            "------------\n",
            "iters:2900\n",
            "Loss:0.7332503622218055\n",
            "Pred:[1 1 1 0 0 1 1 0]\n",
            "True:[0 1 1 1 1 1 1 0]\n",
            "37 + 89 = 230\n",
            "------------\n",
            "iters:3000\n",
            "Loss:0.6957029700678653\n",
            "Pred:[0 0 0 0 0 1 0 0]\n",
            "True:[0 1 0 0 0 0 0 0]\n",
            "31 + 33 = 4\n",
            "------------\n",
            "iters:3100\n",
            "Loss:0.5288446788714706\n",
            "Pred:[0 1 1 1 1 1 0 1]\n",
            "True:[0 1 1 1 1 1 0 1]\n",
            "23 + 102 = 125\n",
            "------------\n",
            "iters:3200\n",
            "Loss:0.8184134024475123\n",
            "Pred:[1 0 0 1 1 0 0 1]\n",
            "True:[1 0 1 0 0 0 0 1]\n",
            "61 + 100 = 153\n",
            "------------\n",
            "iters:3300\n",
            "Loss:0.35473903710528776\n",
            "Pred:[1 0 1 0 1 0 0 0]\n",
            "True:[1 0 1 0 1 0 0 0]\n",
            "74 + 94 = 168\n",
            "------------\n",
            "iters:3400\n",
            "Loss:0.26839264401503077\n",
            "Pred:[0 1 1 1 1 0 1 1]\n",
            "True:[0 1 1 1 1 0 1 1]\n",
            "109 + 14 = 123\n",
            "------------\n",
            "iters:3500\n",
            "Loss:0.5233409456629364\n",
            "Pred:[1 1 0 0 1 0 1 0]\n",
            "True:[1 0 0 0 1 0 1 0]\n",
            "52 + 86 = 202\n",
            "------------\n",
            "iters:3600\n",
            "Loss:0.9350931627341752\n",
            "Pred:[1 0 0 1 1 0 0 0]\n",
            "True:[1 0 1 0 0 0 0 0]\n",
            "98 + 62 = 152\n",
            "------------\n",
            "iters:3700\n",
            "Loss:0.206582132409529\n",
            "Pred:[0 1 1 1 0 0 0 1]\n",
            "True:[0 1 1 1 0 0 0 1]\n",
            "37 + 76 = 113\n",
            "------------\n",
            "iters:3800\n",
            "Loss:0.08027132998439349\n",
            "Pred:[1 0 0 1 0 1 0 1]\n",
            "True:[1 0 0 1 0 1 0 1]\n",
            "33 + 116 = 149\n",
            "------------\n",
            "iters:3900\n",
            "Loss:0.46817545501433455\n",
            "Pred:[0 1 1 1 1 1 1 1]\n",
            "True:[0 1 1 1 1 1 1 1]\n",
            "106 + 21 = 127\n",
            "------------\n",
            "iters:4000\n",
            "Loss:0.06582371971814256\n",
            "Pred:[0 0 1 1 0 1 1 0]\n",
            "True:[0 0 1 1 0 1 1 0]\n",
            "52 + 2 = 54\n",
            "------------\n",
            "iters:4100\n",
            "Loss:0.03710174760516661\n",
            "Pred:[0 0 0 0 0 1 1 0]\n",
            "True:[0 0 0 0 0 1 1 0]\n",
            "2 + 4 = 6\n",
            "------------\n",
            "iters:4200\n",
            "Loss:0.06497819577325425\n",
            "Pred:[0 1 0 1 1 0 0 0]\n",
            "True:[0 1 0 1 1 0 0 0]\n",
            "59 + 29 = 88\n",
            "------------\n",
            "iters:4300\n",
            "Loss:0.027070169100175706\n",
            "Pred:[1 0 1 0 0 0 1 1]\n",
            "True:[1 0 1 0 0 0 1 1]\n",
            "50 + 113 = 163\n",
            "------------\n",
            "iters:4400\n",
            "Loss:0.028728286087460527\n",
            "Pred:[1 0 1 1 0 0 1 1]\n",
            "True:[1 0 1 1 0 0 1 1]\n",
            "120 + 59 = 179\n",
            "------------\n",
            "iters:4500\n",
            "Loss:0.017994359557664895\n",
            "Pred:[1 0 0 0 0 0 1 1]\n",
            "True:[1 0 0 0 0 0 1 1]\n",
            "96 + 35 = 131\n",
            "------------\n",
            "iters:4600\n",
            "Loss:0.02273981114671999\n",
            "Pred:[1 0 1 0 1 1 0 0]\n",
            "True:[1 0 1 0 1 1 0 0]\n",
            "76 + 96 = 172\n",
            "------------\n",
            "iters:4700\n",
            "Loss:0.017132348514602415\n",
            "Pred:[1 1 0 1 0 0 0 0]\n",
            "True:[1 1 0 1 0 0 0 0]\n",
            "97 + 111 = 208\n",
            "------------\n",
            "iters:4800\n",
            "Loss:0.008142254156972104\n",
            "Pred:[0 1 0 1 1 0 1 1]\n",
            "True:[0 1 0 1 1 0 1 1]\n",
            "8 + 83 = 91\n",
            "------------\n",
            "iters:4900\n",
            "Loss:0.00574770001603344\n",
            "Pred:[1 1 0 0 0 1 1 0]\n",
            "True:[1 1 0 0 0 1 1 0]\n",
            "117 + 81 = 198\n",
            "------------\n",
            "iters:5000\n",
            "Loss:0.009823687422099171\n",
            "Pred:[1 0 0 1 0 0 0 0]\n",
            "True:[1 0 0 1 0 0 0 0]\n",
            "115 + 29 = 144\n",
            "------------\n",
            "iters:5100\n",
            "Loss:0.00657571418482572\n",
            "Pred:[0 0 1 0 0 1 1 0]\n",
            "True:[0 0 1 0 0 1 1 0]\n",
            "31 + 7 = 38\n",
            "------------\n",
            "iters:5200\n",
            "Loss:0.01587978595810572\n",
            "Pred:[1 0 1 0 0 0 0 0]\n",
            "True:[1 0 1 0 0 0 0 0]\n",
            "60 + 100 = 160\n",
            "------------\n",
            "iters:5300\n",
            "Loss:0.0025652496343208315\n",
            "Pred:[0 0 1 1 1 1 1 0]\n",
            "True:[0 0 1 1 1 1 1 0]\n",
            "11 + 51 = 62\n",
            "------------\n",
            "iters:5400\n",
            "Loss:0.007245033764893314\n",
            "Pred:[0 1 1 1 1 0 0 1]\n",
            "True:[0 1 1 1 1 0 0 1]\n",
            "102 + 19 = 121\n",
            "------------\n",
            "iters:5500\n",
            "Loss:0.0028154903893880504\n",
            "Pred:[1 0 0 1 0 1 0 0]\n",
            "True:[1 0 0 1 0 1 0 0]\n",
            "75 + 73 = 148\n",
            "------------\n",
            "iters:5600\n",
            "Loss:0.005997439945889853\n",
            "Pred:[0 0 1 1 0 0 1 1]\n",
            "True:[0 0 1 1 0 0 1 1]\n",
            "6 + 45 = 51\n",
            "------------\n",
            "iters:5700\n",
            "Loss:0.011712694737368395\n",
            "Pred:[1 1 0 0 0 0 0 0]\n",
            "True:[1 1 0 0 0 0 0 0]\n",
            "68 + 124 = 192\n",
            "------------\n",
            "iters:5800\n",
            "Loss:0.009478768184176893\n",
            "Pred:[1 1 0 1 1 1 1 0]\n",
            "True:[1 1 0 1 1 1 1 0]\n",
            "104 + 118 = 222\n",
            "------------\n",
            "iters:5900\n",
            "Loss:0.0017181849459950776\n",
            "Pred:[0 1 0 0 1 0 0 0]\n",
            "True:[0 1 0 0 1 0 0 0]\n",
            "3 + 69 = 72\n",
            "------------\n",
            "iters:6000\n",
            "Loss:0.0017593491312421115\n",
            "Pred:[0 1 1 0 0 1 1 0]\n",
            "True:[0 1 1 0 0 1 1 0]\n",
            "39 + 63 = 102\n",
            "------------\n",
            "iters:6100\n",
            "Loss:0.0047076300796360954\n",
            "Pred:[1 0 0 0 0 1 0 1]\n",
            "True:[1 0 0 0 0 1 0 1]\n",
            "15 + 118 = 133\n",
            "------------\n",
            "iters:6200\n",
            "Loss:0.0009357678180470218\n",
            "Pred:[0 1 1 1 1 1 1 0]\n",
            "True:[0 1 1 1 1 1 1 0]\n",
            "67 + 59 = 126\n",
            "------------\n",
            "iters:6300\n",
            "Loss:0.0031401097004175845\n",
            "Pred:[1 1 0 1 0 0 1 1]\n",
            "True:[1 1 0 1 0 0 1 1]\n",
            "113 + 98 = 211\n",
            "------------\n",
            "iters:6400\n",
            "Loss:0.006357231820139407\n",
            "Pred:[0 1 0 1 1 1 0 0]\n",
            "True:[0 1 0 1 1 1 0 0]\n",
            "14 + 78 = 92\n",
            "------------\n",
            "iters:6500\n",
            "Loss:0.00048428902132404745\n",
            "Pred:[1 0 0 1 1 0 1 0]\n",
            "True:[1 0 0 1 1 0 1 0]\n",
            "73 + 81 = 154\n",
            "------------\n",
            "iters:6600\n",
            "Loss:0.008410371930535942\n",
            "Pred:[1 0 1 0 0 1 0 0]\n",
            "True:[1 0 1 0 0 1 0 0]\n",
            "126 + 38 = 164\n",
            "------------\n",
            "iters:6700\n",
            "Loss:0.0013477294457755397\n",
            "Pred:[0 1 1 1 0 1 1 0]\n",
            "True:[0 1 1 1 0 1 1 0]\n",
            "111 + 7 = 118\n",
            "------------\n",
            "iters:6800\n",
            "Loss:0.0024448885830922608\n",
            "Pred:[0 0 1 0 1 1 1 1]\n",
            "True:[0 0 1 0 1 1 1 1]\n",
            "21 + 26 = 47\n",
            "------------\n",
            "iters:6900\n",
            "Loss:0.002214054290069023\n",
            "Pred:[0 1 1 0 1 0 1 1]\n",
            "True:[0 1 1 0 1 0 1 1]\n",
            "1 + 106 = 107\n",
            "------------\n",
            "iters:7000\n",
            "Loss:0.0024353789109568384\n",
            "Pred:[1 0 0 0 0 0 0 1]\n",
            "True:[1 0 0 0 0 0 0 1]\n",
            "45 + 84 = 129\n",
            "------------\n",
            "iters:7100\n",
            "Loss:0.000686687198909984\n",
            "Pred:[1 0 1 1 1 0 1 0]\n",
            "True:[1 0 1 1 1 0 1 0]\n",
            "67 + 119 = 186\n",
            "------------\n",
            "iters:7200\n",
            "Loss:0.0024688435596317963\n",
            "Pred:[0 1 0 0 1 0 1 1]\n",
            "True:[0 1 0 0 1 0 1 1]\n",
            "14 + 61 = 75\n",
            "------------\n",
            "iters:7300\n",
            "Loss:0.0024440146104965535\n",
            "Pred:[1 1 0 1 1 1 0 1]\n",
            "True:[1 1 0 1 1 1 0 1]\n",
            "126 + 95 = 221\n",
            "------------\n",
            "iters:7400\n",
            "Loss:0.00485577367160731\n",
            "Pred:[0 1 0 1 0 0 1 0]\n",
            "True:[0 1 0 1 0 0 1 0]\n",
            "52 + 30 = 82\n",
            "------------\n",
            "iters:7500\n",
            "Loss:0.002067503273318872\n",
            "Pred:[0 1 1 0 0 1 1 1]\n",
            "True:[0 1 1 0 0 1 1 1]\n",
            "24 + 79 = 103\n",
            "------------\n",
            "iters:7600\n",
            "Loss:0.00040556325414090185\n",
            "Pred:[0 1 0 1 1 0 1 0]\n",
            "True:[0 1 0 1 1 0 1 0]\n",
            "85 + 5 = 90\n",
            "------------\n",
            "iters:7700\n",
            "Loss:0.0017934881646948205\n",
            "Pred:[1 0 0 0 0 1 1 1]\n",
            "True:[1 0 0 0 0 1 1 1]\n",
            "41 + 94 = 135\n",
            "------------\n",
            "iters:7800\n",
            "Loss:0.002061180546518408\n",
            "Pred:[1 0 1 0 0 1 1 1]\n",
            "True:[1 0 1 0 0 1 1 1]\n",
            "96 + 71 = 167\n",
            "------------\n",
            "iters:7900\n",
            "Loss:0.003537470895954496\n",
            "Pred:[0 1 0 0 0 0 1 0]\n",
            "True:[0 1 0 0 0 0 1 0]\n",
            "6 + 60 = 66\n",
            "------------\n",
            "iters:8000\n",
            "Loss:0.0037857711750433395\n",
            "Pred:[1 0 1 0 0 0 1 0]\n",
            "True:[1 0 1 0 0 0 1 0]\n",
            "110 + 52 = 162\n",
            "------------\n",
            "iters:8100\n",
            "Loss:0.0033020143699543213\n",
            "Pred:[1 1 0 0 1 0 1 0]\n",
            "True:[1 1 0 0 1 0 1 0]\n",
            "114 + 88 = 202\n",
            "------------\n",
            "iters:8200\n",
            "Loss:0.003153388367235903\n",
            "Pred:[0 1 0 1 1 1 1 0]\n",
            "True:[0 1 0 1 1 1 1 0]\n",
            "34 + 60 = 94\n",
            "------------\n",
            "iters:8300\n",
            "Loss:0.0006670827795836193\n",
            "Pred:[1 0 0 0 0 1 0 0]\n",
            "True:[1 0 0 0 0 1 0 0]\n",
            "21 + 111 = 132\n",
            "------------\n",
            "iters:8400\n",
            "Loss:0.0015003408516764706\n",
            "Pred:[0 1 0 1 0 1 1 1]\n",
            "True:[0 1 0 1 0 1 1 1]\n",
            "38 + 49 = 87\n",
            "------------\n",
            "iters:8500\n",
            "Loss:0.00045292031238197087\n",
            "Pred:[1 1 0 0 1 0 1 0]\n",
            "True:[1 1 0 0 1 0 1 0]\n",
            "93 + 109 = 202\n",
            "------------\n",
            "iters:8600\n",
            "Loss:0.0015386888483417875\n",
            "Pred:[1 0 0 0 0 1 1 1]\n",
            "True:[1 0 0 0 0 1 1 1]\n",
            "20 + 115 = 135\n",
            "------------\n",
            "iters:8700\n",
            "Loss:0.0012565118283797824\n",
            "Pred:[0 1 1 0 1 1 1 1]\n",
            "True:[0 1 1 0 1 1 1 1]\n",
            "76 + 35 = 111\n",
            "------------\n",
            "iters:8800\n",
            "Loss:0.0005005159865161825\n",
            "Pred:[1 0 0 1 1 0 0 0]\n",
            "True:[1 0 0 1 1 0 0 0]\n",
            "89 + 63 = 152\n",
            "------------\n",
            "iters:8900\n",
            "Loss:0.00038089276560940706\n",
            "Pred:[0 1 0 0 0 1 0 0]\n",
            "True:[0 1 0 0 0 1 0 0]\n",
            "11 + 57 = 68\n",
            "------------\n",
            "iters:9000\n",
            "Loss:0.001335483185932051\n",
            "Pred:[0 1 1 1 1 1 1 1]\n",
            "True:[0 1 1 1 1 1 1 1]\n",
            "15 + 112 = 127\n",
            "------------\n",
            "iters:9100\n",
            "Loss:0.00037734575010225316\n",
            "Pred:[0 1 0 0 1 1 0 0]\n",
            "True:[0 1 0 0 1 1 0 0]\n",
            "19 + 57 = 76\n",
            "------------\n",
            "iters:9200\n",
            "Loss:0.0009572831001306498\n",
            "Pred:[0 1 0 1 0 0 1 1]\n",
            "True:[0 1 0 1 0 0 1 1]\n",
            "19 + 64 = 83\n",
            "------------\n",
            "iters:9300\n",
            "Loss:0.0025824011101480107\n",
            "Pred:[0 1 1 1 1 0 1 0]\n",
            "True:[0 1 1 1 1 0 1 0]\n",
            "68 + 54 = 122\n",
            "------------\n",
            "iters:9400\n",
            "Loss:0.001081246895643821\n",
            "Pred:[0 1 1 1 1 1 1 1]\n",
            "True:[0 1 1 1 1 1 1 1]\n",
            "4 + 123 = 127\n",
            "------------\n",
            "iters:9500\n",
            "Loss:0.0003370831381984947\n",
            "Pred:[0 1 0 1 0 0 1 0]\n",
            "True:[0 1 0 1 0 0 1 0]\n",
            "51 + 31 = 82\n",
            "------------\n",
            "iters:9600\n",
            "Loss:0.0011363509364048698\n",
            "Pred:[0 0 1 0 1 0 1 1]\n",
            "True:[0 0 1 0 1 0 1 1]\n",
            "32 + 11 = 43\n",
            "------------\n",
            "iters:9700\n",
            "Loss:0.0008966601549156002\n",
            "Pred:[1 0 0 1 0 0 0 1]\n",
            "True:[1 0 0 1 0 0 0 1]\n",
            "89 + 56 = 145\n",
            "------------\n",
            "iters:9800\n",
            "Loss:0.000155553223641491\n",
            "Pred:[1 0 1 1 1 1 1 0]\n",
            "True:[1 0 1 1 1 1 1 0]\n",
            "69 + 121 = 190\n",
            "------------\n",
            "iters:9900\n",
            "Loss:0.0002929108749966454\n",
            "Pred:[1 0 1 0 1 0 0 0]\n",
            "True:[1 0 1 0 1 0 0 0]\n",
            "51 + 117 = 168\n",
            "------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#中間層の活性化関数を変更\n",
        "ReLU(勾配爆発)"
      ],
      "metadata": {
        "id": "fkxCcI1HKdpD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from common import functions\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def d_tanh(x):\n",
        "    return 1/(np.cosh(x) ** 2)\n",
        "\n",
        "# データを用意\n",
        "# 2進数の桁数\n",
        "binary_dim = 8\n",
        "# 最大値 + 1\n",
        "largest_number = pow(2, binary_dim)\n",
        "# largest_numberまで2進数を用意\n",
        "binary = np.unpackbits(np.array([range(largest_number)],dtype=np.uint8).T,axis=1)\n",
        "\n",
        "input_layer_size = 2\n",
        "hidden_layer_size = 16\n",
        "output_layer_size = 1\n",
        "\n",
        "weight_init_std = 1\n",
        "learning_rate = 0.1\n",
        "\n",
        "iters_num = 10000\n",
        "plot_interval = 100\n",
        "\n",
        "# ウェイト初期化 (バイアスは簡単のため省略)\n",
        "W_in = weight_init_std * np.random.randn(input_layer_size, hidden_layer_size)\n",
        "W_out = weight_init_std * np.random.randn(hidden_layer_size, output_layer_size)\n",
        "W = weight_init_std * np.random.randn(hidden_layer_size, hidden_layer_size)\n",
        "\n",
        "# 勾配\n",
        "W_in_grad = np.zeros_like(W_in)\n",
        "W_out_grad = np.zeros_like(W_out)\n",
        "W_grad = np.zeros_like(W)\n",
        "\n",
        "u = np.zeros((hidden_layer_size, binary_dim + 1))\n",
        "z = np.zeros((hidden_layer_size, binary_dim + 1))\n",
        "y = np.zeros((output_layer_size, binary_dim))\n",
        "\n",
        "delta_out = np.zeros((output_layer_size, binary_dim))\n",
        "delta = np.zeros((hidden_layer_size, binary_dim + 1))\n",
        "\n",
        "all_losses = []\n",
        "\n",
        "for i in range(iters_num):\n",
        "    \n",
        "    # A, B初期化 (a + b = d)\n",
        "    a_int = np.random.randint(largest_number/2)\n",
        "    a_bin = binary[a_int] # binary encoding\n",
        "    b_int = np.random.randint(largest_number/2)\n",
        "    b_bin = binary[b_int] # binary encoding\n",
        "    \n",
        "    # 正解データ\n",
        "    d_int = a_int + b_int\n",
        "    d_bin = binary[d_int]\n",
        "    \n",
        "    # 出力バイナリ\n",
        "    out_bin = np.zeros_like(d_bin)\n",
        "    \n",
        "    # 時系列全体の誤差\n",
        "    all_loss = 0    \n",
        "    \n",
        "    # 時系列ループ\n",
        "    for t in range(binary_dim):\n",
        "        # 入力値\n",
        "        X = np.array([a_bin[ - t - 1], b_bin[ - t - 1]]).reshape(1, -1)\n",
        "        # 時刻tにおける正解データ\n",
        "        dd = np.array([d_bin[binary_dim - t - 1]])\n",
        "        \n",
        "        u[:,t+1] = np.dot(X, W_in) + np.dot(z[:,t].reshape(1, -1), W)\n",
        "        z[:,t+1] = functions.relu(u[:,t+1])\n",
        "#         z[:,t+1] = np.tanh(u[:,t+1])    \n",
        "        y[:,t] = functions.sigmoid(np.dot(z[:,t+1].reshape(1, -1), W_out))\n",
        "\n",
        "\n",
        "        #誤差\n",
        "        loss = functions.mean_squared_error(dd, y[:,t])\n",
        "        \n",
        "        delta_out[:,t] = functions.d_mean_squared_error(dd, y[:,t]) * functions.d_sigmoid(y[:,t])        \n",
        "        \n",
        "        all_loss += loss\n",
        "\n",
        "        out_bin[binary_dim - t - 1] = np.round(y[:,t])\n",
        "    \n",
        "    \n",
        "    for t in range(binary_dim)[::-1]:\n",
        "        X = np.array([a_bin[-t-1],b_bin[-t-1]]).reshape(1, -1)        \n",
        "\n",
        "        delta[:,t] = (np.dot(delta[:,t+1].T, W.T) + np.dot(delta_out[:,t].T, W_out.T)) * functions.d_sigmoid(u[:,t+1])\n",
        "\n",
        "        # 勾配更新\n",
        "        W_out_grad += np.dot(z[:,t+1].reshape(-1,1), delta_out[:,t].reshape(-1,1))\n",
        "        W_grad += np.dot(z[:,t].reshape(-1,1), delta[:,t].reshape(1,-1))\n",
        "        W_in_grad += np.dot(X.T, delta[:,t].reshape(1,-1))\n",
        "    \n",
        "    # 勾配適用\n",
        "    W_in -= learning_rate * W_in_grad\n",
        "    W_out -= learning_rate * W_out_grad\n",
        "    W -= learning_rate * W_grad\n",
        "    \n",
        "    W_in_grad *= 0\n",
        "    W_out_grad *= 0\n",
        "    W_grad *= 0\n",
        "    \n",
        "\n",
        "    if(i % plot_interval == 0):\n",
        "        all_losses.append(all_loss)        \n",
        "        print(\"iters:\" + str(i))\n",
        "        print(\"Loss:\" + str(all_loss))\n",
        "        print(\"Pred:\" + str(out_bin))\n",
        "        print(\"True:\" + str(d_bin))\n",
        "        out_int = 0\n",
        "        for index,x in enumerate(reversed(out_bin)):\n",
        "            out_int += x * pow(2, index)\n",
        "        print(str(a_int) + \" + \" + str(b_int) + \" = \" + str(out_int))\n",
        "        print(\"------------\")\n",
        "\n",
        "lists = range(0, iters_num, plot_interval)\n",
        "plt.plot(lists, all_losses, label=\"loss\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "WfD3RTpjKlkf",
        "outputId": "fa9202f8-c29b-4842-e0a3-0cf47f85e3bd"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/drive/My Drive/DNN_code/common/functions.py:6: RuntimeWarning: overflow encountered in exp\n",
            "  return 1/(1 + np.exp(-x))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iters:0\n",
            "Loss:2.002608951644782\n",
            "Pred:[1 1 1 1 1 0 0 0]\n",
            "True:[0 0 1 1 0 1 0 0]\n",
            "15 + 37 = 248\n",
            "------------\n",
            "iters:100\n",
            "Loss:1.5\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[1 1 0 0 0 0 0 1]\n",
            "106 + 87 = 0\n",
            "------------\n",
            "iters:200\n",
            "Loss:1.5\n",
            "Pred:[1 1 1 1 1 1 1 1]\n",
            "True:[1 0 1 1 1 0 0 1]\n",
            "112 + 73 = 255\n",
            "------------\n",
            "iters:300\n",
            "Loss:1.0\n",
            "Pred:[0 0 0 0 0 0 0 1]\n",
            "True:[0 1 0 0 1 0 0 1]\n",
            "60 + 13 = 1\n",
            "------------\n",
            "iters:400\n",
            "Loss:2.5\n",
            "Pred:[1 1 0 1 1 0 1 0]\n",
            "True:[1 0 1 0 1 1 0 0]\n",
            "121 + 51 = 218\n",
            "------------\n",
            "iters:500\n",
            "Loss:2.625\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 1 1 1 0 1 1 0]\n",
            "14 + 104 = 0\n",
            "------------\n",
            "iters:600\n",
            "Loss:1.5\n",
            "Pred:[1 1 1 1 1 1 1 1]\n",
            "True:[0 1 1 1 0 0 1 1]\n",
            "96 + 19 = 255\n",
            "------------\n",
            "iters:700\n",
            "Loss:2.125\n",
            "Pred:[1 0 0 1 0 0 1 0]\n",
            "True:[0 1 1 1 1 0 1 0]\n",
            "120 + 2 = 146\n",
            "------------\n",
            "iters:800\n",
            "Loss:3.0\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 0 1 1 1 1 1 1]\n",
            "63 + 0 = 0\n",
            "------------\n",
            "iters:900\n",
            "Loss:2.625\n",
            "Pred:[0 0 1 0 0 0 1 0]\n",
            "True:[1 1 0 0 1 1 1 0]\n",
            "96 + 110 = 34\n",
            "------------\n",
            "iters:1000\n",
            "Loss:2.0\n",
            "Pred:[0 1 1 0 0 1 0 1]\n",
            "True:[1 1 0 0 0 1 1 0]\n",
            "111 + 87 = 101\n",
            "------------\n",
            "iters:1100\n",
            "Loss:1.5\n",
            "Pred:[1 1 1 1 1 0 1 0]\n",
            "True:[0 0 1 1 1 0 0 0]\n",
            "49 + 7 = 250\n",
            "------------\n",
            "iters:1200\n",
            "Loss:2.25\n",
            "Pred:[1 1 1 1 1 1 0 0]\n",
            "True:[1 0 0 1 0 0 0 0]\n",
            "68 + 76 = 252\n",
            "------------\n",
            "iters:1300\n",
            "Loss:1.0\n",
            "Pred:[1 1 0 1 1 0 1 0]\n",
            "True:[0 1 0 1 1 1 1 0]\n",
            "55 + 39 = 218\n",
            "------------\n",
            "iters:1400\n",
            "Loss:1.5\n",
            "Pred:[1 1 1 1 0 1 0 1]\n",
            "True:[1 0 0 0 0 1 0 1]\n",
            "74 + 59 = 245\n",
            "------------\n",
            "iters:1500\n",
            "Loss:3.0\n",
            "Pred:[0 0 1 1 0 1 0 1]\n",
            "True:[1 0 0 0 0 0 1 0]\n",
            "21 + 109 = 53\n",
            "------------\n",
            "iters:1600\n",
            "Loss:1.5\n",
            "Pred:[0 1 0 0 1 0 1 0]\n",
            "True:[0 1 1 0 1 0 0 1]\n",
            "53 + 52 = 74\n",
            "------------\n",
            "iters:1700\n",
            "Loss:3.0\n",
            "Pred:[0 1 1 0 1 0 1 0]\n",
            "True:[1 0 1 0 0 1 0 1]\n",
            "101 + 64 = 106\n",
            "------------\n",
            "iters:1800\n",
            "Loss:1.75\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 1 1 0 0 1 0 0]\n",
            "48 + 52 = 0\n",
            "------------\n",
            "iters:1900\n",
            "Loss:1.625\n",
            "Pred:[1 0 1 1 0 1 0 0]\n",
            "True:[1 1 1 0 0 0 0 0]\n",
            "118 + 106 = 180\n",
            "------------\n",
            "iters:2000\n",
            "Loss:0.5\n",
            "Pred:[1 1 0 1 1 0 1 0]\n",
            "True:[0 1 0 1 1 0 1 0]\n",
            "27 + 63 = 218\n",
            "------------\n",
            "iters:2100\n",
            "Loss:2.625\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[1 0 1 1 1 0 1 0]\n",
            "116 + 70 = 0\n",
            "------------\n",
            "iters:2200\n",
            "Loss:1.5\n",
            "Pred:[1 1 1 1 1 0 0 1]\n",
            "True:[1 0 0 1 1 1 0 1]\n",
            "70 + 87 = 249\n",
            "------------\n",
            "iters:2300\n",
            "Loss:2.0\n",
            "Pred:[1 1 1 1 1 1 1 0]\n",
            "True:[1 0 0 1 0 1 0 0]\n",
            "37 + 111 = 254\n",
            "------------\n",
            "iters:2400\n",
            "Loss:2.5\n",
            "Pred:[1 1 1 0 0 1 0 1]\n",
            "True:[0 1 0 1 0 0 0 0]\n",
            "43 + 37 = 229\n",
            "------------\n",
            "iters:2500\n",
            "Loss:2.5\n",
            "Pred:[0 1 1 0 1 1 1 0]\n",
            "True:[1 0 0 1 1 1 1 1]\n",
            "100 + 59 = 110\n",
            "------------\n",
            "iters:2600\n",
            "Loss:2.5\n",
            "Pred:[1 1 1 1 1 1 1 1]\n",
            "True:[1 0 0 1 0 0 1 0]\n",
            "59 + 87 = 255\n",
            "------------\n",
            "iters:2700\n",
            "Loss:2.0\n",
            "Pred:[0 0 0 0 0 1 0 0]\n",
            "True:[0 1 1 0 1 1 0 1]\n",
            "70 + 39 = 4\n",
            "------------\n",
            "iters:2800\n",
            "Loss:2.0\n",
            "Pred:[1 1 1 1 1 1 1 1]\n",
            "True:[1 1 0 0 1 0 0 1]\n",
            "122 + 79 = 255\n",
            "------------\n",
            "iters:2900\n",
            "Loss:1.5\n",
            "Pred:[0 1 1 0 1 1 0 1]\n",
            "True:[1 1 1 0 0 1 0 0]\n",
            "105 + 123 = 109\n",
            "------------\n",
            "iters:3000\n",
            "Loss:2.0\n",
            "Pred:[1 1 1 0 1 0 1 0]\n",
            "True:[1 0 1 0 0 1 1 1]\n",
            "71 + 96 = 234\n",
            "------------\n",
            "iters:3100\n",
            "Loss:1.625\n",
            "Pred:[0 1 0 0 0 0 0 0]\n",
            "True:[1 0 0 1 0 0 0 0]\n",
            "62 + 82 = 64\n",
            "------------\n",
            "iters:3200\n",
            "Loss:2.0\n",
            "Pred:[1 1 1 0 1 1 0 0]\n",
            "True:[0 0 0 1 1 1 0 0]\n",
            "3 + 25 = 236\n",
            "------------\n",
            "iters:3300\n",
            "Loss:1.0\n",
            "Pred:[0 1 1 0 0 1 0 1]\n",
            "True:[0 1 1 0 0 1 1 0]\n",
            "47 + 55 = 101\n",
            "------------\n",
            "iters:3400\n",
            "Loss:2.125\n",
            "Pred:[1 0 0 1 0 1 0 0]\n",
            "True:[0 1 0 1 0 0 1 0]\n",
            "74 + 8 = 148\n",
            "------------\n",
            "iters:3500\n",
            "Loss:3.0\n",
            "Pred:[0 1 1 1 0 1 0 1]\n",
            "True:[1 0 0 1 1 0 1 1]\n",
            "79 + 76 = 117\n",
            "------------\n",
            "iters:3600\n",
            "Loss:2.0\n",
            "Pred:[1 0 1 1 0 1 1 0]\n",
            "True:[0 0 1 0 0 1 0 1]\n",
            "36 + 1 = 182\n",
            "------------\n",
            "iters:3700\n",
            "Loss:2.5\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[1 0 1 1 0 0 1 1]\n",
            "87 + 92 = 0\n",
            "------------\n",
            "iters:3800\n",
            "Loss:1.625\n",
            "Pred:[0 0 1 0 0 1 0 0]\n",
            "True:[0 1 0 1 0 1 0 0]\n",
            "22 + 62 = 36\n",
            "------------\n",
            "iters:3900\n",
            "Loss:2.0\n",
            "Pred:[1 1 0 1 1 0 1 0]\n",
            "True:[1 0 0 0 0 1 1 0]\n",
            "99 + 35 = 218\n",
            "------------\n",
            "iters:4000\n",
            "Loss:1.0\n",
            "Pred:[1 0 0 0 1 0 1 0]\n",
            "True:[1 1 0 0 0 0 1 0]\n",
            "101 + 93 = 138\n",
            "------------\n",
            "iters:4100\n",
            "Loss:0.5\n",
            "Pred:[1 1 1 1 1 0 1 0]\n",
            "True:[1 1 1 0 1 0 1 0]\n",
            "117 + 117 = 250\n",
            "------------\n",
            "iters:4200\n",
            "Loss:2.5\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 1 1 1 0 1 1 0]\n",
            "5 + 113 = 0\n",
            "------------\n",
            "iters:4300\n",
            "Loss:2.5\n",
            "Pred:[1 1 1 0 1 1 1 1]\n",
            "True:[1 1 0 1 0 1 0 0]\n",
            "111 + 101 = 239\n",
            "------------\n",
            "iters:4400\n",
            "Loss:1.625\n",
            "Pred:[0 1 1 0 1 1 0 0]\n",
            "True:[0 1 0 0 1 0 1 0]\n",
            "24 + 50 = 108\n",
            "------------\n",
            "iters:4500\n",
            "Loss:2.0\n",
            "Pred:[1 1 1 0 1 1 1 1]\n",
            "True:[0 1 1 1 1 0 0 1]\n",
            "0 + 121 = 239\n",
            "------------\n",
            "iters:4600\n",
            "Loss:2.0\n",
            "Pred:[1 0 0 0 1 0 1 0]\n",
            "True:[1 0 0 1 0 1 1 1]\n",
            "43 + 108 = 138\n",
            "------------\n",
            "iters:4700\n",
            "Loss:1.5\n",
            "Pred:[1 0 1 1 1 1 1 1]\n",
            "True:[0 1 0 1 1 1 1 1]\n",
            "87 + 8 = 191\n",
            "------------\n",
            "iters:4800\n",
            "Loss:0.625\n",
            "Pred:[0 1 1 0 1 0 1 0]\n",
            "True:[0 1 1 0 0 0 1 0]\n",
            "22 + 76 = 106\n",
            "------------\n",
            "iters:4900\n",
            "Loss:1.125\n",
            "Pred:[1 1 1 0 1 0 1 0]\n",
            "True:[0 1 1 1 1 0 1 0]\n",
            "52 + 70 = 234\n",
            "------------\n",
            "iters:5000\n",
            "Loss:1.5\n",
            "Pred:[1 1 1 1 1 1 1 1]\n",
            "True:[0 1 1 0 0 1 1 1]\n",
            "93 + 10 = 255\n",
            "------------\n",
            "iters:5100\n",
            "Loss:2.0\n",
            "Pred:[1 1 0 1 0 0 1 1]\n",
            "True:[0 1 1 1 0 1 0 1]\n",
            "32 + 85 = 211\n",
            "------------\n",
            "iters:5200\n",
            "Loss:1.0\n",
            "Pred:[1 0 1 1 1 1 1 1]\n",
            "True:[0 0 1 1 1 1 0 1]\n",
            "7 + 54 = 191\n",
            "------------\n",
            "iters:5300\n",
            "Loss:3.5\n",
            "Pred:[0 1 1 0 1 0 1 0]\n",
            "True:[1 1 0 1 0 1 0 1]\n",
            "106 + 107 = 106\n",
            "------------\n",
            "iters:5400\n",
            "Loss:2.0\n",
            "Pred:[0 1 1 0 1 0 1 0]\n",
            "True:[0 1 1 1 1 1 0 1]\n",
            "82 + 43 = 106\n",
            "------------\n",
            "iters:5500\n",
            "Loss:2.5\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 1 1 1 1 0 0 1]\n",
            "93 + 28 = 0\n",
            "------------\n",
            "iters:5600\n",
            "Loss:2.0\n",
            "Pred:[1 1 1 1 0 1 1 1]\n",
            "True:[1 0 1 1 1 0 0 1]\n",
            "77 + 108 = 247\n",
            "------------\n",
            "iters:5700\n",
            "Loss:2.0\n",
            "Pred:[1 1 0 1 1 1 1 0]\n",
            "True:[0 1 1 1 0 1 1 1]\n",
            "98 + 21 = 222\n",
            "------------\n",
            "iters:5800\n",
            "Loss:2.0\n",
            "Pred:[1 0 1 1 0 1 1 1]\n",
            "True:[0 1 1 0 0 1 0 1]\n",
            "53 + 48 = 183\n",
            "------------\n",
            "iters:5900\n",
            "Loss:1.0\n",
            "Pred:[0 0 1 1 0 1 0 1]\n",
            "True:[0 0 1 1 1 1 1 1]\n",
            "17 + 46 = 53\n",
            "------------\n",
            "iters:6000\n",
            "Loss:3.5\n",
            "Pred:[0 0 1 1 1 1 1 1]\n",
            "True:[1 1 0 0 0 0 0 1]\n",
            "75 + 118 = 63\n",
            "------------\n",
            "iters:6100\n",
            "Loss:2.5\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 1 1 1 1 0 1 0]\n",
            "5 + 117 = 0\n",
            "------------\n",
            "iters:6200\n",
            "Loss:2.0\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[1 0 1 0 0 0 1 1]\n",
            "62 + 101 = 0\n",
            "------------\n",
            "iters:6300\n",
            "Loss:2.0\n",
            "Pred:[1 1 1 1 1 1 1 1]\n",
            "True:[1 0 0 0 1 1 1 0]\n",
            "107 + 35 = 255\n",
            "------------\n",
            "iters:6400\n",
            "Loss:2.5\n",
            "Pred:[1 1 1 1 1 1 1 1]\n",
            "True:[0 1 0 0 0 0 1 1]\n",
            "22 + 45 = 255\n",
            "------------\n",
            "iters:6500\n",
            "Loss:2.5\n",
            "Pred:[0 0 0 0 0 0 1 0]\n",
            "True:[0 1 0 1 1 1 1 1]\n",
            "1 + 94 = 2\n",
            "------------\n",
            "iters:6600\n",
            "Loss:1.5\n",
            "Pred:[1 1 0 0 1 0 1 0]\n",
            "True:[1 0 0 0 1 1 1 1]\n",
            "87 + 56 = 202\n",
            "------------\n",
            "iters:6700\n",
            "Loss:2.5\n",
            "Pred:[1 1 1 1 1 1 1 1]\n",
            "True:[0 0 1 0 0 0 1 1]\n",
            "13 + 22 = 255\n",
            "------------\n",
            "iters:6800\n",
            "Loss:2.5\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 1 1 0 1 0 1 1]\n",
            "48 + 59 = 0\n",
            "------------\n",
            "iters:6900\n",
            "Loss:2.0\n",
            "Pred:[1 1 1 0 1 1 1 1]\n",
            "True:[1 0 0 1 1 1 0 1]\n",
            "64 + 93 = 239\n",
            "------------\n",
            "iters:7000\n",
            "Loss:1.5\n",
            "Pred:[0 0 1 1 0 1 1 0]\n",
            "True:[0 0 1 0 0 1 0 1]\n",
            "28 + 9 = 54\n",
            "------------\n",
            "iters:7100\n",
            "Loss:3.0\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[1 1 1 1 0 0 1 1]\n",
            "116 + 127 = 0\n",
            "------------\n",
            "iters:7200\n",
            "Loss:2.5\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 1 1 0 0 1 1 1]\n",
            "14 + 89 = 0\n",
            "------------\n",
            "iters:7300\n",
            "Loss:2.5\n",
            "Pred:[0 0 0 1 0 1 0 0]\n",
            "True:[0 1 1 0 1 1 0 1]\n",
            "106 + 3 = 20\n",
            "------------\n",
            "iters:7400\n",
            "Loss:2.0\n",
            "Pred:[1 1 1 1 1 1 1 1]\n",
            "True:[1 0 0 0 1 1 1 0]\n",
            "89 + 53 = 255\n",
            "------------\n",
            "iters:7500\n",
            "Loss:3.0\n",
            "Pred:[0 1 1 0 1 1 0 1]\n",
            "True:[1 0 0 1 0 1 0 0]\n",
            "65 + 83 = 109\n",
            "------------\n",
            "iters:7600\n",
            "Loss:2.0\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 1 0 1 1 0 0 1]\n",
            "86 + 3 = 0\n",
            "------------\n",
            "iters:7700\n",
            "Loss:1.75\n",
            "Pred:[0 1 1 0 0 1 0 0]\n",
            "True:[1 0 1 1 0 1 0 0]\n",
            "88 + 92 = 100\n",
            "------------\n",
            "iters:7800\n",
            "Loss:2.125\n",
            "Pred:[1 1 1 1 1 1 0 0]\n",
            "True:[1 0 0 1 0 1 1 0]\n",
            "90 + 60 = 252\n",
            "------------\n",
            "iters:7900\n",
            "Loss:2.0\n",
            "Pred:[1 1 1 0 1 0 1 0]\n",
            "True:[0 0 1 0 1 0 0 1]\n",
            "21 + 20 = 234\n",
            "------------\n",
            "iters:8000\n",
            "Loss:0.625\n",
            "Pred:[0 1 1 0 1 0 1 0]\n",
            "True:[0 1 1 1 1 0 1 0]\n",
            "90 + 32 = 106\n",
            "------------\n",
            "iters:8100\n",
            "Loss:1.0\n",
            "Pred:[1 1 1 1 1 1 1 1]\n",
            "True:[1 1 0 1 1 1 1 0]\n",
            "105 + 117 = 255\n",
            "------------\n",
            "iters:8200\n",
            "Loss:2.0\n",
            "Pred:[0 0 1 1 0 1 0 1]\n",
            "True:[0 1 1 0 0 0 1 1]\n",
            "39 + 60 = 53\n",
            "------------\n",
            "iters:8300\n",
            "Loss:2.5\n",
            "Pred:[1 0 1 1 0 0 1 0]\n",
            "True:[1 0 0 0 1 0 0 1]\n",
            "24 + 113 = 178\n",
            "------------\n",
            "iters:8400\n",
            "Loss:2.0\n",
            "Pred:[0 1 1 0 1 0 0 1]\n",
            "True:[1 1 0 1 0 0 0 1]\n",
            "100 + 109 = 105\n",
            "------------\n",
            "iters:8500\n",
            "Loss:1.625\n",
            "Pred:[0 1 1 1 1 0 1 0]\n",
            "True:[0 0 0 1 1 1 1 0]\n",
            "6 + 24 = 122\n",
            "------------\n",
            "iters:8600\n",
            "Loss:2.5\n",
            "Pred:[1 1 0 0 1 0 1 0]\n",
            "True:[1 0 1 1 0 0 1 1]\n",
            "101 + 78 = 202\n",
            "------------\n",
            "iters:8700\n",
            "Loss:2.5\n",
            "Pred:[1 0 0 0 1 0 1 0]\n",
            "True:[1 0 1 1 0 1 1 1]\n",
            "81 + 102 = 138\n",
            "------------\n",
            "iters:8800\n",
            "Loss:1.0\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[1 0 1 0 0 0 0 0]\n",
            "123 + 37 = 0\n",
            "------------\n",
            "iters:8900\n",
            "Loss:1.125\n",
            "Pred:[1 1 1 1 1 1 1 0]\n",
            "True:[1 0 1 1 0 1 1 0]\n",
            "104 + 78 = 254\n",
            "------------\n",
            "iters:9000\n",
            "Loss:1.5\n",
            "Pred:[1 0 0 1 0 0 0 1]\n",
            "True:[0 1 0 1 0 0 1 1]\n",
            "4 + 79 = 145\n",
            "------------\n",
            "iters:9100\n",
            "Loss:1.125\n",
            "Pred:[1 1 0 1 0 1 0 0]\n",
            "True:[0 1 0 1 1 1 0 0]\n",
            "66 + 26 = 212\n",
            "------------\n",
            "iters:9200\n",
            "Loss:2.5\n",
            "Pred:[0 0 0 0 0 0 1 0]\n",
            "True:[1 0 1 0 0 1 0 1]\n",
            "69 + 96 = 2\n",
            "------------\n",
            "iters:9300\n",
            "Loss:2.125\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 1 0 0 1 1 1 0]\n",
            "16 + 62 = 0\n",
            "------------\n",
            "iters:9400\n",
            "Loss:2.0\n",
            "Pred:[0 0 1 0 0 1 0 0]\n",
            "True:[1 0 0 1 0 1 0 1]\n",
            "38 + 111 = 36\n",
            "------------\n",
            "iters:9500\n",
            "Loss:3.5\n",
            "Pred:[0 1 1 0 0 1 0 1]\n",
            "True:[1 0 0 1 1 0 0 0]\n",
            "75 + 77 = 101\n",
            "------------\n",
            "iters:9600\n",
            "Loss:2.0\n",
            "Pred:[0 1 0 0 1 0 0 0]\n",
            "True:[1 0 0 1 1 1 0 0]\n",
            "119 + 37 = 72\n",
            "------------\n",
            "iters:9700\n",
            "Loss:1.5\n",
            "Pred:[0 1 1 1 0 1 0 1]\n",
            "True:[0 1 1 0 1 1 1 1]\n",
            "1 + 110 = 117\n",
            "------------\n",
            "iters:9800\n",
            "Loss:1.25\n",
            "Pred:[1 1 1 1 0 1 0 0]\n",
            "True:[1 0 1 1 0 0 0 0]\n",
            "52 + 124 = 244\n",
            "------------\n",
            "iters:9900\n",
            "Loss:3.0\n",
            "Pred:[0 1 1 1 1 0 1 0]\n",
            "True:[1 0 0 1 0 0 0 1]\n",
            "50 + 95 = 122\n",
            "------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from common import functions\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def d_tanh(x):\n",
        "    return 1/(np.cosh(x) ** 2)\n",
        "\n",
        "# データを用意\n",
        "# 2進数の桁数\n",
        "binary_dim = 8\n",
        "# 最大値 + 1\n",
        "largest_number = pow(2, binary_dim)\n",
        "# largest_numberまで2進数を用意\n",
        "binary = np.unpackbits(np.array([range(largest_number)],dtype=np.uint8).T,axis=1)\n",
        "\n",
        "input_layer_size = 2\n",
        "hidden_layer_size = 16\n",
        "output_layer_size = 1\n",
        "\n",
        "weight_init_std = 1\n",
        "learning_rate = 0.1\n",
        "\n",
        "iters_num = 10000\n",
        "plot_interval = 100\n",
        "\n",
        "# ウェイト初期化 (バイアスは簡単のため省略)\n",
        "W_in = weight_init_std * np.random.randn(input_layer_size, hidden_layer_size)\n",
        "W_out = weight_init_std * np.random.randn(hidden_layer_size, output_layer_size)\n",
        "W = weight_init_std * np.random.randn(hidden_layer_size, hidden_layer_size)\n",
        "\n",
        "# 勾配\n",
        "W_in_grad = np.zeros_like(W_in)\n",
        "W_out_grad = np.zeros_like(W_out)\n",
        "W_grad = np.zeros_like(W)\n",
        "\n",
        "u = np.zeros((hidden_layer_size, binary_dim + 1))\n",
        "z = np.zeros((hidden_layer_size, binary_dim + 1))\n",
        "y = np.zeros((output_layer_size, binary_dim))\n",
        "\n",
        "delta_out = np.zeros((output_layer_size, binary_dim))\n",
        "delta = np.zeros((hidden_layer_size, binary_dim + 1))\n",
        "\n",
        "all_losses = []\n",
        "\n",
        "for i in range(iters_num):\n",
        "    \n",
        "    # A, B初期化 (a + b = d)\n",
        "    a_int = np.random.randint(largest_number/2)\n",
        "    a_bin = binary[a_int] # binary encoding\n",
        "    b_int = np.random.randint(largest_number/2)\n",
        "    b_bin = binary[b_int] # binary encoding\n",
        "    \n",
        "    # 正解データ\n",
        "    d_int = a_int + b_int\n",
        "    d_bin = binary[d_int]\n",
        "    \n",
        "    # 出力バイナリ\n",
        "    out_bin = np.zeros_like(d_bin)\n",
        "    \n",
        "    # 時系列全体の誤差\n",
        "    all_loss = 0    \n",
        "    \n",
        "    # 時系列ループ\n",
        "    for t in range(binary_dim):\n",
        "        # 入力値\n",
        "        X = np.array([a_bin[ - t - 1], b_bin[ - t - 1]]).reshape(1, -1)\n",
        "        # 時刻tにおける正解データ\n",
        "        dd = np.array([d_bin[binary_dim - t - 1]])\n",
        "        \n",
        "        u[:,t+1] = np.dot(X, W_in) + np.dot(z[:,t].reshape(1, -1), W)\n",
        "        z[:,t+1] = np.tanh(u[:,t+1])    \n",
        "        y[:,t] = functions.sigmoid(np.dot(z[:,t+1].reshape(1, -1), W_out))\n",
        "\n",
        "\n",
        "        #誤差\n",
        "        loss = functions.mean_squared_error(dd, y[:,t])\n",
        "        \n",
        "        delta_out[:,t] = functions.d_mean_squared_error(dd, y[:,t]) * functions.d_sigmoid(y[:,t])        \n",
        "        \n",
        "        all_loss += loss\n",
        "\n",
        "        out_bin[binary_dim - t - 1] = np.round(y[:,t])\n",
        "    \n",
        "    \n",
        "    for t in range(binary_dim)[::-1]:\n",
        "        X = np.array([a_bin[-t-1],b_bin[-t-1]]).reshape(1, -1)        \n",
        "\n",
        "        delta[:,t] = (np.dot(delta[:,t+1].T, W.T) + np.dot(delta_out[:,t].T, W_out.T)) * functions.d_sigmoid(u[:,t+1])\n",
        "\n",
        "        # 勾配更新\n",
        "        W_out_grad += np.dot(z[:,t+1].reshape(-1,1), delta_out[:,t].reshape(-1,1))\n",
        "        W_grad += np.dot(z[:,t].reshape(-1,1), delta[:,t].reshape(1,-1))\n",
        "        W_in_grad += np.dot(X.T, delta[:,t].reshape(1,-1))\n",
        "    \n",
        "    # 勾配適用\n",
        "    W_in -= learning_rate * W_in_grad\n",
        "    W_out -= learning_rate * W_out_grad\n",
        "    W -= learning_rate * W_grad\n",
        "    \n",
        "    W_in_grad *= 0\n",
        "    W_out_grad *= 0\n",
        "    W_grad *= 0\n",
        "    \n",
        "\n",
        "    if(i % plot_interval == 0):\n",
        "        all_losses.append(all_loss)        \n",
        "        print(\"iters:\" + str(i))\n",
        "        print(\"Loss:\" + str(all_loss))\n",
        "        print(\"Pred:\" + str(out_bin))\n",
        "        print(\"True:\" + str(d_bin))\n",
        "        out_int = 0\n",
        "        for index,x in enumerate(reversed(out_bin)):\n",
        "            out_int += x * pow(2, index)\n",
        "        print(str(a_int) + \" + \" + str(b_int) + \" = \" + str(out_int))\n",
        "        print(\"------------\")\n",
        "\n",
        "lists = range(0, iters_num, plot_interval)\n",
        "plt.plot(lists, all_losses, label=\"loss\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "9aNllNWLNlaE",
        "outputId": "836497be-bdc0-41ce-9c8b-4e7d74cb28fb"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iters:0\n",
            "Loss:2.728614847877323\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 1 0 1 1 1 1 1]\n",
            "34 + 61 = 0\n",
            "------------\n",
            "iters:100\n",
            "Loss:1.2517127884750272\n",
            "Pred:[1 1 0 1 0 0 1 0]\n",
            "True:[0 1 1 0 1 0 0 1]\n",
            "74 + 31 = 210\n",
            "------------\n",
            "iters:200\n",
            "Loss:1.400496818272857\n",
            "Pred:[1 1 1 1 0 1 0 0]\n",
            "True:[0 0 1 0 1 0 1 0]\n",
            "9 + 33 = 244\n",
            "------------\n",
            "iters:300\n",
            "Loss:0.8745152985167266\n",
            "Pred:[0 0 1 1 1 1 1 0]\n",
            "True:[0 1 1 1 1 0 1 0]\n",
            "72 + 50 = 62\n",
            "------------\n",
            "iters:400\n",
            "Loss:1.0602426010691817\n",
            "Pred:[0 0 0 1 1 0 0 0]\n",
            "True:[1 0 0 0 0 1 0 0]\n",
            "12 + 120 = 24\n",
            "------------\n",
            "iters:500\n",
            "Loss:0.8464283247569667\n",
            "Pred:[0 1 0 0 0 1 1 0]\n",
            "True:[0 1 0 0 1 0 1 0]\n",
            "30 + 44 = 70\n",
            "------------\n",
            "iters:600\n",
            "Loss:0.9904097829647989\n",
            "Pred:[0 1 0 1 1 1 1 1]\n",
            "True:[1 0 0 0 1 0 1 1]\n",
            "80 + 59 = 95\n",
            "------------\n",
            "iters:700\n",
            "Loss:1.0117310587307669\n",
            "Pred:[1 0 1 1 1 1 1 1]\n",
            "True:[0 1 1 1 1 0 1 1]\n",
            "70 + 53 = 191\n",
            "------------\n",
            "iters:800\n",
            "Loss:0.9478720429804004\n",
            "Pred:[1 1 1 0 0 1 1 0]\n",
            "True:[0 0 0 0 0 1 1 0]\n",
            "5 + 1 = 230\n",
            "------------\n",
            "iters:900\n",
            "Loss:0.8947740589169705\n",
            "Pred:[1 0 0 0 0 1 0 0]\n",
            "True:[0 1 0 0 1 0 0 0]\n",
            "50 + 22 = 132\n",
            "------------\n",
            "iters:1000\n",
            "Loss:1.1156634152932599\n",
            "Pred:[1 0 1 0 0 0 0 0]\n",
            "True:[0 0 0 0 0 1 1 0]\n",
            "6 + 0 = 160\n",
            "------------\n",
            "iters:1100\n",
            "Loss:1.120833008141597\n",
            "Pred:[0 1 1 1 1 0 0 1]\n",
            "True:[1 0 1 1 0 1 1 1]\n",
            "76 + 107 = 121\n",
            "------------\n",
            "iters:1200\n",
            "Loss:1.0632326156011147\n",
            "Pred:[0 0 0 1 1 1 1 1]\n",
            "True:[0 1 1 1 1 1 0 1]\n",
            "118 + 7 = 31\n",
            "------------\n",
            "iters:1300\n",
            "Loss:1.254612071134982\n",
            "Pred:[1 0 0 0 0 0 0 0]\n",
            "True:[0 1 1 1 0 1 0 0]\n",
            "12 + 104 = 128\n",
            "------------\n",
            "iters:1400\n",
            "Loss:0.8121263210907377\n",
            "Pred:[0 1 1 1 1 1 0 0]\n",
            "True:[0 1 0 1 0 1 0 0]\n",
            "28 + 56 = 124\n",
            "------------\n",
            "iters:1500\n",
            "Loss:1.0216660328184406\n",
            "Pred:[0 0 0 0 1 0 1 0]\n",
            "True:[0 1 0 0 0 1 0 0]\n",
            "61 + 7 = 10\n",
            "------------\n",
            "iters:1600\n",
            "Loss:0.8514874456169736\n",
            "Pred:[1 1 1 1 1 0 1 0]\n",
            "True:[0 1 1 0 1 0 1 0]\n",
            "70 + 36 = 250\n",
            "------------\n",
            "iters:1700\n",
            "Loss:1.12667295735266\n",
            "Pred:[1 1 1 0 1 0 1 0]\n",
            "True:[1 0 0 0 1 1 0 0]\n",
            "26 + 114 = 234\n",
            "------------\n",
            "iters:1800\n",
            "Loss:0.9272926640841415\n",
            "Pred:[1 0 1 1 0 1 1 0]\n",
            "True:[0 0 1 1 0 1 0 0]\n",
            "14 + 38 = 182\n",
            "------------\n",
            "iters:1900\n",
            "Loss:0.8088386728166952\n",
            "Pred:[1 1 1 1 1 0 1 1]\n",
            "True:[1 1 0 1 1 0 0 1]\n",
            "120 + 97 = 251\n",
            "------------\n",
            "iters:2000\n",
            "Loss:0.6681985476825474\n",
            "Pred:[0 0 1 1 1 1 0 1]\n",
            "True:[0 1 1 1 1 1 0 1]\n",
            "53 + 72 = 61\n",
            "------------\n",
            "iters:2100\n",
            "Loss:1.3112765892147138\n",
            "Pred:[0 1 1 1 1 1 1 0]\n",
            "True:[1 0 0 0 0 1 0 1]\n",
            "30 + 103 = 126\n",
            "------------\n",
            "iters:2200\n",
            "Loss:1.2586994676704633\n",
            "Pred:[1 0 1 1 0 1 1 0]\n",
            "True:[0 1 1 0 1 0 0 0]\n",
            "6 + 98 = 182\n",
            "------------\n",
            "iters:2300\n",
            "Loss:1.1317296128607266\n",
            "Pred:[1 1 1 1 1 1 1 0]\n",
            "True:[0 1 0 0 1 0 0 0]\n",
            "9 + 63 = 254\n",
            "------------\n",
            "iters:2400\n",
            "Loss:1.185590850497985\n",
            "Pred:[0 1 0 0 0 1 1 1]\n",
            "True:[1 0 1 0 1 1 0 1]\n",
            "51 + 122 = 71\n",
            "------------\n",
            "iters:2500\n",
            "Loss:1.1274370981104398\n",
            "Pred:[0 1 1 0 1 1 1 1]\n",
            "True:[1 0 0 0 0 1 0 1]\n",
            "104 + 29 = 111\n",
            "------------\n",
            "iters:2600\n",
            "Loss:1.2496161714881444\n",
            "Pred:[1 1 0 0 0 1 1 0]\n",
            "True:[0 0 1 0 1 1 1 1]\n",
            "7 + 40 = 198\n",
            "------------\n",
            "iters:2700\n",
            "Loss:0.9731364585217722\n",
            "Pred:[0 1 0 0 0 1 1 1]\n",
            "True:[0 1 1 0 1 0 0 1]\n",
            "11 + 94 = 71\n",
            "------------\n",
            "iters:2800\n",
            "Loss:1.0003205363622936\n",
            "Pred:[1 0 1 1 1 1 0 1]\n",
            "True:[1 0 0 1 0 0 0 1]\n",
            "103 + 42 = 189\n",
            "------------\n",
            "iters:2900\n",
            "Loss:1.2130113787268377\n",
            "Pred:[0 1 1 1 1 1 1 0]\n",
            "True:[1 0 1 1 0 0 1 0]\n",
            "101 + 77 = 126\n",
            "------------\n",
            "iters:3000\n",
            "Loss:0.9436974249273354\n",
            "Pred:[1 1 1 1 0 0 1 0]\n",
            "True:[1 0 0 1 1 0 1 0]\n",
            "113 + 41 = 242\n",
            "------------\n",
            "iters:3100\n",
            "Loss:0.9686779861246708\n",
            "Pred:[0 0 1 0 1 0 1 0]\n",
            "True:[0 0 1 1 1 1 0 0]\n",
            "37 + 23 = 42\n",
            "------------\n",
            "iters:3200\n",
            "Loss:0.7000351227704732\n",
            "Pred:[0 1 1 0 0 0 0 0]\n",
            "True:[0 1 0 1 0 0 0 0]\n",
            "33 + 47 = 96\n",
            "------------\n",
            "iters:3300\n",
            "Loss:0.7246172170589231\n",
            "Pred:[1 0 0 1 1 0 1 0]\n",
            "True:[1 1 0 1 1 0 1 0]\n",
            "98 + 120 = 154\n",
            "------------\n",
            "iters:3400\n",
            "Loss:0.868998085054324\n",
            "Pred:[1 1 0 1 1 1 0 0]\n",
            "True:[0 1 0 0 1 1 0 0]\n",
            "19 + 57 = 220\n",
            "------------\n",
            "iters:3500\n",
            "Loss:0.8341810447696237\n",
            "Pred:[1 0 1 1 0 0 0 0]\n",
            "True:[1 0 0 0 0 1 0 1]\n",
            "50 + 83 = 176\n",
            "------------\n",
            "iters:3600\n",
            "Loss:0.9081532923259051\n",
            "Pred:[0 1 0 0 0 1 1 1]\n",
            "True:[1 0 0 0 0 1 1 1]\n",
            "80 + 55 = 71\n",
            "------------\n",
            "iters:3700\n",
            "Loss:1.107907546677461\n",
            "Pred:[1 1 1 0 1 1 1 1]\n",
            "True:[0 1 1 0 0 0 1 1]\n",
            "41 + 58 = 239\n",
            "------------\n",
            "iters:3800\n",
            "Loss:1.0160947018579911\n",
            "Pred:[1 1 1 1 1 0 0 0]\n",
            "True:[0 1 1 0 1 0 0 0]\n",
            "40 + 64 = 248\n",
            "------------\n",
            "iters:3900\n",
            "Loss:0.5983084777028138\n",
            "Pred:[0 0 0 1 0 0 1 1]\n",
            "True:[0 0 0 1 0 0 0 1]\n",
            "6 + 11 = 19\n",
            "------------\n",
            "iters:4000\n",
            "Loss:1.032115262768492\n",
            "Pred:[0 1 1 1 0 0 0 0]\n",
            "True:[1 0 1 1 1 0 0 0]\n",
            "116 + 68 = 112\n",
            "------------\n",
            "iters:4100\n",
            "Loss:0.6843334167851797\n",
            "Pred:[0 0 1 0 0 1 1 0]\n",
            "True:[0 0 1 0 1 1 1 0]\n",
            "40 + 6 = 38\n",
            "------------\n",
            "iters:4200\n",
            "Loss:0.7962096788760494\n",
            "Pred:[0 1 1 1 1 1 0 0]\n",
            "True:[0 1 1 0 1 0 0 0]\n",
            "98 + 6 = 124\n",
            "------------\n",
            "iters:4300\n",
            "Loss:0.9273688497394169\n",
            "Pred:[0 1 1 0 1 0 1 1]\n",
            "True:[0 1 0 0 0 0 1 1]\n",
            "17 + 50 = 107\n",
            "------------\n",
            "iters:4400\n",
            "Loss:1.2597526025975336\n",
            "Pred:[0 1 0 0 0 0 1 1]\n",
            "True:[1 0 1 1 1 1 1 1]\n",
            "69 + 122 = 67\n",
            "------------\n",
            "iters:4500\n",
            "Loss:0.9530256802642667\n",
            "Pred:[0 1 0 1 1 1 1 0]\n",
            "True:[1 0 1 0 1 0 1 0]\n",
            "59 + 111 = 94\n",
            "------------\n",
            "iters:4600\n",
            "Loss:1.064862680407596\n",
            "Pred:[1 1 1 0 0 1 0 1]\n",
            "True:[0 1 1 1 1 1 1 1]\n",
            "34 + 93 = 229\n",
            "------------\n",
            "iters:4700\n",
            "Loss:0.6575292237455225\n",
            "Pred:[0 0 1 0 1 1 1 0]\n",
            "True:[1 0 1 0 1 1 1 0]\n",
            "80 + 94 = 46\n",
            "------------\n",
            "iters:4800\n",
            "Loss:0.6643970449114024\n",
            "Pred:[1 1 0 0 0 0 0 1]\n",
            "True:[1 0 0 0 1 0 0 1]\n",
            "48 + 89 = 193\n",
            "------------\n",
            "iters:4900\n",
            "Loss:0.8618784786331912\n",
            "Pred:[1 1 0 1 0 0 1 1]\n",
            "True:[1 0 0 0 1 1 1 1]\n",
            "84 + 59 = 211\n",
            "------------\n",
            "iters:5000\n",
            "Loss:0.7386508137169473\n",
            "Pred:[0 0 0 0 0 1 1 0]\n",
            "True:[0 0 0 1 1 1 1 0]\n",
            "18 + 12 = 6\n",
            "------------\n",
            "iters:5100\n",
            "Loss:0.7124193888883902\n",
            "Pred:[0 1 1 1 0 1 1 1]\n",
            "True:[0 1 1 0 1 1 0 1]\n",
            "52 + 57 = 119\n",
            "------------\n",
            "iters:5200\n",
            "Loss:0.7776527122077753\n",
            "Pred:[0 1 0 1 1 0 0 1]\n",
            "True:[1 1 0 1 0 0 0 1]\n",
            "125 + 84 = 89\n",
            "------------\n",
            "iters:5300\n",
            "Loss:1.0454373021234633\n",
            "Pred:[1 1 1 0 1 1 1 1]\n",
            "True:[0 1 0 1 1 0 1 1]\n",
            "0 + 91 = 239\n",
            "------------\n",
            "iters:5400\n",
            "Loss:0.9303952803928494\n",
            "Pred:[1 1 0 1 1 1 1 1]\n",
            "True:[1 0 0 0 1 0 1 1]\n",
            "67 + 72 = 223\n",
            "------------\n",
            "iters:5500\n",
            "Loss:0.639920945231749\n",
            "Pred:[1 1 1 1 1 1 1 0]\n",
            "True:[0 1 1 1 1 1 0 0]\n",
            "47 + 77 = 254\n",
            "------------\n",
            "iters:5600\n",
            "Loss:0.8020885634130817\n",
            "Pred:[0 0 1 0 1 1 1 0]\n",
            "True:[1 0 0 0 0 1 1 0]\n",
            "21 + 113 = 46\n",
            "------------\n",
            "iters:5700\n",
            "Loss:0.9205971367475481\n",
            "Pred:[1 1 1 0 1 0 1 0]\n",
            "True:[0 1 1 0 0 0 0 0]\n",
            "41 + 55 = 234\n",
            "------------\n",
            "iters:5800\n",
            "Loss:0.7080050125961734\n",
            "Pred:[0 1 0 0 1 1 0 1]\n",
            "True:[0 1 1 1 1 1 0 1]\n",
            "120 + 5 = 77\n",
            "------------\n",
            "iters:5900\n",
            "Loss:0.667433077543018\n",
            "Pred:[0 1 1 0 0 1 1 1]\n",
            "True:[0 1 0 0 0 1 1 1]\n",
            "20 + 51 = 103\n",
            "------------\n",
            "iters:6000\n",
            "Loss:1.1144203022001287\n",
            "Pred:[1 1 1 1 0 0 0 0]\n",
            "True:[1 0 0 0 0 0 1 0]\n",
            "49 + 81 = 240\n",
            "------------\n",
            "iters:6100\n",
            "Loss:0.9569420785892233\n",
            "Pred:[1 1 1 0 0 0 0 0]\n",
            "True:[0 1 1 0 1 0 0 0]\n",
            "84 + 20 = 224\n",
            "------------\n",
            "iters:6200\n",
            "Loss:0.5406132765113132\n",
            "Pred:[1 0 1 1 1 1 0 1]\n",
            "True:[1 0 1 1 0 1 0 1]\n",
            "105 + 76 = 189\n",
            "------------\n",
            "iters:6300\n",
            "Loss:0.8073815659290379\n",
            "Pred:[0 0 0 1 0 1 1 0]\n",
            "True:[0 1 1 0 0 1 1 0]\n",
            "55 + 47 = 22\n",
            "------------\n",
            "iters:6400\n",
            "Loss:1.1285277017703104\n",
            "Pred:[0 1 0 0 0 0 1 1]\n",
            "True:[1 0 0 0 1 1 1 1]\n",
            "54 + 89 = 67\n",
            "------------\n",
            "iters:6500\n",
            "Loss:0.8820927016544142\n",
            "Pred:[0 1 0 0 1 0 0 0]\n",
            "True:[0 0 0 0 1 0 0 0]\n",
            "8 + 0 = 72\n",
            "------------\n",
            "iters:6600\n",
            "Loss:0.7406797490178106\n",
            "Pred:[1 0 0 1 0 1 0 1]\n",
            "True:[1 0 0 1 1 0 0 1]\n",
            "75 + 78 = 149\n",
            "------------\n",
            "iters:6700\n",
            "Loss:0.7681203743951934\n",
            "Pred:[1 1 1 0 1 1 0 0]\n",
            "True:[1 1 1 0 0 0 0 0]\n",
            "106 + 118 = 236\n",
            "------------\n",
            "iters:6800\n",
            "Loss:0.7002333213833406\n",
            "Pred:[0 0 0 0 1 1 1 0]\n",
            "True:[1 0 0 1 1 1 1 0]\n",
            "108 + 50 = 14\n",
            "------------\n",
            "iters:6900\n",
            "Loss:0.6080690099118753\n",
            "Pred:[0 1 1 0 0 1 0 0]\n",
            "True:[0 1 1 1 0 1 0 0]\n",
            "6 + 110 = 100\n",
            "------------\n",
            "iters:7000\n",
            "Loss:0.17843773650872707\n",
            "Pred:[1 1 1 0 0 1 0 1]\n",
            "True:[1 1 1 0 0 1 0 1]\n",
            "116 + 113 = 229\n",
            "------------\n",
            "iters:7100\n",
            "Loss:0.9133260149815148\n",
            "Pred:[0 1 0 0 0 1 1 1]\n",
            "True:[0 1 0 0 1 0 0 1]\n",
            "58 + 15 = 71\n",
            "------------\n",
            "iters:7200\n",
            "Loss:0.6596160300813241\n",
            "Pred:[0 0 1 0 0 0 1 0]\n",
            "True:[1 0 1 0 0 0 1 0]\n",
            "49 + 113 = 34\n",
            "------------\n",
            "iters:7300\n",
            "Loss:0.28270760175464377\n",
            "Pred:[1 0 0 1 1 0 1 0]\n",
            "True:[1 0 0 1 1 0 1 0]\n",
            "127 + 27 = 154\n",
            "------------\n",
            "iters:7400\n",
            "Loss:0.8036582998031023\n",
            "Pred:[1 0 0 0 1 1 0 1]\n",
            "True:[1 1 0 0 0 1 1 1]\n",
            "120 + 79 = 141\n",
            "------------\n",
            "iters:7500\n",
            "Loss:0.9074269030772214\n",
            "Pred:[1 0 0 0 0 0 0 0]\n",
            "True:[0 1 1 0 0 0 0 0]\n",
            "74 + 22 = 128\n",
            "------------\n",
            "iters:7600\n",
            "Loss:0.28306450012219775\n",
            "Pred:[1 0 0 0 0 1 0 0]\n",
            "True:[1 0 0 0 0 1 0 0]\n",
            "61 + 71 = 132\n",
            "------------\n",
            "iters:7700\n",
            "Loss:0.49044179220968426\n",
            "Pred:[1 1 0 1 1 1 1 0]\n",
            "True:[1 1 0 0 1 1 1 0]\n",
            "100 + 106 = 222\n",
            "------------\n",
            "iters:7800\n",
            "Loss:0.2967430481442068\n",
            "Pred:[0 1 1 1 1 1 0 0]\n",
            "True:[0 1 1 1 1 1 0 0]\n",
            "76 + 48 = 124\n",
            "------------\n",
            "iters:7900\n",
            "Loss:0.6720283902925392\n",
            "Pred:[1 0 1 1 1 0 0 0]\n",
            "True:[1 0 0 1 1 0 0 0]\n",
            "64 + 88 = 184\n",
            "------------\n",
            "iters:8000\n",
            "Loss:0.13970707970370264\n",
            "Pred:[0 0 1 1 0 0 0 1]\n",
            "True:[0 0 1 1 0 0 0 1]\n",
            "40 + 9 = 49\n",
            "------------\n",
            "iters:8100\n",
            "Loss:0.3094470871380378\n",
            "Pred:[0 0 0 0 0 0 1 1]\n",
            "True:[1 0 0 0 0 0 1 1]\n",
            "29 + 102 = 3\n",
            "------------\n",
            "iters:8200\n",
            "Loss:0.12586517061535185\n",
            "Pred:[0 0 0 1 0 0 0 1]\n",
            "True:[0 0 0 1 0 0 0 1]\n",
            "14 + 3 = 17\n",
            "------------\n",
            "iters:8300\n",
            "Loss:0.08387948688310759\n",
            "Pred:[1 0 0 0 0 1 0 0]\n",
            "True:[1 0 0 0 0 1 0 0]\n",
            "121 + 11 = 132\n",
            "------------\n",
            "iters:8400\n",
            "Loss:0.17484992867910537\n",
            "Pred:[1 0 0 0 1 1 0 0]\n",
            "True:[1 0 0 0 1 1 0 0]\n",
            "114 + 26 = 140\n",
            "------------\n",
            "iters:8500\n",
            "Loss:0.13947535339542094\n",
            "Pred:[0 1 0 1 1 0 0 0]\n",
            "True:[0 1 0 1 1 0 0 0]\n",
            "30 + 58 = 88\n",
            "------------\n",
            "iters:8600\n",
            "Loss:0.04822139593843918\n",
            "Pred:[1 0 1 1 1 0 0 1]\n",
            "True:[1 0 1 1 1 0 0 1]\n",
            "86 + 99 = 185\n",
            "------------\n",
            "iters:8700\n",
            "Loss:0.011206606316760988\n",
            "Pred:[1 0 0 1 1 0 1 1]\n",
            "True:[1 0 0 1 1 0 1 1]\n",
            "71 + 84 = 155\n",
            "------------\n",
            "iters:8800\n",
            "Loss:0.4477656672270063\n",
            "Pred:[1 1 0 1 1 1 0 0]\n",
            "True:[0 1 0 1 1 1 0 0]\n",
            "79 + 13 = 220\n",
            "------------\n",
            "iters:8900\n",
            "Loss:0.01686586409848924\n",
            "Pred:[1 0 0 0 0 1 1 1]\n",
            "True:[1 0 0 0 0 1 1 1]\n",
            "100 + 35 = 135\n",
            "------------\n",
            "iters:9000\n",
            "Loss:0.017988355413969575\n",
            "Pred:[1 0 0 0 1 0 1 1]\n",
            "True:[1 0 0 0 1 0 1 1]\n",
            "110 + 29 = 139\n",
            "------------\n",
            "iters:9100\n",
            "Loss:0.14096490260185807\n",
            "Pred:[0 0 1 1 0 1 1 0]\n",
            "True:[0 0 1 1 0 1 1 0]\n",
            "10 + 44 = 54\n",
            "------------\n",
            "iters:9200\n",
            "Loss:0.15702525986461197\n",
            "Pred:[0 0 1 0 1 0 1 0]\n",
            "True:[0 1 1 0 1 0 1 0]\n",
            "71 + 35 = 42\n",
            "------------\n",
            "iters:9300\n",
            "Loss:0.12750835590021592\n",
            "Pred:[1 0 0 0 1 1 0 0]\n",
            "True:[1 0 0 0 1 1 0 0]\n",
            "114 + 26 = 140\n",
            "------------\n",
            "iters:9400\n",
            "Loss:0.008014103204278098\n",
            "Pred:[0 1 0 0 1 1 1 1]\n",
            "True:[0 1 0 0 1 1 1 1]\n",
            "16 + 63 = 79\n",
            "------------\n",
            "iters:9500\n",
            "Loss:0.012511557232207555\n",
            "Pred:[0 1 1 1 0 1 0 0]\n",
            "True:[0 1 1 1 0 1 0 0]\n",
            "35 + 81 = 116\n",
            "------------\n",
            "iters:9600\n",
            "Loss:0.01968129718998703\n",
            "Pred:[0 1 0 0 0 1 1 1]\n",
            "True:[0 1 0 0 0 1 1 1]\n",
            "68 + 3 = 71\n",
            "------------\n",
            "iters:9700\n",
            "Loss:0.001872224378417677\n",
            "Pred:[1 0 1 0 1 1 0 1]\n",
            "True:[1 0 1 0 1 1 0 1]\n",
            "55 + 118 = 173\n",
            "------------\n",
            "iters:9800\n",
            "Loss:0.0014465714132912862\n",
            "Pred:[1 1 0 1 0 0 0 1]\n",
            "True:[1 1 0 1 0 0 0 1]\n",
            "93 + 116 = 209\n",
            "------------\n",
            "iters:9900\n",
            "Loss:0.015267751997385682\n",
            "Pred:[1 1 1 0 0 1 0 1]\n",
            "True:[1 1 1 0 0 1 0 1]\n",
            "125 + 104 = 229\n",
            "------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "kP-w1yoJN4bM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}